{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "828349c5",
   "metadata": {},
   "source": [
    "# Main Notebook to experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e2e75a",
   "metadata": {},
   "source": [
    "### Load the music preference dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a593e7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"music.csv\")\n",
    "\n",
    "labels = ['amazed-suprised', 'happy-pleased', 'relaxing-clam', 'quiet-still',\n",
    "       'sad-lonely', 'angry-aggresive']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "random_state = 0\n",
    "n_test = 50\n",
    "X,Y = df.drop(columns=labels).to_numpy(), df[labels].to_numpy()\n",
    "X_train, x_test, Y_train, y_test = train_test_split(X, Y, test_size=n_test, random_state=random_state)\n",
    "\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# solvers=  ['lbfgs', 'saga', 'liblinear', 'sag', 'newton-cg', 'newton-cholesky'] # All solvers for LogisticRegression\n",
    "solvers=  ['liblinear','newton-cg', 'newton-cholesky'] # Only solvers that converge\n",
    "N = 500\n",
    "for s in solvers:\n",
    "    continue # Comment this to run the tests\n",
    "    train_acc = 0\n",
    "    test_acc = 0\n",
    "    best_test_acc = 0\n",
    "    for _ in range(N):\n",
    "        base = LogisticRegression(solver=s)\n",
    "        chain = ClassifierChain(base,order=\"random\")\n",
    "\n",
    "        chain = chain.fit(X_train,Y_train)\n",
    "        train_acc += np.mean(chain.predict(X_train)==Y_train)\n",
    "        t = np.mean(chain.predict(x_test)==y_test)\n",
    "        test_acc += t\n",
    "        best_test_acc = max(best_test_acc,t)\n",
    "\n",
    "    print(f\"Solver: {s}:\\n\\tTraining accuracy: {train_acc/N:0.5f}\\n\\tTest accuracy    : {test_acc/N:0.5f}\\n\\tBest Test accuracy: {best_test_acc:0.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83600985",
   "metadata": {},
   "source": [
    "### Another baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "67bc4da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solver: liblinear:\n",
      "\tTraining accuracy: 0.64578\n",
      "\tTest accuracy    : 0.62690\n",
      "\tBest Test accuracy: 0.64900\n",
      "Solver: newton-cg:\n",
      "\tTraining accuracy: 0.64755\n",
      "\tTest accuracy    : 0.62929\n",
      "\tBest Test accuracy: 0.65800\n",
      "Solver: newton-cholesky:\n",
      "\tTraining accuracy: 0.64670\n",
      "\tTest accuracy    : 0.62855\n",
      "\tBest Test accuracy: 0.65800\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "n_samples = 1000\n",
    "n_features=6\n",
    "n_labels=3\n",
    "random_state=0\n",
    "\n",
    "X, Y = make_multilabel_classification(\n",
    "    n_samples=n_samples, \n",
    "    n_features=n_features, \n",
    "    n_labels=n_labels, \n",
    "    random_state=random_state)\n",
    "\n",
    "test_size = 0.2\n",
    "X_train, x_test, Y_train, y_test = train_test_split(\n",
    "    X, Y,\n",
    "    test_size=test_size,\n",
    "    random_state=random_state)\n",
    "\n",
    "print(X_train, Y_train)\n",
    "\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# solvers=  ['lbfgs', 'saga', 'liblinear', 'sag', 'newton-cg', 'newton-cholesky'] # All solvers for LogisticRegression\n",
    "solvers=  ['liblinear','newton-cg', 'newton-cholesky'] # Only solvers that converge\n",
    "N = 500\n",
    "for s in solvers:\n",
    "    continue # Comment this to run the tests\n",
    "    train_acc = 0\n",
    "    test_acc = 0\n",
    "    best_test_acc = 0\n",
    "    for _ in range(N):\n",
    "        base = LogisticRegression(solver=s)\n",
    "        chain = ClassifierChain(base,order=\"random\")\n",
    "\n",
    "        chain = chain.fit(X_train,Y_train)\n",
    "        train_acc += np.mean(chain.predict(X_train)==Y_train)\n",
    "        t = np.mean(chain.predict(x_test)==y_test)\n",
    "        test_acc += t\n",
    "        best_test_acc = max(best_test_acc,t)\n",
    "\n",
    "    print(f\"Solver: {s}:\\n\\tTraining accuracy: {train_acc/N:0.5f}\\n\\tTest accuracy    : {test_acc/N:0.5f}\\n\\tBest Test accuracy: {best_test_acc:0.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aae7c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
