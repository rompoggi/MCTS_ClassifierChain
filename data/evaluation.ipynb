{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of our approach\n",
    "\n",
    "In this notebook, we include the test routine we used to compare our method, with the intention to help anyway trying to reproduce the obtained results. \n",
    "\n",
    "This notebook assumes that the datasets were cleaned using the [preprocessing notebook](./data_preprocessing.ipynb).\n",
    "The results of our run were saved to [losses.json](./.results/losses.json).\n",
    "\n",
    "If any bugs were to be caught while reading this code or while reproducing the results, please let us know on the project's [GitHub page](https://github.com/rompoggi/MCTS_ClassifierChain) via a [Pull Request](https://github.com/rompoggi/MCTS_ClassifierChain/pulls) or the [Discussions](https://github.com/rompoggi/MCTS_ClassifierChain/discussions) channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_names = [\n",
    "    \"2-EMOT\",\n",
    "    \"3-SCENE\",\n",
    "    \"4-FLAGS\",\n",
    "    \"5-FOODTRUCK\",\n",
    "    \"6-YEAST\",\n",
    "    \"7-BIRDS\",\n",
    "    \"8-GENBASE\",\n",
    "    # \"9-MEDC\",          # Removed as too long to test on\n",
    "    # \"10-ENRON\",        # Removed as too long to test on\n",
    "    # \"11-MEDIAMILL\",    # Removed as too long to test on\n",
    "    ]\n",
    "\n",
    "import pandas as pd\n",
    "def get_dataset(ds: str):\n",
    "    path_X = f\"./data/datasets/{ds}_X.csv\"\n",
    "    path_y = f\"./data/datasets/{ds}_y.csv\"\n",
    "    X = pd.read_csv(path_X)\n",
    "    y = pd.read_csv(path_y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics import hamming_loss, zero_one_loss\n",
    "from datetime import datetime \n",
    "\n",
    "from mcts_inference.pcc import PCC\n",
    "from mcts_inference.mcts import MCTS\n",
    "from mcts_inference.mcc import MCC\n",
    "from mcts_inference.policy import UCB, EpsGreedy, Thompson_Sampling\n",
    "from mcts_inference.constraints import Constraint\n",
    "from mcts_inference.mcts_config import MCTSConfig\n",
    "\n",
    "def losses(X, y, chain, algo, config, loss_fns=[hamming_loss]):\n",
    "    if algo is None:\n",
    "        y_pred = chain.predict(X)\n",
    "    elif config is not None:\n",
    "        y_pred = np.abs(algo(X, chain, config))\n",
    "    else:\n",
    "        raise ValueError(\"Config cannot be None if algo is not None\")\n",
    "\n",
    "    return [fn(y, y_pred) for fn in loss_fns]\n",
    "\n",
    "def loss_algos(ds, k=5, n_repeats = 1, random_state=0, loss_fns=[hamming_loss, zero_one_loss], loss_dict={}):\n",
    "    d_time = 20.\n",
    "    n_iter = 5\n",
    "    \n",
    "    loss_dict[ds] = {}\n",
    "    loss_dict[ds][\"PCC\"] = []\n",
    "    loss_dict[ds][\"CC\"] = []\n",
    "    loss_dict[ds][\"MCC\"] = []\n",
    "    loss_dict[ds][\"MCTS UCB(2)\"] = []\n",
    "    loss_dict[ds][\"MCTS EpsGreedy(0.2)\"] = []\n",
    "    loss_dict[ds][\"MCTS EpsGreedy(0.5)\"] = []\n",
    "    loss_dict[ds][\"MCTS Thompson_Sampling(1,1)\"] = []\n",
    "    loss_dict[ds][\"MCT1S UCB(2)\"] = []\n",
    "    loss_dict[ds][\"MCT1S EpsGreedy(0.2)\"] = []\n",
    "\n",
    "    X, y = get_dataset(ds)\n",
    "    \n",
    "    chain = ClassifierChain(SVC(max_iter=10_000, gamma=\"auto\", probability=True, random_state=random_state))\n",
    "\n",
    "    rkf = RepeatedKFold(n_splits=k, n_repeats=n_repeats, random_state=random_state)\n",
    "\n",
    "    print(f\" - {n_iter=}, {d_time=}, k={k}, n_repeats={n_repeats}\")\n",
    "    i = 1\n",
    "    for train_idx, test_idx in rkf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        print(f\"[{' '*(int(math.log(n_repeats*k,10))-int(math.log(i,10)))}{i}/{n_repeats * k} \", end=\"\")\n",
    "        if (not (y_train.nunique() > 1).all()):  # Check if there are multiple classes in the training set\n",
    "            print(f\"missing \", end=\"\")\n",
    "            # continue\n",
    "            dummy_row = pd.DataFrame({col: [0 if y_train[col].iloc[0] == 1 else 1] for col in y_train.columns}, index=[y_train.index.max() + 1])\n",
    "            y_train = pd.concat([y_train, dummy_row])\n",
    "            dummy_x_row = pd.DataFrame(np.zeros((1, len(X_train.columns))), columns=X_train.columns, index=[X_train.index.max() + 1])\n",
    "            X_train = pd.concat([X_train, dummy_x_row])\n",
    "\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        chain = chain.fit(X_train, y_train)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "        chain = chain.fit(X_train, y_train)\n",
    "        loss = losses(X_test, y_test, chain, algo=None, config=None, loss_fns=loss_fns)\n",
    "        loss_dict[ds][\"CC\"].append(loss)   \n",
    "        print(f\". \", end=\"\")\n",
    "\n",
    "        config = MCTSConfig(n_classes=y.shape[1], constraint=Constraint(time=True, d_time=d_time))\n",
    "        loss = losses(X_test, y_test, chain, algo=PCC, config=config, loss_fns=loss_fns)\n",
    "        loss_dict[ds][\"PCC\"].append(loss)\n",
    "        print(f\". \", end=\"\")\n",
    "\n",
    "        config = MCTSConfig(n_classes=y.shape[1], selection_policy=UCB(2), constraint=Constraint(max_iter=True, n_iter=n_iter))\n",
    "        loss = losses(X_test, y_test, chain, MCC, config, loss_fns=loss_fns)\n",
    "        loss_dict[ds][\"MCC\"].append(loss)\n",
    "        print(f\". \", end=\"\")\n",
    "\n",
    "        config = MCTSConfig(n_classes=y.shape[1], selection_policy=UCB(2), constraint=Constraint(max_iter=True, n_iter=n_iter))\n",
    "        loss = losses(X_test, y_test, chain, MCTS, config, loss_fns=loss_fns)\n",
    "        loss_dict[ds][\"MCTS UCB(2)\"].append(loss)\n",
    "        print(f\". \", end=\"\")\n",
    "\n",
    "        config = MCTSConfig(n_classes=y.shape[1], selection_policy=EpsGreedy(0.2), constraint=Constraint(max_iter=True, n_iter=n_iter))\n",
    "        loss = losses(X_test, y_test, chain, MCTS, config, loss_fns=loss_fns)\n",
    "        loss_dict[ds][\"MCTS EpsGreedy(0.2)\"].append(loss)\n",
    "        print(f\". \", end=\"\")\n",
    "\n",
    "        config = MCTSConfig(n_classes=y.shape[1], selection_policy=EpsGreedy(0.5), constraint=Constraint(max_iter=True, n_iter=n_iter))\n",
    "        loss = losses(X_test, y_test, chain, MCTS, config, loss_fns=loss_fns)\n",
    "        loss_dict[ds][\"MCTS EpsGreedy(0.5)\"].append(loss)\n",
    "        print(f\". \", end=\"\")\n",
    "\n",
    "        config = MCTSConfig(n_classes=y.shape[1], selection_policy=Thompson_Sampling(1,1), constraint=Constraint(max_iter=True, n_iter=n_iter))\n",
    "        loss = losses(X_test, y_test, chain, MCTS, config, loss_fns=loss_fns)\n",
    "        loss_dict[ds][\"MCTS Thompson_Sampling(1,1)\"].append(loss)\n",
    "        print(f\". \", end=\"\")\n",
    "\n",
    "        config = MCTSConfig(n_classes=y.shape[1], selection_policy=UCB(2), constraint=Constraint(max_iter=True, n_iter=n_iter), step_once=False)\n",
    "        loss = losses(X_test, y_test, chain, MCTS, config, loss_fns=loss_fns)\n",
    "        loss_dict[ds][\"MCT1S UCB(2)\"].append(loss)\n",
    "        print(f\". \", end=\"\")\n",
    "\n",
    "        config = MCTSConfig(n_classes=y.shape[1], selection_policy=EpsGreedy(0.2), constraint=Constraint(max_iter=True, n_iter=n_iter), step_once=False)\n",
    "        loss = losses(X_test, y_test, chain, MCTS, config, loss_fns=loss_fns)\n",
    "        loss_dict[ds][\"MCT1S EpsGreedy(0.2)\"].append(loss)\n",
    "        print(f\". {datetime.now().strftime('%H:%M:%S')}]\")\n",
    "\n",
    "        i+=1\n",
    "\n",
    "    for key in loss_dict[ds].keys():\n",
    "        loss_dict[ds][key] = list(np.mean(loss_dict[ds][key], axis=0))\n",
    "\n",
    "    return loss_dict[ds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Hamming Loss & Zero One Loss-\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "> Dataset: 2-EMOT - 16:23:08 - n_iter=5, d_time=20.0, k=10, n_repeats=2\n",
      "[ 1/20 . . . . . . . . . 16:23:22]\n",
      "[ 2/20 . "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m> Dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mds\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 11\u001b[0m     L \u001b[38;5;241m=\u001b[39m \u001b[43mloss_algos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mhamming_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzero_one_loss\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlosses_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBrute Force (PCC)           : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mL[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPCC\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m[\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mx\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mx\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mL[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPCC\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 81\u001b[0m, in \u001b[0;36mloss_algos\u001b[0;34m(ds, k, n_repeats, random_state, loss_fns, loss_dict)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     80\u001b[0m config \u001b[38;5;241m=\u001b[39m MCTSConfig(n_classes\u001b[38;5;241m=\u001b[39my\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], constraint\u001b[38;5;241m=\u001b[39mConstraint(time\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, d_time\u001b[38;5;241m=\u001b[39md_time))\n\u001b[0;32m---> 81\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mlosses\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPCC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m loss_dict[ds][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPCC\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 22\u001b[0m, in \u001b[0;36mlosses\u001b[0;34m(X, y, chain, algo, config, loss_fns)\u001b[0m\n\u001b[1;32m     20\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m chain\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 22\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(\u001b[43malgo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfig cannot be None if algo is not None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Education/Bachelor/Thesis/MCTS_ClassifierChain/src/mcts_inference/pcc.py:98\u001b[0m, in \u001b[0;36mPCC\u001b[0;34m(x, model, config)\u001b[0m\n\u001b[1;32m     95\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_2d(x)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mparallel:\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[1;32m    100\u001b[0m             out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(tqdm(pool\u001b[38;5;241m.\u001b[39mimap(PCC_wrapper, [(x, model, config) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X]), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(X)))\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/context.py:119\u001b[0m, in \u001b[0;36mBaseContext.Pool\u001b[0;34m(self, processes, initializer, initargs, maxtasksperchild)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''Returns a process pool object'''\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpool\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pool\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocesses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitializer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxtasksperchild\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py:215\u001b[0m, in \u001b[0;36mPool.__init__\u001b[0;34m(self, processes, initializer, initargs, maxtasksperchild, context)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_processes \u001b[38;5;241m=\u001b[39m processes\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_repopulate_pool\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool:\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py:306\u001b[0m, in \u001b[0;36mPool._repopulate_pool\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_repopulate_pool\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_repopulate_pool_static\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_processes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inqueue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_outqueue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maxtasksperchild\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrap_exception\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/pool.py:329\u001b[0m, in \u001b[0;36mPool._repopulate_pool_static\u001b[0;34m(ctx, Process, processes, pool, inqueue, outqueue, initializer, initargs, maxtasksperchild, wrap_exception)\u001b[0m\n\u001b[1;32m    327\u001b[0m w\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m w\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcess\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPoolWorker\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    328\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 329\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m pool\u001b[38;5;241m.\u001b[39mappend(w)\n\u001b[1;32m    331\u001b[0m util\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madded worker\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/context.py:288\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_posix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/popen_spawn_posix.py:42\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     40\u001b[0m tracker_fd \u001b[38;5;241m=\u001b[39m resource_tracker\u001b[38;5;241m.\u001b[39mgetfd()\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fds\u001b[38;5;241m.\u001b[39mappend(tracker_fd)\n\u001b[0;32m---> 42\u001b[0m prep_data \u001b[38;5;241m=\u001b[39m \u001b[43mspawn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_preparation_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m fp \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO()\n\u001b[1;32m     44\u001b[0m set_spawning_popen(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py:164\u001b[0m, in \u001b[0;36mget_preparation_data\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_preparation_data\u001b[39m(name):\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m    Return info about parent needed by child to unpickle process object\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 164\u001b[0m     \u001b[43m_check_not_importing_main\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    166\u001b[0m         log_to_stderr\u001b[38;5;241m=\u001b[39mutil\u001b[38;5;241m.\u001b[39m_log_to_stderr,\n\u001b[1;32m    167\u001b[0m         authkey\u001b[38;5;241m=\u001b[39mprocess\u001b[38;5;241m.\u001b[39mcurrent_process()\u001b[38;5;241m.\u001b[39mauthkey,\n\u001b[1;32m    168\u001b[0m         )\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m util\u001b[38;5;241m.\u001b[39m_logger \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/spawn.py:139\u001b[0m, in \u001b[0;36m_check_not_importing_main\u001b[0;34m()\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_not_importing_main\u001b[39m():\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_inheriting\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    140\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124m        An attempt has been made to start a new process before the\u001b[39m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124m        current process has finished its bootstrapping phase.\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124m        section in https://docs.python.org/3/library/multiprocessing.html\u001b[39m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m'''\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/multiprocessing/process.py:37\u001b[0m, in \u001b[0;36mcurrent_process\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     ORIGINAL_DIR \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Public functions\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcurrent_process\u001b[39m():\n\u001b[1;32m     38\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m    Return process object representing the current process\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _current_process\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import hamming_loss, zero_one_loss\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "losses_dict = dict()\n",
    "print(\"- Hamming Loss & Zero One Loss-\")\n",
    "for ds in ds_names[:7]:\n",
    "    print(\">\"*80)\n",
    "    print(f\"> Dataset: {ds} - {datetime.now().strftime('%H:%M:%S')}\", end=\"\")\n",
    "    try:\n",
    "        L = loss_algos(ds, k=10, n_repeats=2, random_state=0, loss_fns=[hamming_loss, zero_one_loss], loss_dict=losses_dict)\n",
    "        print(\"_\"*32)\n",
    "        print(f\"Brute Force (PCC)           : {L['PCC']}, Score: {[1- x for x in L['PCC']]}\")\n",
    "        print(f\"Classifier Chain (CC)       : {L['CC']}, Score: {[1- x for x in L['CC']]}\")\n",
    "        print(f\"Monte Carlo CC (MCC)        : {L['MCC']}, Score: {[1- x for x in L['MCC']]}\")\n",
    "        print(f\"MCTS UCB(2)                 : {L['MCTS UCB(2)']}, Score: {[1- x for x in L['MCTS UCB(2)']]}\")\n",
    "        print(f\"MCTS EpsGreedy(0.2)         : {L['MCTS EpsGreedy(0.2)']}, Score: {[1-x for x in L['MCTS EpsGreedy(0.2)']]}\")\n",
    "        print(f\"MCTS EpsGreedy(0.5)         : {L['MCTS EpsGreedy(0.5)']}, Score: {[1-x for x in L['MCTS EpsGreedy(0.5)']]}\")\n",
    "        print(f\"MCTS Thompson_Sampling(1,1) : {L['MCTS Thompson_Sampling(1,1)']}, Score: {[1-x for x in L['MCTS Thompson_Sampling(1,1)']]}\")\n",
    "        print(f\"MCT1S UCB(2)                : {L['MCT1S UCB(2)']}, Score: {[1- x for x in L['MCT1S UCB(2)']]}\")\n",
    "        print(f\"MCT1S EpsGreedy(0.2)        : {L['MCT1S EpsGreedy(0.2)']}, Score: {[1- x for x in L['MCT1S EpsGreedy(0.2)']]}\")\n",
    "        print(\"_\"*32,\"\\n\")\n",
    "\n",
    "        with open('./data/.results/temp_losses.json', 'a') as outfile:  # Save results to file\n",
    "            L[\"datetime\"] = datetime.now().strftime('%H:%M:%S')\n",
    "            json.dump(L, outfile)\n",
    "            del L[\"datetime\"]  # Remove this key as we do not save it if the whole test goes through\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in {ds}: {e}\")\n",
    "        losses_dict[ds] = None\n",
    "\n",
    "losses_dict[\"datetime\"] = datetime.now().strftime('%H:%M:%S')\n",
    "with open('./data/.results/losses.json', 'a') as outfile:  # Save all results\n",
    "    json.dump(losses_dict, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
