{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of the novel methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_names = [\n",
    "    \"2-EMOT\",\n",
    "    \"3-SCENE\",\n",
    "    \"4-FLAGS\",\n",
    "    \"5-FOODTRUCK\",\n",
    "    \"6-YEAST\",\n",
    "    \"7-BIRDS\",\n",
    "    \"8-GENBASE\",\n",
    "    \"9-MEDC\",\n",
    "    \"10-ENRON\",\n",
    "    \"11-MEDIAMILL\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def get_dataset(ds: str):\n",
    "    path_X = f\"./data/datasets/{ds}_X.csv\"\n",
    "    path_y = f\"./data/datasets/{ds}_y.csv\"\n",
    "    X = pd.read_csv(path_X)\n",
    "    y = pd.read_csv(path_y)\n",
    "    return X, y\n",
    "\n",
    "X, y = get_dataset(\"3-SCENE\")\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "import numpy as np\n",
    "from sklearn.metrics import hamming_loss, zero_one_loss \n",
    "\n",
    "from mcts_inference.brute_force import brute_force as bf\n",
    "from mcts_inference.mcts import MCTS\n",
    "from mcts_inference.mc import MCC\n",
    "from mcts_inference.policy import UCB\n",
    "from mcts_inference.constraints import Constraint\n",
    "from mcts_inference.mcts_config import MCTSConfig\n",
    "\n",
    "def losses(X_train, y_train, X_test, y_test, chain, algo, config, loss_fn=hamming_loss):\n",
    "    chain = chain.fit(X_train, y_train)\n",
    "    if algo is None:\n",
    "        y_pred = chain.predict(X_test)\n",
    "    elif config is not None:\n",
    "        y_pred = np.abs(algo(X_test, chain, config))\n",
    "    else:\n",
    "        raise ValueError(\"Config cannot be None if algo is not None\")\n",
    "\n",
    "    return loss_fn(y_test, y_pred)\n",
    "\n",
    "def loss_algos(ds, k=5, n_repeats = 1, random_state=0, loss_fn=hamming_loss):\n",
    "    X, y = get_dataset(ds)\n",
    "    chain = ClassifierChain(LogisticRegression(solver=\"liblinear\", max_iter=10000))\n",
    "\n",
    "    n_iter = 100\n",
    "    d_time = 1.\n",
    "    \n",
    "    bf_loss = []\n",
    "    cc_loss = []\n",
    "    mc_loss = []\n",
    "    mcts_loss = []\n",
    "    mct1s_loss = []\n",
    "\n",
    "    rkf = RepeatedKFold(n_splits=k, n_repeats=n_repeats, random_state=random_state)\n",
    "    for train_idx, test_idx in rkf.split(X, y):\n",
    "        # print(i)\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        config = MCTSConfig(n_classes=y.shape[1], constraint=Constraint(time=True, d_time=d_time))\n",
    "        loss = losses(X_train, y_train, X_test, y_test, chain, algo=bf, config=config, loss_fn=loss_fn)\n",
    "        bf_loss.append(loss)\n",
    "\n",
    "        loss = losses(X_train, y_train, X_test, y_test, chain, algo=None, config=None, loss_fn=loss_fn)\n",
    "        cc_loss.append(loss)\n",
    "\n",
    "        config = MCTSConfig(n_classes=y.shape[1], selection_policy=UCB(2), constraint=Constraint(max_iter=True, n_iter=n_iter))\n",
    "        loss = losses(X_train, y_train, X_test, y_test, chain, MCC, config, loss_fn=loss_fn)\n",
    "        mc_loss.append(loss)\n",
    "\n",
    "        config = MCTSConfig(n_classes=y.shape[1], selection_policy=UCB(2), constraint=Constraint(max_iter=True, n_iter=n_iter))\n",
    "        loss = losses(X_train, y_train, X_test, y_test, chain, MCTS, config, loss_fn=loss_fn)\n",
    "        mcts_loss.append(loss)\n",
    "\n",
    "        config = MCTSConfig(n_classes=y.shape[1], selection_policy=UCB(2), constraint=Constraint(max_iter=True, n_iter=n_iter), step_once=False)\n",
    "        loss = losses(X_train, y_train, X_test, y_test, chain, MCTS, config, loss_fn=loss_fn)\n",
    "        mct1s_loss.append(loss)\n",
    "\n",
    "    return {\"BF\": np.mean(bf_loss), \"CC\": np.mean(cc_loss), \"MC\": np.mean(mc_loss), \"MCTS\": np.mean(mcts_loss), \"MCTS1S\": np.mean(mct1s_loss)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "dataset_hamming_losses = dict()\n",
    "print(\"- Hamming Loss -\")\n",
    "for ds in ds_names:\n",
    "    print(f\"> Dataset: {ds}\")\n",
    "    try:\n",
    "        L = loss_algos(ds, k=5, n_repeats=1, random_state=0, loss_fn=hamming_loss)\n",
    "        print(f\"\\tBrute Force: {L['BF']}, Score: {1-L['BF']}\")\n",
    "        print(f\"\\tClassifier Chain (CC): {L['CC']}, Score: {1-L['CC']}\")\n",
    "        print(f\"\\tMonte Carlo CC: {L['MC']}, Score: {1-L['MC']}\")\n",
    "        print(f\"\\tMCTS: {L['MCTS']}, Score: {1-L['MCTS']}\")\n",
    "        print(f\"\\tMCTS1S: {L['MCTS1S']}, Score: {1-L['MCTS1S']}\")\n",
    "        dataset_hamming_losses[ds] = L\n",
    "    except Exception as e:\n",
    "        print(f\"Error in {ds}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "\n",
    "dataset_zero_one_losses = dict()\n",
    "print(\"- Zero-One Loss -\")\n",
    "for ds in ds_names:\n",
    "    print(f\"> Dataset: {ds}\")\n",
    "    try:\n",
    "        L = loss_algos(ds, k=5, n_repeats=1, random_state=0, loss_fn=zero_one_loss)\n",
    "        print(f\"\\tBrute Force: {L['BF']}, Score: {1-L['BF']}\")\n",
    "        print(f\"\\tClassifier Chain (CC): {L['CC']}, Score: {1-L['CC']}\")\n",
    "        print(f\"\\tMonte Carlo CC: {L['MC']}, Score: {1-L['MC']}\")\n",
    "        print(f\"\\tMCTS: {L['MCTS']}, Score: {1-L['MCTS']}\")\n",
    "        print(f\"\\tMCTS1S: {L['MCTS1S']}, Score: {1-L['MCTS1S']}\")\n",
    "        dataset_zero_one_losses[ds] = L\n",
    "    except Exception as e:\n",
    "        print(f\"Error in {ds}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
