{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "212749e6",
   "metadata": {},
   "source": [
    "# Cleaning up of datasets for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8600337f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_files = True\n",
    "\n",
    "if save_files:\n",
    "    import os\n",
    "    if (os.path.exists(\"./data/\") is False):\n",
    "        os.makedirs(\"./data/\")\n",
    "        \n",
    "    assert(os.path.exists(\"./data/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f15734c",
   "metadata": {},
   "source": [
    "## 1. Solar Flare: N = 1389, L = 3, d = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7b15061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.11/site-packages (0.0.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb99457e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'uci_id': 89, 'name': 'Solar Flare', 'repository_url': 'https://archive.ics.uci.edu/dataset/89/solar+flare', 'data_url': 'https://archive.ics.uci.edu/static/public/89/data.csv', 'abstract': 'Each class attribute counts the number of solar flares of a certain class that occur in a 24 hour period', 'area': 'Physics and Chemistry', 'tasks': ['Regression'], 'characteristics': ['Multivariate'], 'num_instances': 1389, 'num_features': 10, 'feature_types': ['Categorical'], 'demographics': [], 'target_col': ['common flares', 'moderate flares', 'severe flares'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1989, 'last_updated': 'Wed Feb 14 2024', 'dataset_doi': '10.24432/C5530G', 'creators': [], 'intro_paper': None, 'additional_info': {'summary': 'Notes:\\r\\n\\r\\n   -- The database contains 3 potential classes, one for the number of times a certain type of solar flare occured in a 24 hour period.\\r\\n   -- Each instance represents captured features for 1 active region on the sun.\\r\\n   -- The data are divided into two sections. The second section (flare.data2) has had much more error correction applied to the it, and has consequently been treated as more reliable.', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': \"   1. Code for class (modified Zurich class)  (A,B,C,D,E,F,H)\\r\\n   2. Code for largest spot size              (X,R,S,A,H,K)\\r\\n   3. Code for spot distribution              (X,O,I,C)\\r\\n   4. Activity                                (1 = reduced, 2 = unchanged)\\r\\n   5. Evolution                               (1 = decay, 2 = no growth, 3 = growth)\\r\\n   6. Previous 24 hour flare activity code    (1 = nothing as big as an M1, 2 = one M1, 3 = more activity than one M1)\\r\\n   7. Historically-complex                    (1 = Yes, 2 = No)\\r\\n   8. Did region become historically complex  on this pass across the sun's disk (1 = yes, 2 = no) \\r\\n   9. Area                                    (1 = small, 2 = large)\\r\\n  10. Area of the largest spot                (1 = <=5, 2 = >5)\\r\\n\\r\\n From all these predictors three classes of flares are predicted, which are represented in the last three columns.\\r\\n\\r\\n  11. C-class flares production by this region in the following 24 hours (common flares); Number\\r\\n  12. M-class flares production by this region in the following 24 hours (moderate flares);   Number\\r\\n  13. X-class flares production by this region in the following 24 hours (severe flares); Number\\r\\n     \", 'citation': None}}\n",
      "                               name     role         type demographic  \\\n",
      "0             modified Zurich class  Feature  Categorical        None   \n",
      "1                 largest spot size  Feature  Categorical        None   \n",
      "2                 spot distribution  Feature  Categorical        None   \n",
      "3                          activity  Feature      Integer        None   \n",
      "4                         evolution  Feature      Integer        None   \n",
      "5   previous 24 hour flare activity  Feature      Integer        None   \n",
      "6              historically-complex  Feature      Integer        None   \n",
      "7       became complex on this pass  Feature      Integer        None   \n",
      "8                              area  Feature      Integer        None   \n",
      "9              area of largest spot  Feature      Integer        None   \n",
      "10                    common flares   Target      Integer        None   \n",
      "11                  moderate flares   Target      Integer        None   \n",
      "12                    severe flares   Target      Integer        None   \n",
      "\n",
      "                                          description units missing_values  \n",
      "0                                       A,B,C,D,E,F,H  None             no  \n",
      "1                                         X,R,S,A,H,K  None             no  \n",
      "2                                             X,O,I,C  None             no  \n",
      "3                          1 = reduced, 2 = unchanged  None             no  \n",
      "4                1 = decay, 2 = no growth, 3 = growth  None             no  \n",
      "5   1 = nothing as big as an M1, 2 = one M1, 3 = m...  None             no  \n",
      "6                                     1 = Yes, 2 = No  None             no  \n",
      "7   . Did region become historically complex  on t...  None             no  \n",
      "8                                1 = small, 2 = large  None             no  \n",
      "9                                     1 = <=5, 2 = >5  None             no  \n",
      "10  C-class flares production by this region in th...  None             no  \n",
      "11  M-class flares production by this region in th...  None             no  \n",
      "12  X-class flares production by this region in th...  None             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo, list_available_datasets\n",
    "\n",
    "# fetch dataset \n",
    "solar_flare = fetch_ucirepo(name=\"Solar Flare\") \n",
    "\n",
    "print(solar_flare.data.version2)\n",
    "  \n",
    "# data (as pandas dataframes)\n",
    "X = solar_flare.data.features \n",
    "y = solar_flare.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(solar_flare.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(solar_flare.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "967601e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      modified Zurich class  largest spot size  spot distribution  activity  \\\n",
       " 0                         1                  4                  2         1   \n",
       " 1                         2                  4                  2         1   \n",
       " 2                         1                  4                  2         1   \n",
       " 3                         2                  4                  2         1   \n",
       " 4                         2                  0                  2         1   \n",
       " ...                     ...                ...                ...       ...   \n",
       " 1384                      5                  4                  3         1   \n",
       " 1385                      5                  4                  3         2   \n",
       " 1386                      1                  4                  2         1   \n",
       " 1387                      5                  3                  3         1   \n",
       " 1388                      0                  5                  2         1   \n",
       " \n",
       "       evolution  previous 24 hour flare activity  historically-complex  \\\n",
       " 0             2                                1                     1   \n",
       " 1             3                                1                     1   \n",
       " 2             3                                1                     1   \n",
       " 3             3                                1                     1   \n",
       " 4             3                                1                     1   \n",
       " ...         ...                              ...                   ...   \n",
       " 1384          2                                1                     1   \n",
       " 1385          2                                1                     1   \n",
       " 1386          2                                1                     2   \n",
       " 1387          2                                1                     1   \n",
       " 1388          1                                1                     1   \n",
       " \n",
       "       became complex on this pass  area  area of largest spot  \n",
       " 0                               2     1                     2  \n",
       " 1                               2     1                     2  \n",
       " 2                               2     1                     1  \n",
       " 3                               2     1                     2  \n",
       " 4                               2     1                     2  \n",
       " ...                           ...   ...                   ...  \n",
       " 1384                            1     1                     1  \n",
       " 1385                            2     1                     1  \n",
       " 1386                            2     1                     1  \n",
       " 1387                            2     1                     1  \n",
       " 1388                            2     1                     1  \n",
       " \n",
       " [1389 rows x 10 columns],\n",
       "       common flares  moderate flares  severe flares\n",
       " 0                 0                0              0\n",
       " 1                 0                0              0\n",
       " 2                 0                0              0\n",
       " 3                 0                0              0\n",
       " 4                 0                0              0\n",
       " ...             ...              ...            ...\n",
       " 1384              0                0              0\n",
       " 1385              0                0              0\n",
       " 1386              0                0              0\n",
       " 1387              0                0              0\n",
       " 1388              0                0              0\n",
       " \n",
       " [1389 rows x 3 columns])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "clean_X = X.copy()\n",
    "for x in X.columns:\n",
    "    if X[x].dtype == 'object':\n",
    "        clean_X[x] = label_encoder.fit_transform(X[x])      \n",
    "\n",
    "X = clean_X.copy()\n",
    "del clean_X\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f3b312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_files:\n",
    "    X.to_csv('./data/1-FLARE_X.csv')\n",
    "    y.to_csv('./data/1-FLARE_y.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76be05f0",
   "metadata": {},
   "source": [
    "## 0.2. Bridges, N = 105, L = 6 , d = 7, not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce424d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "bridges_raw_file_name = './bridges/bridges.arff'\n",
    "assert(os.path.isfile(bridges_raw_file_name))\n",
    "\n",
    "# Load ARFF file\n",
    "data, meta = arff.loadarff(bridges_raw_file_name,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da9e3b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  IDENTIF RIVER LOCATION ERECTED   PURPOSE  LENGTH LANES CLEAR-G   T-OR-D  \\\n",
       " 0      E1     M        3  CRAFTS   HIGHWAY       ?     2       N  THROUGH   \n",
       " 1      E2     A       25  CRAFTS   HIGHWAY  MEDIUM     2       N  THROUGH   \n",
       " 2      E3     A       39  CRAFTS  AQUEDUCT       ?     1       N  THROUGH   \n",
       " 3      E5     A       29  CRAFTS   HIGHWAY  MEDIUM     2       N  THROUGH   \n",
       " 4      E6     M       23  CRAFTS   HIGHWAY       ?     2       N  THROUGH   \n",
       " \n",
       "   MATERIAL   SPAN REL-L  TYPE  \n",
       " 0     WOOD  SHORT     S  WOOD  \n",
       " 1     WOOD  SHORT     S  WOOD  \n",
       " 2     WOOD      ?     S  WOOD  \n",
       " 3     WOOD  SHORT     S  WOOD  \n",
       " 4     WOOD      ?     S  WOOD  ,\n",
       " Index(['IDENTIF', 'RIVER', 'LOCATION', 'ERECTED', 'PURPOSE', 'LENGTH', 'LANES',\n",
       "        'CLEAR-G', 'T-OR-D', 'MATERIAL', 'SPAN', 'REL-L', 'TYPE'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Optionally, decode byte strings to regular strings if necessary\n",
    "df = df.applymap(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
    "\n",
    "df.head(), df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d80ffa08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     IDENTIF  RIVER  LOCATION  ERECTED  PURPOSE  LENGTH  LANES  CLEAR-G  \\\n",
       " 0          0      1        22        0        1       0      1        2   \n",
       " 1         17      0        17        0        1       2      1        2   \n",
       " 2         28      0        33        0        0       0      0        2   \n",
       " 3         50      0        21        0        1       2      1        2   \n",
       " 4         61      1        15        0        1       0      1        2   \n",
       " ..       ...    ...       ...      ...      ...     ...    ...      ...   \n",
       " 100       90      0        26        3        1       3      2        1   \n",
       " 101       89      1        53        3        1       1      2        1   \n",
       " 102       88      0        16        3        1       3      3        1   \n",
       " 103       96      2        41        3        1       1      3        1   \n",
       " 104       95      1        51        3        1       3      3        1   \n",
       " \n",
       "      T-OR-D  MATERIAL  SPAN  REL-L  \n",
       " 0         2         2     3      2  \n",
       " 1         2         2     3      2  \n",
       " 2         2         2     0      2  \n",
       " 3         2         2     3      2  \n",
       " 4         2         2     0      2  \n",
       " ..      ...       ...   ...    ...  \n",
       " 100       1         1     2      3  \n",
       " 101       1         1     1      1  \n",
       " 102       2         1     2      1  \n",
       " 103       2         1     1      1  \n",
       " 104       2         1     1      1  \n",
       " \n",
       " [105 rows x 12 columns],\n",
       "      TYPE_ARCH  TYPE_CANTILEV  TYPE_CONT-T  TYPE_SIMPLE-T  TYPE_SUSPEN  \\\n",
       " 0            0              0            0              0            0   \n",
       " 1            0              0            0              0            0   \n",
       " 2            0              0            0              0            0   \n",
       " 3            0              0            0              0            0   \n",
       " 4            0              0            0              0            0   \n",
       " ..         ...            ...          ...            ...          ...   \n",
       " 100          0              0            1              0            0   \n",
       " 101          0              0            1              0            0   \n",
       " 102          1              0            0              0            0   \n",
       " 103          1              0            0              0            0   \n",
       " 104          1              0            0              0            0   \n",
       " \n",
       "      TYPE_WOOD  \n",
       " 0            1  \n",
       " 1            1  \n",
       " 2            1  \n",
       " 3            1  \n",
       " 4            1  \n",
       " ..         ...  \n",
       " 100          0  \n",
       " 101          0  \n",
       " 102          0  \n",
       " 103          0  \n",
       " 104          0  \n",
       " \n",
       " [105 rows x 6 columns])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=[\"TYPE\"])\n",
    "y = pd.DataFrame(df[\"TYPE\"])\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for x in X.columns:\n",
    "    if X[x].dtype == 'object':\n",
    "        X[x] = label_encoder.fit_transform(X[x])\n",
    "\n",
    "y = pd.DataFrame(df[\"TYPE\"])\n",
    "y = pd.get_dummies(y[\"TYPE\"], prefix=\"TYPE\")\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b16308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_files and False:  # and False since we are not using bridges\n",
    "    X.to_csv(\"./data/2-BRIDGES_X.csv\")\n",
    "    y.to_csv(\"./data/2-BRIDGES_y.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd6964c",
   "metadata": {},
   "source": [
    "## 0.3. Parkinson's: L = 1, Not usable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e35c1314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.11/site-packages (0.0.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca3cf5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 174, 'name': 'Parkinsons', 'repository_url': 'https://archive.ics.uci.edu/dataset/174/parkinsons', 'data_url': 'https://archive.ics.uci.edu/static/public/174/data.csv', 'abstract': \"Oxford Parkinson's Disease Detection Dataset\", 'area': 'Health and Medicine', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 197, 'num_features': 22, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['status'], 'index_col': ['name'], 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2007, 'last_updated': 'Wed Feb 14 2024', 'dataset_doi': '10.24432/C59C74', 'creators': ['Max Little'], 'intro_paper': {'title': 'Exploiting Nonlinear Recurrence and Fractal Scaling Properties for Voice Disorder Detection', 'authors': 'Max A. Little, P. McSharry, S. Roberts, D. Costello, I. Moroz', 'published_in': 'BioMedical Engineering OnLine', 'year': 2007, 'url': 'https://www.semanticscholar.org/paper/27e1dcd0d64bfc9d936e597d4f29b80c21571936', 'doi': '10.1186/1475-925X-6-23'}, 'additional_info': {'summary': 'This dataset is composed of a range of biomedical voice measurements from 31 people, 23 with Parkinson\\'s disease (PD). Each column in the table is a particular voice measure, and each row corresponds one of 195 voice recording from these individuals (\"name\" column). The main aim of the data is to discriminate healthy people from those with PD, according to \"status\" column which is set to 0 for healthy and 1 for PD. \\r\\n\\r\\nThe data is in ASCII CSV format. The rows of the CSV file contain an instance corresponding to one voice recording. There are around six recordings per patient, the name of the patient is identified in the first column.For further information or to pass on comments, please contact Max Little (littlem \\'@\\' robots.ox.ac.uk).\\r\\n\\r\\nFurther details are contained in the following reference -- if you use this dataset, please cite:\\r\\nMax A. Little, Patrick E. McSharry, Eric J. Hunter, Lorraine O. Ramig (2008), \\'Suitability of dysphonia measurements for telemonitoring of Parkinson\\'s disease\\', IEEE Transactions on Biomedical Engineering (to appear).', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': \"Matrix column entries (attributes):\\r\\nname - ASCII subject name and recording number\\r\\nMDVP:Fo(Hz) - Average vocal fundamental frequency\\r\\nMDVP:Fhi(Hz) - Maximum vocal fundamental frequency\\r\\nMDVP:Flo(Hz) - Minimum vocal fundamental frequency\\r\\nMDVP:Jitter(%),MDVP:Jitter(Abs),MDVP:RAP,MDVP:PPQ,Jitter:DDP - Several measures of variation in fundamental frequency\\r\\nMDVP:Shimmer,MDVP:Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,MDVP:APQ,Shimmer:DDA - Several measures of variation in amplitude\\r\\nNHR,HNR - Two measures of ratio of noise to tonal components in the voice\\r\\nstatus - Health status of the subject (one) - Parkinson's, (zero) - healthy\\r\\nRPDE,D2 - Two nonlinear dynamical complexity measures\\r\\nDFA - Signal fractal scaling exponent\\r\\nspread1,spread2,PPE - Three nonlinear measures of fundamental frequency variation\\r\\n\", 'citation': None}}\n",
      "            name     role         type demographic description units  \\\n",
      "0           name       ID  Categorical        None        None  None   \n",
      "1        MDVP:Fo  Feature   Continuous        None        None    Hz   \n",
      "2       MDVP:Fhi  Feature   Continuous        None        None    Hz   \n",
      "3       MDVP:Flo  Feature   Continuous        None        None    Hz   \n",
      "4    MDVP:Jitter  Feature   Continuous        None        None     %   \n",
      "5    MDVP:Jitter  Feature   Continuous        None        None   Abs   \n",
      "6       MDVP:RAP  Feature   Continuous        None        None  None   \n",
      "7       MDVP:PPQ  Feature   Continuous        None        None  None   \n",
      "8     Jitter:DDP  Feature   Continuous        None        None  None   \n",
      "9   MDVP:Shimmer  Feature   Continuous        None        None  None   \n",
      "10  MDVP:Shimmer  Feature   Continuous        None        None    dB   \n",
      "11  Shimmer:APQ3  Feature   Continuous        None        None  None   \n",
      "12  Shimmer:APQ5  Feature   Continuous        None        None  None   \n",
      "13      MDVP:APQ  Feature   Continuous        None        None  None   \n",
      "14   Shimmer:DDA  Feature   Continuous        None        None  None   \n",
      "15           NHR  Feature   Continuous        None        None  None   \n",
      "16           HNR  Feature   Continuous        None        None  None   \n",
      "17        status   Target      Integer        None        None  None   \n",
      "18          RPDE  Feature   Continuous        None        None  None   \n",
      "19           DFA  Feature   Continuous        None        None  None   \n",
      "20       spread1  Feature   Continuous        None        None  None   \n",
      "21       spread2  Feature   Continuous        None        None  None   \n",
      "22            D2  Feature   Continuous        None        None  None   \n",
      "23           PPE  Feature   Continuous        None        None  None   \n",
      "\n",
      "   missing_values  \n",
      "0              no  \n",
      "1              no  \n",
      "2              no  \n",
      "3              no  \n",
      "4              no  \n",
      "5              no  \n",
      "6              no  \n",
      "7              no  \n",
      "8              no  \n",
      "9              no  \n",
      "10             no  \n",
      "11             no  \n",
      "12             no  \n",
      "13             no  \n",
      "14             no  \n",
      "15             no  \n",
      "16             no  \n",
      "17             no  \n",
      "18             no  \n",
      "19             no  \n",
      "20             no  \n",
      "21             no  \n",
      "22             no  \n",
      "23             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "parkinsons = fetch_ucirepo(id=174) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = parkinsons.data.features \n",
    "y = parkinsons.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(parkinsons.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(parkinsons.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75bc48c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     MDVP:Fo  MDVP:Fhi  MDVP:Flo  MDVP:RAP  MDVP:PPQ  Jitter:DDP  \\\n",
       " 0    119.992   157.302    74.997   0.00370   0.00554     0.01109   \n",
       " 1    122.400   148.650   113.819   0.00465   0.00696     0.01394   \n",
       " 2    116.682   131.111   111.555   0.00544   0.00781     0.01633   \n",
       " 3    116.676   137.871   111.366   0.00502   0.00698     0.01505   \n",
       " 4    116.014   141.781   110.655   0.00655   0.00908     0.01966   \n",
       " ..       ...       ...       ...       ...       ...         ...   \n",
       " 190  174.188   230.978    94.261   0.00263   0.00259     0.00790   \n",
       " 191  209.516   253.017    89.488   0.00331   0.00292     0.00994   \n",
       " 192  174.688   240.005    74.287   0.00624   0.00564     0.01873   \n",
       " 193  198.764   396.961    74.904   0.00370   0.00390     0.01109   \n",
       " 194  214.289   260.277    77.973   0.00295   0.00317     0.00885   \n",
       " \n",
       "      Shimmer:APQ3  Shimmer:APQ5  MDVP:APQ  Shimmer:DDA      NHR     HNR  \\\n",
       " 0         0.02182       0.03130   0.02971      0.06545  0.02211  21.033   \n",
       " 1         0.03134       0.04518   0.04368      0.09403  0.01929  19.085   \n",
       " 2         0.02757       0.03858   0.03590      0.08270  0.01309  20.651   \n",
       " 3         0.02924       0.04005   0.03772      0.08771  0.01353  20.644   \n",
       " 4         0.03490       0.04825   0.04465      0.10470  0.01767  19.649   \n",
       " ..            ...           ...       ...          ...      ...     ...   \n",
       " 190       0.02336       0.02498   0.02745      0.07008  0.02764  19.517   \n",
       " 191       0.01604       0.01657   0.01879      0.04812  0.01810  19.147   \n",
       " 192       0.01268       0.01365   0.01667      0.03804  0.10715  17.883   \n",
       " 193       0.01265       0.01321   0.01588      0.03794  0.07223  19.020   \n",
       " 194       0.01026       0.01161   0.01373      0.03078  0.04398  21.209   \n",
       " \n",
       "          RPDE       DFA   spread1   spread2        D2       PPE  MDVP:Jitter  \\\n",
       " 0    0.414783  0.815285 -4.813031  0.266482  2.301442  0.284654      0.00784   \n",
       " 1    0.458359  0.819521 -4.075192  0.335590  2.486855  0.368674      0.00968   \n",
       " 2    0.429895  0.825288 -4.443179  0.311173  2.342259  0.332634      0.01050   \n",
       " 3    0.434969  0.819235 -4.117501  0.334147  2.405554  0.368975      0.00997   \n",
       " 4    0.417356  0.823484 -3.747787  0.234513  2.332180  0.410335      0.01284   \n",
       " ..        ...       ...       ...       ...       ...       ...          ...   \n",
       " 190  0.448439  0.657899 -6.538586  0.121952  2.657476  0.133050      0.00459   \n",
       " 191  0.431674  0.683244 -6.195325  0.129303  2.784312  0.168895      0.00564   \n",
       " 192  0.407567  0.655683 -6.787197  0.158453  2.679772  0.131728      0.01360   \n",
       " 193  0.451221  0.643956 -6.744577  0.207454  2.138608  0.123306      0.00740   \n",
       " 194  0.462803  0.664357 -5.724056  0.190667  2.555477  0.148569      0.00567   \n",
       " \n",
       "      MDVP:Shimmer  \n",
       " 0         0.04374  \n",
       " 1         0.06134  \n",
       " 2         0.05233  \n",
       " 3         0.05492  \n",
       " 4         0.06425  \n",
       " ..            ...  \n",
       " 190       0.04087  \n",
       " 191       0.02751  \n",
       " 192       0.02308  \n",
       " 193       0.02296  \n",
       " 194       0.01884  \n",
       " \n",
       " [195 rows x 20 columns],\n",
       "      status\n",
       " 0         1\n",
       " 1         1\n",
       " 2         1\n",
       " 3         1\n",
       " 4         1\n",
       " ..      ...\n",
       " 190       0\n",
       " 191       0\n",
       " 192       0\n",
       " 193       0\n",
       " 194       0\n",
       " \n",
       " [195 rows x 1 columns])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "clean_X = X.drop(columns=[\"MDVP:Jitter\", \"MDVP:Shimmer\"]).copy()\n",
    "clean_X[\"MDVP:Jitter\"] = X[\"MDVP:Jitter\"].values.T[0]\n",
    "clean_X[\"MDVP:Shimmer\"] = X[\"MDVP:Shimmer\"].values.T[0]\n",
    "\n",
    "\n",
    "for x in clean_X.columns:\n",
    "    if clean_X[x].dtype == 'object':\n",
    "        clean_X[x] = label_encoder.fit_transform(clean_X[x])\n",
    "\n",
    "clean_y = y.copy()\n",
    "for yc in clean_y.columns:\n",
    "    if clean_y[yc].dtype == 'object':\n",
    "        clean_y[yc] = label_encoder.fit_transform(clean_y[yc])\n",
    "        \n",
    "clean_X, clean_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3379aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_files:\n",
    "    clean_X.to_csv(\"3-PARKINS_X.csv\")\n",
    "    clean_y.to_csv(\"3-PARKINS_y.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037f6297",
   "metadata": {},
   "source": [
    "## 0.4. Thyroid: Missing labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3611f10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  age sex on thyroxine query on thyroxine on antithyroid medication sick  \\\n",
       " 0  41   F            f                  f                         f    f   \n",
       " 1  23   F            f                  f                         f    f   \n",
       " 2  46   M            f                  f                         f    f   \n",
       " 3  70   F            t                  f                         f    f   \n",
       " 4  70   F            f                  f                         f    f   \n",
       " \n",
       "   pregnant thyroid surgery I131 treatment query hypothyroid  ... TT4 measured  \\\n",
       " 0        f               f              f                 f  ...            t   \n",
       " 1        f               f              f                 f  ...            t   \n",
       " 2        f               f              f                 f  ...            t   \n",
       " 3        f               f              f                 f  ...            t   \n",
       " 4        f               f              f                 f  ...            t   \n",
       " \n",
       "    TT4 T4U measured   T4U FTI measured  FTI TBG measured TBG referral source  \\\n",
       " 0  125            t  1.14            t  109            f   ?            SVHC   \n",
       " 1  102            f     ?            f    ?            f   ?           other   \n",
       " 2  109            t  0.91            t  120            f   ?           other   \n",
       " 3  175            f     ?            f    ?            f   ?           other   \n",
       " 4   61            t  0.87            t   70            f   ?             SVI   \n",
       " \n",
       "   binaryClass  \n",
       " 0           P  \n",
       " 1           P  \n",
       " 2           P  \n",
       " 3           P  \n",
       " 4           P  \n",
       " \n",
       " [5 rows x 30 columns],\n",
       " Index(['age', 'sex', 'on thyroxine', 'query on thyroxine',\n",
       "        'on antithyroid medication', 'sick', 'pregnant', 'thyroid surgery',\n",
       "        'I131 treatment', 'query hypothyroid', 'query hyperthyroid', 'lithium',\n",
       "        'goitre', 'tumor', 'hypopituitary', 'psych', 'TSH measured', 'TSH',\n",
       "        'T3 measured', 'T3', 'TT4 measured', 'TT4', 'T4U measured', 'T4U',\n",
       "        'FTI measured', 'FTI', 'TBG measured', 'TBG', 'referral source',\n",
       "        'binaryClass'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "thyroid_csv_file = \"./thyroid/hypothyroid.csv\"\n",
    "df = pd.read_csv(thyroid_csv_file)\n",
    "\n",
    "df.head(), df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e6c63f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"binaryClass\"])\n",
    "y = df[\"binaryClass\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec18aa43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'f'}, {'?'})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(X[\"TBG measured\"]), set(X[\"TBG\"])  # Can drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e671317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>on thyroxine</th>\n",
       "      <th>query on thyroxine</th>\n",
       "      <th>on antithyroid medication</th>\n",
       "      <th>sick</th>\n",
       "      <th>pregnant</th>\n",
       "      <th>thyroid surgery</th>\n",
       "      <th>I131 treatment</th>\n",
       "      <th>query hypothyroid</th>\n",
       "      <th>...</th>\n",
       "      <th>TSH</th>\n",
       "      <th>T3 measured</th>\n",
       "      <th>T3</th>\n",
       "      <th>TT4 measured</th>\n",
       "      <th>TT4</th>\n",
       "      <th>T4U measured</th>\n",
       "      <th>T4U</th>\n",
       "      <th>FTI measured</th>\n",
       "      <th>FTI</th>\n",
       "      <th>referral source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3</td>\n",
       "      <td>t</td>\n",
       "      <td>2.5</td>\n",
       "      <td>t</td>\n",
       "      <td>125</td>\n",
       "      <td>t</td>\n",
       "      <td>1.14</td>\n",
       "      <td>t</td>\n",
       "      <td>109</td>\n",
       "      <td>SVHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>t</td>\n",
       "      <td>2</td>\n",
       "      <td>t</td>\n",
       "      <td>102</td>\n",
       "      <td>f</td>\n",
       "      <td>?</td>\n",
       "      <td>f</td>\n",
       "      <td>?</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>M</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>0.98</td>\n",
       "      <td>f</td>\n",
       "      <td>?</td>\n",
       "      <td>t</td>\n",
       "      <td>109</td>\n",
       "      <td>t</td>\n",
       "      <td>0.91</td>\n",
       "      <td>t</td>\n",
       "      <td>120</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>F</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16</td>\n",
       "      <td>t</td>\n",
       "      <td>1.9</td>\n",
       "      <td>t</td>\n",
       "      <td>175</td>\n",
       "      <td>f</td>\n",
       "      <td>?</td>\n",
       "      <td>f</td>\n",
       "      <td>?</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>0.72</td>\n",
       "      <td>t</td>\n",
       "      <td>1.2</td>\n",
       "      <td>t</td>\n",
       "      <td>61</td>\n",
       "      <td>t</td>\n",
       "      <td>0.87</td>\n",
       "      <td>t</td>\n",
       "      <td>70</td>\n",
       "      <td>SVI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3767</th>\n",
       "      <td>30</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>?</td>\n",
       "      <td>f</td>\n",
       "      <td>?</td>\n",
       "      <td>f</td>\n",
       "      <td>?</td>\n",
       "      <td>f</td>\n",
       "      <td>?</td>\n",
       "      <td>f</td>\n",
       "      <td>?</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3768</th>\n",
       "      <td>68</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>2.1</td>\n",
       "      <td>t</td>\n",
       "      <td>124</td>\n",
       "      <td>t</td>\n",
       "      <td>1.08</td>\n",
       "      <td>t</td>\n",
       "      <td>114</td>\n",
       "      <td>SVI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3769</th>\n",
       "      <td>74</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>5.1</td>\n",
       "      <td>t</td>\n",
       "      <td>1.8</td>\n",
       "      <td>t</td>\n",
       "      <td>112</td>\n",
       "      <td>t</td>\n",
       "      <td>1.07</td>\n",
       "      <td>t</td>\n",
       "      <td>105</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3770</th>\n",
       "      <td>72</td>\n",
       "      <td>M</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>t</td>\n",
       "      <td>2</td>\n",
       "      <td>t</td>\n",
       "      <td>82</td>\n",
       "      <td>t</td>\n",
       "      <td>0.94</td>\n",
       "      <td>t</td>\n",
       "      <td>87</td>\n",
       "      <td>SVI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3771</th>\n",
       "      <td>64</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>2.2</td>\n",
       "      <td>t</td>\n",
       "      <td>99</td>\n",
       "      <td>t</td>\n",
       "      <td>1.07</td>\n",
       "      <td>t</td>\n",
       "      <td>92</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3772 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age sex on thyroxine query on thyroxine on antithyroid medication sick  \\\n",
       "0     41   F            f                  f                         f    f   \n",
       "1     23   F            f                  f                         f    f   \n",
       "2     46   M            f                  f                         f    f   \n",
       "3     70   F            t                  f                         f    f   \n",
       "4     70   F            f                  f                         f    f   \n",
       "...   ..  ..          ...                ...                       ...  ...   \n",
       "3767  30   F            f                  f                         f    f   \n",
       "3768  68   F            f                  f                         f    f   \n",
       "3769  74   F            f                  f                         f    f   \n",
       "3770  72   M            f                  f                         f    f   \n",
       "3771  64   F            f                  f                         f    f   \n",
       "\n",
       "     pregnant thyroid surgery I131 treatment query hypothyroid  ...   TSH  \\\n",
       "0           f               f              f                 f  ...   1.3   \n",
       "1           f               f              f                 f  ...   4.1   \n",
       "2           f               f              f                 f  ...  0.98   \n",
       "3           f               f              f                 f  ...  0.16   \n",
       "4           f               f              f                 f  ...  0.72   \n",
       "...       ...             ...            ...               ...  ...   ...   \n",
       "3767        f               f              f                 f  ...     ?   \n",
       "3768        f               f              f                 f  ...     1   \n",
       "3769        f               f              f                 f  ...   5.1   \n",
       "3770        f               f              f                 f  ...   0.7   \n",
       "3771        f               f              f                 f  ...     1   \n",
       "\n",
       "     T3 measured   T3 TT4 measured  TT4 T4U measured   T4U FTI measured  FTI  \\\n",
       "0              t  2.5            t  125            t  1.14            t  109   \n",
       "1              t    2            t  102            f     ?            f    ?   \n",
       "2              f    ?            t  109            t  0.91            t  120   \n",
       "3              t  1.9            t  175            f     ?            f    ?   \n",
       "4              t  1.2            t   61            t  0.87            t   70   \n",
       "...          ...  ...          ...  ...          ...   ...          ...  ...   \n",
       "3767           f    ?            f    ?            f     ?            f    ?   \n",
       "3768           t  2.1            t  124            t  1.08            t  114   \n",
       "3769           t  1.8            t  112            t  1.07            t  105   \n",
       "3770           t    2            t   82            t  0.94            t   87   \n",
       "3771           t  2.2            t   99            t  1.07            t   92   \n",
       "\n",
       "     referral source  \n",
       "0               SVHC  \n",
       "1              other  \n",
       "2              other  \n",
       "3              other  \n",
       "4                SVI  \n",
       "...              ...  \n",
       "3767           other  \n",
       "3768             SVI  \n",
       "3769           other  \n",
       "3770             SVI  \n",
       "3771           other  \n",
       "\n",
       "[3772 rows x 27 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_X = X.drop(columns=[\"TBG measured\", \"TBG\"])\n",
    "\n",
    "clean_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e254f7",
   "metadata": {},
   "source": [
    "## 2. Music: 593, 6, 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "307bbae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   amazed-suprised  happy-pleased  relaxing-clam  quiet-still  sad-lonely  \\\n",
       " 0                0              1              1            0           0   \n",
       " 1                1              0              0            0           0   \n",
       " 2                0              1              0            0           0   \n",
       " 3                0              0              1            0           0   \n",
       " 4                0              0              0            1           0   \n",
       " \n",
       "    angry-aggresive  Mean_Acc1298_Mean_Mem40_Centroid  \\\n",
       " 0                0                          0.034741   \n",
       " 1                1                          0.081374   \n",
       " 2                1                          0.110545   \n",
       " 3                0                          0.042481   \n",
       " 4                0                          0.074550   \n",
       " \n",
       "    Mean_Acc1298_Mean_Mem40_Rolloff  Mean_Acc1298_Mean_Mem40_Flux  \\\n",
       " 0                         0.089665                      0.091225   \n",
       " 1                         0.272747                      0.085733   \n",
       " 2                         0.273567                      0.084410   \n",
       " 3                         0.199281                      0.093447   \n",
       " 4                         0.140880                      0.079789   \n",
       " \n",
       "    Mean_Acc1298_Mean_Mem40_MFCC_0  ...  Std_Acc1298_Std_Mem40_MFCC_11  \\\n",
       " 0                      -73.302422  ...                       0.118630   \n",
       " 1                      -62.584437  ...                       0.070075   \n",
       " 2                      -65.235325  ...                       0.079917   \n",
       " 3                      -80.305152  ...                       0.129145   \n",
       " 4                      -93.697749  ...                       0.284196   \n",
       " \n",
       "    Std_Acc1298_Std_Mem40_MFCC_12  BH_LowPeakAmp  BH_LowPeakBPM  \\\n",
       " 0                       0.094923       0.051035             68   \n",
       " 1                       0.041565       0.295031             70   \n",
       " 2                       0.085821       0.161574             61   \n",
       " 3                       0.122330       0.043012             66   \n",
       " 4                       0.189988       0.029308            100   \n",
       " \n",
       "    BH_HighPeakAmp  BH_HighPeakBPM  BH_HighLowRatio    BHSUM1    BHSUM2  \\\n",
       " 0        0.014937             136                2  0.245457  0.105065   \n",
       " 1        0.276366             140                2  0.343547  0.276366   \n",
       " 2        0.000000             183                3  0.188693  0.045941   \n",
       " 3        0.206562             132                2  0.102839  0.241934   \n",
       " 4        0.144039             200                2  0.195196  0.310801   \n",
       " \n",
       "      BHSUM3  \n",
       " 0  0.405399  \n",
       " 1  0.710924  \n",
       " 2  0.457372  \n",
       " 3  0.351009  \n",
       " 4  0.683817  \n",
       " \n",
       " [5 rows x 78 columns],\n",
       " Index(['amazed-suprised', 'happy-pleased', 'relaxing-clam', 'quiet-still',\n",
       "        'sad-lonely', 'angry-aggresive', 'Mean_Acc1298_Mean_Mem40_Centroid',\n",
       "        'Mean_Acc1298_Mean_Mem40_Rolloff', 'Mean_Acc1298_Mean_Mem40_Flux',\n",
       "        'Mean_Acc1298_Mean_Mem40_MFCC_0', 'Mean_Acc1298_Mean_Mem40_MFCC_1',\n",
       "        'Mean_Acc1298_Mean_Mem40_MFCC_2', 'Mean_Acc1298_Mean_Mem40_MFCC_3',\n",
       "        'Mean_Acc1298_Mean_Mem40_MFCC_4', 'Mean_Acc1298_Mean_Mem40_MFCC_5',\n",
       "        'Mean_Acc1298_Mean_Mem40_MFCC_6', 'Mean_Acc1298_Mean_Mem40_MFCC_7',\n",
       "        'Mean_Acc1298_Mean_Mem40_MFCC_8', 'Mean_Acc1298_Mean_Mem40_MFCC_9',\n",
       "        'Mean_Acc1298_Mean_Mem40_MFCC_10', 'Mean_Acc1298_Mean_Mem40_MFCC_11',\n",
       "        'Mean_Acc1298_Mean_Mem40_MFCC_12', 'Mean_Acc1298_Std_Mem40_Centroid',\n",
       "        'Mean_Acc1298_Std_Mem40_Rolloff', 'Mean_Acc1298_Std_Mem40_Flux',\n",
       "        'Mean_Acc1298_Std_Mem40_MFCC_0', 'Mean_Acc1298_Std_Mem40_MFCC_1',\n",
       "        'Mean_Acc1298_Std_Mem40_MFCC_2', 'Mean_Acc1298_Std_Mem40_MFCC_3',\n",
       "        'Mean_Acc1298_Std_Mem40_MFCC_4', 'Mean_Acc1298_Std_Mem40_MFCC_5',\n",
       "        'Mean_Acc1298_Std_Mem40_MFCC_6', 'Mean_Acc1298_Std_Mem40_MFCC_7',\n",
       "        'Mean_Acc1298_Std_Mem40_MFCC_8', 'Mean_Acc1298_Std_Mem40_MFCC_9',\n",
       "        'Mean_Acc1298_Std_Mem40_MFCC_10', 'Mean_Acc1298_Std_Mem40_MFCC_11',\n",
       "        'Mean_Acc1298_Std_Mem40_MFCC_12', 'Std_Acc1298_Mean_Mem40_Centroid',\n",
       "        'Std_Acc1298_Mean_Mem40_Rolloff', 'Std_Acc1298_Mean_Mem40_Flux',\n",
       "        'Std_Acc1298_Mean_Mem40_MFCC_0', 'Std_Acc1298_Mean_Mem40_MFCC_1',\n",
       "        'Std_Acc1298_Mean_Mem40_MFCC_2', 'Std_Acc1298_Mean_Mem40_MFCC_3',\n",
       "        'Std_Acc1298_Mean_Mem40_MFCC_4', 'Std_Acc1298_Mean_Mem40_MFCC_5',\n",
       "        'Std_Acc1298_Mean_Mem40_MFCC_6', 'Std_Acc1298_Mean_Mem40_MFCC_7',\n",
       "        'Std_Acc1298_Mean_Mem40_MFCC_8', 'Std_Acc1298_Mean_Mem40_MFCC_9',\n",
       "        'Std_Acc1298_Mean_Mem40_MFCC_10', 'Std_Acc1298_Mean_Mem40_MFCC_11',\n",
       "        'Std_Acc1298_Mean_Mem40_MFCC_12', 'Std_Acc1298_Std_Mem40_Centroid',\n",
       "        'Std_Acc1298_Std_Mem40_Rolloff', 'Std_Acc1298_Std_Mem40_Flux',\n",
       "        'Std_Acc1298_Std_Mem40_MFCC_0', 'Std_Acc1298_Std_Mem40_MFCC_1',\n",
       "        'Std_Acc1298_Std_Mem40_MFCC_2', 'Std_Acc1298_Std_Mem40_MFCC_3',\n",
       "        'Std_Acc1298_Std_Mem40_MFCC_4', 'Std_Acc1298_Std_Mem40_MFCC_5',\n",
       "        'Std_Acc1298_Std_Mem40_MFCC_6', 'Std_Acc1298_Std_Mem40_MFCC_7',\n",
       "        'Std_Acc1298_Std_Mem40_MFCC_8', 'Std_Acc1298_Std_Mem40_MFCC_9',\n",
       "        'Std_Acc1298_Std_Mem40_MFCC_10', 'Std_Acc1298_Std_Mem40_MFCC_11',\n",
       "        'Std_Acc1298_Std_Mem40_MFCC_12', 'BH_LowPeakAmp', 'BH_LowPeakBPM',\n",
       "        'BH_HighPeakAmp', 'BH_HighPeakBPM', 'BH_HighLowRatio', 'BHSUM1',\n",
       "        'BHSUM2', 'BHSUM3'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./datasets/2-EMOT.csv\")\n",
    "\n",
    "df.head(), df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "969fa488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['amazed-suprised', 'happy-pleased', 'relaxing-clam', 'quiet-still',\n",
       "       'sad-lonely', 'angry-aggresive'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = df.columns[:6]\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b0f8ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     Mean_Acc1298_Mean_Mem40_Centroid  Mean_Acc1298_Mean_Mem40_Rolloff  \\\n",
       " 0                            0.034741                         0.089665   \n",
       " 1                            0.081374                         0.272747   \n",
       " 2                            0.110545                         0.273567   \n",
       " 3                            0.042481                         0.199281   \n",
       " 4                            0.074550                         0.140880   \n",
       " ..                                ...                              ...   \n",
       " 588                          0.027142                         0.047551   \n",
       " 589                          0.094829                         0.204498   \n",
       " 590                          0.035169                         0.065403   \n",
       " 591                          0.054276                         0.238158   \n",
       " 592                          0.073194                         0.140733   \n",
       " \n",
       "      Mean_Acc1298_Mean_Mem40_Flux  Mean_Acc1298_Mean_Mem40_MFCC_0  \\\n",
       " 0                        0.091225                      -73.302422   \n",
       " 1                        0.085733                      -62.584437   \n",
       " 2                        0.084410                      -65.235325   \n",
       " 3                        0.093447                      -80.305152   \n",
       " 4                        0.079789                      -93.697749   \n",
       " ..                            ...                             ...   \n",
       " 588                      0.072043                      -79.881347   \n",
       " 589                      0.082824                      -61.364436   \n",
       " 590                      0.075227                      -81.750533   \n",
       " 591                      0.095935                      -71.009724   \n",
       " 592                      0.080545                      -74.517081   \n",
       " \n",
       "      Mean_Acc1298_Mean_Mem40_MFCC_1  Mean_Acc1298_Mean_Mem40_MFCC_2  \\\n",
       " 0                          6.215179                        0.615074   \n",
       " 1                          3.183163                       -0.218145   \n",
       " 2                          2.794964                        0.639047   \n",
       " 3                          5.824409                        0.648848   \n",
       " 4                          5.543229                        1.064262   \n",
       " ..                              ...                             ...   \n",
       " 588                        8.119313                        1.927310   \n",
       " 589                        2.966229                        0.627740   \n",
       " 590                       10.311701                        0.092224   \n",
       " 591                        3.181340                        1.547197   \n",
       " 592                        6.945590                       -1.047953   \n",
       " \n",
       "      Mean_Acc1298_Mean_Mem40_MFCC_3  Mean_Acc1298_Mean_Mem40_MFCC_4  \\\n",
       " 0                          2.037160                        0.804065   \n",
       " 1                          0.163038                        0.620251   \n",
       " 2                          1.281297                        0.757896   \n",
       " 3                          1.754870                        1.495532   \n",
       " 4                          0.899152                        0.890336   \n",
       " ..                              ...                             ...   \n",
       " 588                        1.696017                        0.397888   \n",
       " 589                        1.440352                        0.856243   \n",
       " 590                        0.818851                        1.569606   \n",
       " 591                        2.407780                        0.618838   \n",
       " 592                        1.952278                        0.341936   \n",
       " \n",
       "      Mean_Acc1298_Mean_Mem40_MFCC_5  Mean_Acc1298_Mean_Mem40_MFCC_6  ...  \\\n",
       " 0                          1.301409                        0.558576  ...   \n",
       " 1                          0.458514                        0.041426  ...   \n",
       " 2                          0.489412                        0.627636  ...   \n",
       " 3                          0.739909                        0.809644  ...   \n",
       " 4                          0.702328                        0.490685  ...   \n",
       " ..                              ...                             ...  ...   \n",
       " 588                        0.857559                        0.302742  ...   \n",
       " 589                        1.110282                        0.394450  ...   \n",
       " 590                        1.831909                        0.057216  ...   \n",
       " 591                        0.997950                        0.825143  ...   \n",
       " 592                        0.770582                        0.144989  ...   \n",
       " \n",
       "      Std_Acc1298_Std_Mem40_MFCC_11  Std_Acc1298_Std_Mem40_MFCC_12  \\\n",
       " 0                         0.118630                       0.094923   \n",
       " 1                         0.070075                       0.041565   \n",
       " 2                         0.079917                       0.085821   \n",
       " 3                         0.129145                       0.122330   \n",
       " 4                         0.284196                       0.189988   \n",
       " ..                             ...                            ...   \n",
       " 588                       0.129552                       0.106260   \n",
       " 589                       0.128090                       0.167160   \n",
       " 590                       0.147194                       0.098238   \n",
       " 591                       0.080006                       0.058181   \n",
       " 592                       0.073605                       0.081219   \n",
       " \n",
       "      BH_LowPeakAmp  BH_LowPeakBPM  BH_HighPeakAmp  BH_HighPeakBPM  \\\n",
       " 0         0.051035             68        0.014937             136   \n",
       " 1         0.295031             70        0.276366             140   \n",
       " 2         0.161574             61        0.000000             183   \n",
       " 3         0.043012             66        0.206562             132   \n",
       " 4         0.029308            100        0.144039             200   \n",
       " ..             ...            ...             ...             ...   \n",
       " 588       0.089991             87        0.564842             174   \n",
       " 589       0.035827             65        0.003942             130   \n",
       " 590       0.033681             88        0.000000             176   \n",
       " 591       0.155650             84        0.276695             168   \n",
       " 592       0.056101             94        0.007080             188   \n",
       " \n",
       "      BH_HighLowRatio    BHSUM1    BHSUM2    BHSUM3  \n",
       " 0                  2  0.245457  0.105065  0.405399  \n",
       " 1                  2  0.343547  0.276366  0.710924  \n",
       " 2                  3  0.188693  0.045941  0.457372  \n",
       " 3                  2  0.102839  0.241934  0.351009  \n",
       " 4                  2  0.195196  0.310801  0.683817  \n",
       " ..               ...       ...       ...       ...  \n",
       " 588                2  0.261742  0.002657  1.149211  \n",
       " 589                2  0.282122  0.052218  0.335371  \n",
       " 590                2  0.184313  0.247136  0.476993  \n",
       " 591                2  0.547126  0.183494  1.255820  \n",
       " 592                2  0.087328  0.236815  0.451701  \n",
       " \n",
       " [593 rows x 72 columns],\n",
       "      amazed-suprised  happy-pleased  relaxing-clam  quiet-still  sad-lonely  \\\n",
       " 0                  0              1              1            0           0   \n",
       " 1                  1              0              0            0           0   \n",
       " 2                  0              1              0            0           0   \n",
       " 3                  0              0              1            0           0   \n",
       " 4                  0              0              0            1           0   \n",
       " ..               ...            ...            ...          ...         ...   \n",
       " 588                0              0              1            1           1   \n",
       " 589                1              0              0            0           1   \n",
       " 590                0              0              1            1           1   \n",
       " 591                0              1              1            0           0   \n",
       " 592                0              1              0            0           0   \n",
       " \n",
       "      angry-aggresive  \n",
       " 0                  0  \n",
       " 1                  1  \n",
       " 2                  1  \n",
       " 3                  0  \n",
       " 4                  0  \n",
       " ..               ...  \n",
       " 588                0  \n",
       " 589                1  \n",
       " 590                0  \n",
       " 591                0  \n",
       " 592                0  \n",
       " \n",
       " [593 rows x 6 columns])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=targets)\n",
    "y = df[targets]\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54e5e4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_files:\n",
    "    X.to_csv(\"./data/2-EMOT_X.csv\")\n",
    "    y.to_csv(\"./data/2-EMOT_y.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1dcefe",
   "metadata": {},
   "source": [
    "## 3. Scence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fcaace8b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   beach  sunset  foliage  field  mountain  urban      Att1      Att2  \\\n",
       " 0      1       0        0      0         1      0  0.646467  0.666435   \n",
       " 1      1       0        0      0         0      1  0.770156  0.767255   \n",
       " 2      1       0        0      0         0      0  0.793984  0.772096   \n",
       " 3      1       0        0      0         0      0  0.938563  0.949260   \n",
       " 4      1       0        0      0         0      0  0.512130  0.524684   \n",
       " \n",
       "        Att3      Att4  ...    Att285    Att286    Att287    Att288    Att289  \\\n",
       " 0  0.685047  0.699053  ...  0.061538  0.049615  0.068962  0.653879  0.354982   \n",
       " 1  0.761053  0.745630  ...  0.114123  0.160008  0.414088  0.361843  0.303399   \n",
       " 2  0.761820  0.762213  ...  0.047596  0.038082  0.079977  0.004901  0.003460   \n",
       " 3  0.955621  0.966743  ...  0.027527  0.016922  0.024174  0.036799  0.007694   \n",
       " 4  0.520020  0.504467  ...  0.158730  0.023177  0.129994  0.167709  0.226580   \n",
       " \n",
       "      Att290    Att291    Att292    Att293    Att294  \n",
       " 0  0.124074  0.157332  0.247298  0.014025  0.029709  \n",
       " 1  0.176387  0.251454  0.137833  0.082672  0.036320  \n",
       " 2  0.006049  0.017166  0.051125  0.112506  0.083924  \n",
       " 3  0.009735  0.019267  0.031290  0.049780  0.090959  \n",
       " 4  0.218534  0.198151  0.238796  0.164270  0.184290  \n",
       " \n",
       " [5 rows x 300 columns],\n",
       " Index(['beach', 'sunset', 'foliage', 'field', 'mountain', 'urban', 'Att1',\n",
       "        'Att2', 'Att3', 'Att4',\n",
       "        ...\n",
       "        'Att285', 'Att286', 'Att287', 'Att288', 'Att289', 'Att290', 'Att291',\n",
       "        'Att292', 'Att293', 'Att294'],\n",
       "       dtype='object', length=300))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./datasets/3-SCENE.csv\")\n",
    "\n",
    "df.head(), df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d28f3e2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(          Att1      Att2      Att3      Att4      Att5      Att6      Att7  \\\n",
       " 0     0.646467  0.666435  0.685047  0.699053  0.652746  0.407864  0.150309   \n",
       " 1     0.770156  0.767255  0.761053  0.745630  0.742231  0.688086  0.708416   \n",
       " 2     0.793984  0.772096  0.761820  0.762213  0.740569  0.734361  0.722677   \n",
       " 3     0.938563  0.949260  0.955621  0.966743  0.968649  0.869619  0.696925   \n",
       " 4     0.512130  0.524684  0.520020  0.504467  0.471209  0.417654  0.364292   \n",
       " ...        ...       ...       ...       ...       ...       ...       ...   \n",
       " 2402  0.875782  0.901653  0.926227  0.721366  0.795826  0.867642  0.794125   \n",
       " 2403  0.657706  0.669877  0.692338  0.713920  0.727374  0.750354  0.684372   \n",
       " 2404  0.952281  0.944987  0.905556  0.836604  0.875916  0.957034  0.953938   \n",
       " 2405  0.883990  0.899004  0.901019  0.904298  0.846402  0.858145  0.851362   \n",
       " 2406  0.974915  0.866425  0.818144  0.936140  0.938583  0.935087  0.930597   \n",
       " \n",
       "           Att8      Att9     Att10  ...    Att285    Att286    Att287  \\\n",
       " 0     0.535193  0.555689  0.580782  ...  0.061538  0.049615  0.068962   \n",
       " 1     0.757351  0.760633  0.740314  ...  0.114123  0.160008  0.414088   \n",
       " 2     0.849128  0.839607  0.812746  ...  0.047596  0.038082  0.079977   \n",
       " 3     0.953460  0.959631  0.966320  ...  0.027527  0.016922  0.024174   \n",
       " 4     0.562266  0.588592  0.584449  ...  0.158730  0.023177  0.129994   \n",
       " ...        ...       ...       ...  ...       ...       ...       ...   \n",
       " 2402  0.899067  0.908963  0.895336  ...  0.070152  0.061081  0.121834   \n",
       " 2403  0.718770  0.719916  0.730645  ...  0.047577  0.079166  0.034408   \n",
       " 2404  0.967956  0.819636  0.707311  ...  0.039668  0.050678  0.020770   \n",
       " 2405  0.852472  0.876665  0.908187  ...  0.168355  0.111811  0.148926   \n",
       " 2406  1.000000  0.806074  0.717955  ...  0.003132  0.002082  0.001343   \n",
       " \n",
       "         Att288    Att289    Att290    Att291    Att292    Att293    Att294  \n",
       " 0     0.653879  0.354982  0.124074  0.157332  0.247298  0.014025  0.029709  \n",
       " 1     0.361843  0.303399  0.176387  0.251454  0.137833  0.082672  0.036320  \n",
       " 2     0.004901  0.003460  0.006049  0.017166  0.051125  0.112506  0.083924  \n",
       " 3     0.036799  0.007694  0.009735  0.019267  0.031290  0.049780  0.090959  \n",
       " 4     0.167709  0.226580  0.218534  0.198151  0.238796  0.164270  0.184290  \n",
       " ...        ...       ...       ...       ...       ...       ...       ...  \n",
       " 2402  0.378950  0.366901  0.211351  0.215147  0.279607  0.254413  0.134350  \n",
       " 2403  0.095084  0.025579  0.013329  0.217201  0.199491  0.048747  0.041638  \n",
       " 2404  0.022791  0.033978  0.023563  0.028002  0.031900  0.017547  0.019734  \n",
       " 2405  0.097985  0.361665  0.200352  0.239041  0.256158  0.226332  0.223070  \n",
       " 2406  0.151318  0.061375  0.072015  0.073742  0.005131  0.025059  0.004033  \n",
       " \n",
       " [2407 rows x 294 columns],\n",
       "       beach  sunset  foliage  field  mountain  urban\n",
       " 0         1       0        0      0         1      0\n",
       " 1         1       0        0      0         0      1\n",
       " 2         1       0        0      0         0      0\n",
       " 3         1       0        0      0         0      0\n",
       " 4         1       0        0      0         0      0\n",
       " ...     ...     ...      ...    ...       ...    ...\n",
       " 2402      0       0        0      0         0      1\n",
       " 2403      0       0        0      0         0      1\n",
       " 2404      0       0        0      0         0      1\n",
       " 2405      0       0        0      0         0      1\n",
       " 2406      0       0        0      0         0      1\n",
       " \n",
       " [2407 rows x 6 columns])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = df.columns[df.columns.str.startswith('Att')]\n",
    "\n",
    "X = df[columns]\n",
    "y = df.drop(columns=columns)\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8636920d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_files:\n",
    "    X.to_csv(\"./data/3-SCENE_X.csv\")\n",
    "    y.to_csv(\"./data/3-SCENE_y.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69343255",
   "metadata": {},
   "source": [
    "## 4. Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63bc31e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  landmass zone    area  population language religion  bars  stripes  colours  \\\n",
       " 0        5    1   648.0        16.0       10        2   0.0      3.0      5.0   \n",
       " 1        3    1    29.0         3.0        6        6   0.0      0.0      3.0   \n",
       " 2        4    1  2388.0        20.0        8        2   2.0      0.0      3.0   \n",
       " 3        6    3     0.0         0.0        1        1   0.0      0.0      5.0   \n",
       " 4        3    1     0.0         0.0        6        0   3.0      0.0      3.0   \n",
       " \n",
       "    circles  ...  icon  animate  text  red green blue yellow white black orange  \n",
       " 0      0.0  ...     1        0     0    1     1    0      1     1     1      0  \n",
       " 1      0.0  ...     0        1     0    1     0    0      1     0     1      0  \n",
       " 2      0.0  ...     0        0     0    1     1    0      0     1     0      0  \n",
       " 3      0.0  ...     1        1     0    1     0    1      1     1     0      1  \n",
       " 4      0.0  ...     0        0     0    1     0    1      1     0     0      0  \n",
       " \n",
       " [5 rows x 26 columns],\n",
       " Index(['landmass', 'zone', 'area', 'population', 'language', 'religion',\n",
       "        'bars', 'stripes', 'colours', 'circles', 'crosses', 'saltires',\n",
       "        'quarters', 'sunstars', 'crescent', 'triangle', 'icon', 'animate',\n",
       "        'text', 'red', 'green', 'blue', 'yellow', 'white', 'black', 'orange'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "flags_raw_file_name = './flags/flags.arff'\n",
    "assert(os.path.isfile(flags_raw_file_name))\n",
    "\n",
    "# Load ARFF file\n",
    "data, meta = arff.loadarff(flags_raw_file_name,)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Optionally, decode byte strings to regular strings if necessary\n",
    "df = df.applymap(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
    "\n",
    "df.head(), df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5471109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(    landmass zone    area  population language religion  bars  stripes  \\\n",
       " 0          5    1   648.0        16.0       10        2   0.0      3.0   \n",
       " 1          3    1    29.0         3.0        6        6   0.0      0.0   \n",
       " 2          4    1  2388.0        20.0        8        2   2.0      0.0   \n",
       " 3          6    3     0.0         0.0        1        1   0.0      0.0   \n",
       " 4          3    1     0.0         0.0        6        0   3.0      0.0   \n",
       " ..       ...  ...     ...         ...      ...      ...   ...      ...   \n",
       " 189        6    3     3.0         0.0        1        1   0.0      0.0   \n",
       " 190        3    1   256.0        22.0        6        6   0.0      3.0   \n",
       " 191        4    2   905.0        28.0       10        5   0.0      0.0   \n",
       " 192        4    2   753.0         6.0       10        5   3.0      0.0   \n",
       " 193        4    2   391.0         8.0       10        5   0.0      7.0   \n",
       " \n",
       "      colours  circles  crosses  saltires  quarters  sunstars crescent  \\\n",
       " 0        5.0      0.0      0.0       0.0       0.0       1.0        0   \n",
       " 1        3.0      0.0      0.0       0.0       0.0       1.0        0   \n",
       " 2        3.0      0.0      0.0       0.0       0.0       1.0        1   \n",
       " 3        5.0      0.0      0.0       0.0       0.0       0.0        0   \n",
       " 4        3.0      0.0      0.0       0.0       0.0       0.0        0   \n",
       " ..       ...      ...      ...       ...       ...       ...      ...   \n",
       " 189      3.0      0.0      0.0       0.0       1.0       5.0        0   \n",
       " 190      4.0      0.0      0.0       0.0       0.0       1.0        0   \n",
       " 191      4.0      1.0      0.0       0.0       0.0       0.0        0   \n",
       " 192      4.0      0.0      0.0       0.0       0.0       0.0        0   \n",
       " 193      5.0      0.0      0.0       0.0       0.0       1.0        0   \n",
       " \n",
       "     triangle icon animate text  \n",
       " 0          0    1       0    0  \n",
       " 1          0    0       1    0  \n",
       " 2          0    0       0    0  \n",
       " 3          1    1       1    0  \n",
       " 4          0    0       0    0  \n",
       " ..       ...  ...     ...  ...  \n",
       " 189        0    0       0    0  \n",
       " 190        0    0       0    0  \n",
       " 191        0    1       1    0  \n",
       " 192        0    0       1    0  \n",
       " 193        1    1       1    0  \n",
       " \n",
       " [194 rows x 19 columns],\n",
       "     red green blue yellow white black orange\n",
       " 0     1     1    0      1     1     1      0\n",
       " 1     1     0    0      1     0     1      0\n",
       " 2     1     1    0      0     1     0      0\n",
       " 3     1     0    1      1     1     0      1\n",
       " 4     1     0    1      1     0     0      0\n",
       " ..   ..   ...  ...    ...   ...   ...    ...\n",
       " 189   1     0    1      0     1     0      0\n",
       " 190   1     0    1      1     1     0      0\n",
       " 191   1     1    0      1     0     0      1\n",
       " 192   1     1    0      0     0     1      1\n",
       " 193   1     1    0      1     1     1      0\n",
       " \n",
       " [194 rows x 7 columns])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\"red\", \"green\", \"blue\", \"yellow\", 'white', 'black', \"orange\"]\n",
    "\n",
    "X = df.drop(columns=columns)\n",
    "y = df[columns]\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4bd7457",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_files:\n",
    "    X.to_csv(\"./data/4-FLAGS_X.csv\")\n",
    "    y.to_csv(\"./data/4-FLAGS_y.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0fe38c",
   "metadata": {},
   "source": [
    "# 5. Foodtruck: N = 407, L = 12, d = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9034a2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   frequency       time  expenses      motivation  taste  hygiene  menu  \\\n",
       " 0        2.0     dinner      30.0          friend    5.0      4.0   4.0   \n",
       " 1        0.0     dinner      20.0       by_chance    5.0      2.0   4.0   \n",
       " 2        1.0  afternoon      15.0       by_chance    5.0      2.0   2.0   \n",
       " 3        0.0      lunch      40.0          friend    5.0      5.0   4.0   \n",
       " 4        0.0     dinner      15.0  social_network    5.0      4.0   2.0   \n",
       " \n",
       "    presentation  attendance  ingredients  ...  italian_food  brazilian_food  \\\n",
       " 0           3.0         4.0          4.0  ...             0               0   \n",
       " 1           4.0         4.0          4.0  ...             1               0   \n",
       " 2           5.0         3.0          5.0  ...             0               1   \n",
       " 3           3.0         4.0          4.0  ...             0               0   \n",
       " 4           3.0         4.0          4.0  ...             0               0   \n",
       " \n",
       "    mexican_food  chinese_food  japanese_food arabic_food  snacks  \\\n",
       " 0             0             0              0           0       0   \n",
       " 1             1             0              0           0       0   \n",
       " 2             0             0              0           0       0   \n",
       " 3             0             0              0           0       0   \n",
       " 4             0             0              0           0       0   \n",
       " \n",
       "    healthy_food  fitness_food  sweets_desserts  \n",
       " 0             0             0                1  \n",
       " 1             0             0                1  \n",
       " 2             0             0                0  \n",
       " 3             0             0                0  \n",
       " 4             0             0                0  \n",
       " \n",
       " [5 rows x 33 columns],\n",
       " Index(['frequency', 'time', 'expenses', 'motivation', 'taste', 'hygiene',\n",
       "        'menu', 'presentation', 'attendance', 'ingredients', 'place.to.sit',\n",
       "        'takeaway', 'variation', 'stop.strucks', 'schedule', 'gender',\n",
       "        'age.group', 'scholarity', 'average.income', 'has.work',\n",
       "        'marital.status', 'street_food', 'gourmet', 'italian_food',\n",
       "        'brazilian_food', 'mexican_food', 'chinese_food', 'japanese_food',\n",
       "        'arabic_food', 'snacks', 'healthy_food', 'fitness_food',\n",
       "        'sweets_desserts'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "mediamill_raw_file_name = './foodtruck/foodtruck.arff'\n",
    "assert(os.path.isfile(mediamill_raw_file_name))\n",
    "\n",
    "# Load ARFF file\n",
    "data, meta = arff.loadarff(mediamill_raw_file_name,)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Optionally, decode byte strings to regular strings if necessary\n",
    "df = df.applymap(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
    "\n",
    "df.head(), df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "662420fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     frequency       time  expenses      motivation  taste  hygiene  menu  \\\n",
       " 0          2.0     dinner      30.0          friend    5.0      4.0   4.0   \n",
       " 1          0.0     dinner      20.0       by_chance    5.0      2.0   4.0   \n",
       " 2          1.0  afternoon      15.0       by_chance    5.0      2.0   2.0   \n",
       " 3          0.0      lunch      40.0          friend    5.0      5.0   4.0   \n",
       " 4          0.0     dinner      15.0  social_network    5.0      4.0   2.0   \n",
       " ..         ...        ...       ...             ...    ...      ...   ...   \n",
       " 402        0.0     dinner      30.0          friend    5.0      5.0   5.0   \n",
       " 403        0.0     dinner      30.0  social_network    5.0      5.0   4.0   \n",
       " 404        0.0     dinner      30.0  social_network    5.0      5.0   4.0   \n",
       " 405        1.0     dinner      30.0  social_network    5.0      4.0   4.0   \n",
       " 406        0.0     dinner      15.0          friend    4.0      4.0   5.0   \n",
       " \n",
       "      presentation  attendance  ingredients  ...  takeaway  variation  \\\n",
       " 0             3.0         4.0          4.0  ...       3.0        3.0   \n",
       " 1             4.0         4.0          4.0  ...       2.0        3.0   \n",
       " 2             5.0         3.0          5.0  ...       2.0        2.0   \n",
       " 3             3.0         4.0          4.0  ...       4.0        5.0   \n",
       " 4             3.0         4.0          4.0  ...       3.0        4.0   \n",
       " ..            ...         ...          ...  ...       ...        ...   \n",
       " 402           5.0         5.0          5.0  ...       3.0        3.0   \n",
       " 403           3.0         4.0          4.0  ...       3.0        4.0   \n",
       " 404           5.0         5.0          5.0  ...       2.0        4.0   \n",
       " 405           4.0         4.0          5.0  ...       3.0        4.0   \n",
       " 406           2.0         4.0          4.0  ...       4.0        4.0   \n",
       " \n",
       "      stop.strucks  schedule  gender age.group  scholarity  average.income  \\\n",
       " 0             2.0       2.0       M       2.0         1.5             4.0   \n",
       " 1             1.0       4.0       F       3.0         2.0             5.0   \n",
       " 2             2.0       1.0       M       2.0         1.5             4.0   \n",
       " 3             1.0       1.0       M       3.0         2.0             6.0   \n",
       " 4             1.0       1.0       M       2.0         1.5             4.0   \n",
       " ..            ...       ...     ...       ...         ...             ...   \n",
       " 402           3.0       4.0       F       3.0         2.0             3.0   \n",
       " 403           5.0       4.0       F       1.0         1.0             4.0   \n",
       " 404           3.0       2.0       M       2.0         2.0             1.0   \n",
       " 405           5.0       4.0       M       3.0         1.5             2.0   \n",
       " 406           4.0       4.0       M       1.0         0.0             1.0   \n",
       " \n",
       "      has.work  marital.status  \n",
       " 0         0.0          single  \n",
       " 1         1.0         married  \n",
       " 2         1.0          single  \n",
       " 3         1.0          single  \n",
       " 4         1.0          single  \n",
       " ..        ...             ...  \n",
       " 402       1.0          single  \n",
       " 403       0.0          single  \n",
       " 404       1.0          single  \n",
       " 405       1.0         married  \n",
       " 406       0.0          single  \n",
       " \n",
       " [407 rows x 21 columns],\n",
       "     gourmet snacks street_food italian_food brazilian_food mexican_food  \\\n",
       " 0         0      0           1            0              0            0   \n",
       " 1         0      0           1            1              0            1   \n",
       " 2         0      0           1            0              1            0   \n",
       " 3         1      0           0            0              0            0   \n",
       " 4         0      0           1            0              0            0   \n",
       " ..      ...    ...         ...          ...            ...          ...   \n",
       " 402       0      0           1            0              0            0   \n",
       " 403       1      0           1            0              0            0   \n",
       " 404       0      0           1            0              0            0   \n",
       " 405       1      1           1            1              1            1   \n",
       " 406       0      1           0            0              0            0   \n",
       " \n",
       "     chinese_food japanese_food arabic_food healthy_food fitness_food  \\\n",
       " 0              0             0           0            0            0   \n",
       " 1              0             0           0            0            0   \n",
       " 2              0             0           0            0            0   \n",
       " 3              0             0           0            0            0   \n",
       " 4              0             0           0            0            0   \n",
       " ..           ...           ...         ...          ...          ...   \n",
       " 402            0             0           0            0            0   \n",
       " 403            0             0           0            0            0   \n",
       " 404            0             0           0            0            0   \n",
       " 405            1             1           1            0            0   \n",
       " 406            0             0           0            0            0   \n",
       " \n",
       "     sweets_desserts  \n",
       " 0                 1  \n",
       " 1                 1  \n",
       " 2                 0  \n",
       " 3                 0  \n",
       " 4                 0  \n",
       " ..              ...  \n",
       " 402               0  \n",
       " 403               1  \n",
       " 404               1  \n",
       " 405               1  \n",
       " 406               0  \n",
       " \n",
       " [407 rows x 12 columns])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['gourmet', 'snacks', 'street_food', 'italian_food',\n",
    "           'brazilian_food', 'mexican_food', 'chinese_food','japanese_food',\n",
    "           'arabic_food', 'healthy_food', 'fitness_food', 'sweets_desserts']\n",
    "\n",
    "X = df.drop(columns=columns)\n",
    "y = df[columns]\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "acda8e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_files:\n",
    "    X.to_csv(\"./data/5-FOODTRUCK_X.csv\")\n",
    "    y.to_csv(\"./data/5-FOODTRUCK_y.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfff6e10",
   "metadata": {},
   "source": [
    "## 6. Yeast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6dfb0485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Att1</th>\n",
       "      <th>Att2</th>\n",
       "      <th>Att3</th>\n",
       "      <th>Att4</th>\n",
       "      <th>Att5</th>\n",
       "      <th>Att6</th>\n",
       "      <th>Att7</th>\n",
       "      <th>Att8</th>\n",
       "      <th>Att9</th>\n",
       "      <th>Att10</th>\n",
       "      <th>...</th>\n",
       "      <th>Class5</th>\n",
       "      <th>Class6</th>\n",
       "      <th>Class7</th>\n",
       "      <th>Class8</th>\n",
       "      <th>Class9</th>\n",
       "      <th>Class10</th>\n",
       "      <th>Class11</th>\n",
       "      <th>Class12</th>\n",
       "      <th>Class13</th>\n",
       "      <th>Class14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004168</td>\n",
       "      <td>-0.170975</td>\n",
       "      <td>-0.156748</td>\n",
       "      <td>-0.142151</td>\n",
       "      <td>0.058781</td>\n",
       "      <td>0.026851</td>\n",
       "      <td>0.197719</td>\n",
       "      <td>0.041850</td>\n",
       "      <td>0.066938</td>\n",
       "      <td>-0.056617</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.103956</td>\n",
       "      <td>0.011879</td>\n",
       "      <td>-0.098986</td>\n",
       "      <td>-0.054501</td>\n",
       "      <td>-0.007970</td>\n",
       "      <td>0.049113</td>\n",
       "      <td>-0.030580</td>\n",
       "      <td>-0.077933</td>\n",
       "      <td>-0.080529</td>\n",
       "      <td>-0.016267</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.509949</td>\n",
       "      <td>0.401709</td>\n",
       "      <td>0.293799</td>\n",
       "      <td>0.087714</td>\n",
       "      <td>0.011686</td>\n",
       "      <td>-0.006411</td>\n",
       "      <td>-0.006255</td>\n",
       "      <td>0.013646</td>\n",
       "      <td>-0.040666</td>\n",
       "      <td>-0.024447</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.119092</td>\n",
       "      <td>0.004412</td>\n",
       "      <td>-0.002262</td>\n",
       "      <td>0.072254</td>\n",
       "      <td>0.044512</td>\n",
       "      <td>-0.051467</td>\n",
       "      <td>0.074686</td>\n",
       "      <td>-0.007670</td>\n",
       "      <td>0.079438</td>\n",
       "      <td>0.062184</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.042037</td>\n",
       "      <td>0.007054</td>\n",
       "      <td>-0.069483</td>\n",
       "      <td>0.081015</td>\n",
       "      <td>-0.048207</td>\n",
       "      <td>0.089446</td>\n",
       "      <td>-0.004947</td>\n",
       "      <td>0.064456</td>\n",
       "      <td>-0.133387</td>\n",
       "      <td>0.068878</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2412</th>\n",
       "      <td>-0.119784</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>-0.123645</td>\n",
       "      <td>-0.015513</td>\n",
       "      <td>-0.059683</td>\n",
       "      <td>0.091032</td>\n",
       "      <td>-0.043302</td>\n",
       "      <td>0.229219</td>\n",
       "      <td>-0.071498</td>\n",
       "      <td>0.182709</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2413</th>\n",
       "      <td>0.085327</td>\n",
       "      <td>0.058590</td>\n",
       "      <td>0.085268</td>\n",
       "      <td>-0.020897</td>\n",
       "      <td>0.068972</td>\n",
       "      <td>0.030125</td>\n",
       "      <td>0.078056</td>\n",
       "      <td>0.011346</td>\n",
       "      <td>0.052618</td>\n",
       "      <td>0.066093</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2414</th>\n",
       "      <td>0.082526</td>\n",
       "      <td>-0.095571</td>\n",
       "      <td>-0.022019</td>\n",
       "      <td>-0.046793</td>\n",
       "      <td>-0.038360</td>\n",
       "      <td>0.041084</td>\n",
       "      <td>0.056509</td>\n",
       "      <td>0.011749</td>\n",
       "      <td>-0.029657</td>\n",
       "      <td>-0.012198</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2415</th>\n",
       "      <td>-0.130830</td>\n",
       "      <td>0.008868</td>\n",
       "      <td>-0.009457</td>\n",
       "      <td>-0.058930</td>\n",
       "      <td>-0.041224</td>\n",
       "      <td>0.042269</td>\n",
       "      <td>0.117717</td>\n",
       "      <td>0.037388</td>\n",
       "      <td>-0.085563</td>\n",
       "      <td>0.136649</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2416</th>\n",
       "      <td>-0.171578</td>\n",
       "      <td>-0.066536</td>\n",
       "      <td>0.168206</td>\n",
       "      <td>0.246831</td>\n",
       "      <td>0.079555</td>\n",
       "      <td>0.016528</td>\n",
       "      <td>-0.088908</td>\n",
       "      <td>-0.212926</td>\n",
       "      <td>-0.280230</td>\n",
       "      <td>-0.187064</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2417 rows Ã— 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Att1      Att2      Att3      Att4      Att5      Att6      Att7  \\\n",
       "0     0.004168 -0.170975 -0.156748 -0.142151  0.058781  0.026851  0.197719   \n",
       "1    -0.103956  0.011879 -0.098986 -0.054501 -0.007970  0.049113 -0.030580   \n",
       "2     0.509949  0.401709  0.293799  0.087714  0.011686 -0.006411 -0.006255   \n",
       "3     0.119092  0.004412 -0.002262  0.072254  0.044512 -0.051467  0.074686   \n",
       "4     0.042037  0.007054 -0.069483  0.081015 -0.048207  0.089446 -0.004947   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2412 -0.119784  0.001259 -0.123645 -0.015513 -0.059683  0.091032 -0.043302   \n",
       "2413  0.085327  0.058590  0.085268 -0.020897  0.068972  0.030125  0.078056   \n",
       "2414  0.082526 -0.095571 -0.022019 -0.046793 -0.038360  0.041084  0.056509   \n",
       "2415 -0.130830  0.008868 -0.009457 -0.058930 -0.041224  0.042269  0.117717   \n",
       "2416 -0.171578 -0.066536  0.168206  0.246831  0.079555  0.016528 -0.088908   \n",
       "\n",
       "          Att8      Att9     Att10  ...  Class5  Class6  Class7  Class8  \\\n",
       "0     0.041850  0.066938 -0.056617  ...       0       0       1       1   \n",
       "1    -0.077933 -0.080529 -0.016267  ...       0       0       0       0   \n",
       "2     0.013646 -0.040666 -0.024447  ...       0       0       0       0   \n",
       "3    -0.007670  0.079438  0.062184  ...       0       0       0       0   \n",
       "4     0.064456 -0.133387  0.068878  ...       1       1       0       0   \n",
       "...        ...       ...       ...  ...     ...     ...     ...     ...   \n",
       "2412  0.229219 -0.071498  0.182709  ...       0       0       0       0   \n",
       "2413  0.011346  0.052618  0.066093  ...       0       0       0       0   \n",
       "2414  0.011749 -0.029657 -0.012198  ...       0       1       1       1   \n",
       "2415  0.037388 -0.085563  0.136649  ...       0       0       0       0   \n",
       "2416 -0.212926 -0.280230 -0.187064  ...       0       0       0       0   \n",
       "\n",
       "      Class9  Class10  Class11  Class12  Class13  Class14  \n",
       "0          0        0        0        1        1        0  \n",
       "1          0        0        0        0        0        0  \n",
       "2          0        0        0        1        1        0  \n",
       "3          0        0        0        0        0        0  \n",
       "4          0        0        0        0        0        0  \n",
       "...      ...      ...      ...      ...      ...      ...  \n",
       "2412       0        0        0        0        0        0  \n",
       "2413       0        0        0        1        1        0  \n",
       "2414       0        0        0        1        1        0  \n",
       "2415       0        0        0        1        1        0  \n",
       "2416       0        0        0        1        1        0  \n",
       "\n",
       "[2417 rows x 117 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "yeast_raw_file_name = './yeast/yeast.arff'\n",
    "assert(os.path.isfile(yeast_raw_file_name))\n",
    "\n",
    "# Load ARFF file\n",
    "data, meta = arff.loadarff(yeast_raw_file_name)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Optionally, decode byte strings to regular strings if necessary\n",
    "df = df.applymap(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38d593b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(          Att1      Att2      Att3      Att4      Att5      Att6      Att7  \\\n",
       " 0     0.004168 -0.170975 -0.156748 -0.142151  0.058781  0.026851  0.197719   \n",
       " 1    -0.103956  0.011879 -0.098986 -0.054501 -0.007970  0.049113 -0.030580   \n",
       " 2     0.509949  0.401709  0.293799  0.087714  0.011686 -0.006411 -0.006255   \n",
       " 3     0.119092  0.004412 -0.002262  0.072254  0.044512 -0.051467  0.074686   \n",
       " 4     0.042037  0.007054 -0.069483  0.081015 -0.048207  0.089446 -0.004947   \n",
       " ...        ...       ...       ...       ...       ...       ...       ...   \n",
       " 2412 -0.119784  0.001259 -0.123645 -0.015513 -0.059683  0.091032 -0.043302   \n",
       " 2413  0.085327  0.058590  0.085268 -0.020897  0.068972  0.030125  0.078056   \n",
       " 2414  0.082526 -0.095571 -0.022019 -0.046793 -0.038360  0.041084  0.056509   \n",
       " 2415 -0.130830  0.008868 -0.009457 -0.058930 -0.041224  0.042269  0.117717   \n",
       " 2416 -0.171578 -0.066536  0.168206  0.246831  0.079555  0.016528 -0.088908   \n",
       " \n",
       "           Att8      Att9     Att10  ...     Att94     Att95     Att96  \\\n",
       " 0     0.041850  0.066938 -0.056617  ...  0.006166 -0.012976 -0.014259   \n",
       " 1    -0.077933 -0.080529 -0.016267  ...  0.007680  0.027719 -0.085811   \n",
       " 2     0.013646 -0.040666 -0.024447  ...  0.096277 -0.044932 -0.089470   \n",
       " 3    -0.007670  0.079438  0.062184  ... -0.083809  0.200354 -0.075716   \n",
       " 4     0.064456 -0.133387  0.068878  ... -0.060467  0.044351 -0.057209   \n",
       " ...        ...       ...       ...  ...       ...       ...       ...   \n",
       " 2412  0.229219 -0.071498  0.182709  ...  0.024084 -0.055915 -0.055593   \n",
       " 2413  0.011346  0.052618  0.066093  ... -0.079992 -0.075444  0.294987   \n",
       " 2414  0.011749 -0.029657 -0.012198  ... -0.006624 -0.036850 -0.064831   \n",
       " 2415  0.037388 -0.085563  0.136649  ...  0.085087  0.033166 -0.012710   \n",
       " 2416 -0.212926 -0.280230 -0.187064  ...  0.360199 -0.058178 -0.003104   \n",
       " \n",
       "          Att97     Att98     Att99    Att100    Att101    Att102    Att103  \n",
       " 0    -0.015024 -0.010747  0.000411 -0.032056 -0.018312  0.030126  0.124722  \n",
       " 1     0.111123  0.050541  0.027565 -0.063569 -0.041471 -0.079758  0.017161  \n",
       " 2    -0.009162 -0.012010  0.308378 -0.028053  0.026710 -0.066565 -0.122352  \n",
       " 3     0.196605  0.152758 -0.028484 -0.074207 -0.089227 -0.049913 -0.043893  \n",
       " 4     0.028047  0.029661 -0.050026  0.023248 -0.061539 -0.035160  0.067834  \n",
       " ...        ...       ...       ...       ...       ...       ...       ...  \n",
       " 2412 -0.049642  0.018571  0.068742 -0.061001 -0.081132 -0.065844  0.001267  \n",
       " 2413 -0.076379 -0.076293 -0.072451 -0.052258 -0.040026  0.342176 -0.169668  \n",
       " 2414 -0.068696 -0.068521 -0.039841  0.274575 -0.066957  0.260121 -0.125303  \n",
       " 2415  0.135359  0.213512 -0.107561 -0.081925 -0.122332 -0.022453  0.001953  \n",
       " 2416 -0.016028  0.054244 -0.017797 -0.081870 -0.083342 -0.063135  0.018810  \n",
       " \n",
       " [2417 rows x 103 columns],\n",
       "      Class1 Class2 Class3 Class4 Class5 Class6 Class7 Class8 Class9 Class10  \\\n",
       " 0         0      0      0      0      0      0      1      1      0       0   \n",
       " 1         0      0      1      1      0      0      0      0      0       0   \n",
       " 2         0      1      1      0      0      0      0      0      0       0   \n",
       " 3         0      0      1      1      0      0      0      0      0       0   \n",
       " 4         0      0      1      1      1      1      0      0      0       0   \n",
       " ...     ...    ...    ...    ...    ...    ...    ...    ...    ...     ...   \n",
       " 2412      0      1      1      0      0      0      0      0      0       0   \n",
       " 2413      1      1      0      0      0      0      0      0      0       0   \n",
       " 2414      0      0      0      0      0      1      1      1      0       0   \n",
       " 2415      0      0      0      0      0      0      0      0      0       0   \n",
       " 2416      0      1      1      0      0      0      0      0      0       0   \n",
       " \n",
       "      Class11 Class12 Class13 Class14  \n",
       " 0          0       1       1       0  \n",
       " 1          0       0       0       0  \n",
       " 2          0       1       1       0  \n",
       " 3          0       0       0       0  \n",
       " 4          0       0       0       0  \n",
       " ...      ...     ...     ...     ...  \n",
       " 2412       0       0       0       0  \n",
       " 2413       0       1       1       0  \n",
       " 2414       0       1       1       0  \n",
       " 2415       0       1       1       0  \n",
       " 2416       0       1       1       0  \n",
       " \n",
       " [2417 rows x 14 columns])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = df.columns[df.columns.str.startswith('Att')]\n",
    "\n",
    "X = df[columns]\n",
    "y = df.drop(columns=columns)\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68d11122",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_files:\n",
    "    X.to_csv(\"./data/6-YEAST_X.csv\")\n",
    "    y.to_csv(\"./data/6-YEAST_y.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c5750c",
   "metadata": {},
   "source": [
    "## 7. Birds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04853e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['L1', 'L2', 'L3', 'L4', 'L5', 'L6', 'L7', 'L8', 'L9', 'L10',\n",
       "       ...\n",
       "       'A251', 'A252', 'A253', 'A254', 'A255', 'A256', 'A257', 'A258', 'A259',\n",
       "       'A260'],\n",
       "      dtype='object', length=279)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./datasets/7-BIRDS.csv\")\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3cb84142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(           A1        A2        A3        A4        A5        A6        A7  \\\n",
       " 0    0.016521  0.039926  0.089632  0.134119  0.170470  0.176872  0.171546   \n",
       " 1    0.006600  0.035984  0.089956  0.123214  0.172273  0.177068  0.165507   \n",
       " 2    0.006894  0.017722  0.048062  0.065802  0.103443  0.091397  0.084931   \n",
       " 3    0.031046  0.127675  0.221428  0.272707  0.358743  0.349389  0.316029   \n",
       " 4    0.064721  0.226644  0.304482  0.274662  0.346980  0.334063  0.307223   \n",
       " ..        ...       ...       ...       ...       ...       ...       ...   \n",
       " 640  0.065968  0.005699  0.009809  0.014150  0.027981  0.027554  0.028538   \n",
       " 641  0.037432  0.010440  0.021009  0.025018  0.089126  0.037404  0.037024   \n",
       " 642  0.200058  0.054787  0.137048  0.162441  0.192939  0.177832  0.178606   \n",
       " 643  0.064331  0.012261  0.022449  0.026526  0.044141  0.040997  0.039509   \n",
       " 644  0.008697  0.012031  0.021212  0.028663  0.044081  0.041791  0.044002   \n",
       " \n",
       "            A8        A9       A10  ...  A251  A252       A253       A254  \\\n",
       " 0    0.182392  0.162482  0.159083  ...   0.0    13  16.384615  20.617394   \n",
       " 1    0.179655  0.161744  0.163678  ...   0.0     0   0.000000   0.000000   \n",
       " 2    0.088666  0.075676  0.074408  ...   0.0     2  24.000000   2.828427   \n",
       " 3    0.330656  0.310752  0.306288  ...   0.0     0   0.000000   0.000000   \n",
       " 4    0.324666  0.297070  0.292258  ...   0.0     0   0.000000   0.000000   \n",
       " ..        ...       ...       ...  ...   ...   ...        ...        ...   \n",
       " 640  0.031886  0.027338  0.030704  ...   0.0     0   0.000000   0.000000   \n",
       " 641  0.046730  0.033445  0.036546  ...   0.0     0   0.000000   0.000000   \n",
       " 642  0.174532  0.136221  0.142075  ...   0.0     0   0.000000   0.000000   \n",
       " 643  0.044909  0.040044  0.041884  ...   0.0     0   0.000000   0.000000   \n",
       " 644  0.046693  0.040220  0.041678  ...   0.0     0   0.000000   0.000000   \n",
       " \n",
       "           A255       A256        A257         A258  A259  A260  \n",
       " 0    46.769231  71.863118  788.923077  1761.802180     1     1  \n",
       " 1     0.000000   0.000000    0.000000     0.000000     0     1  \n",
       " 2    28.000000   1.414214  674.000000   113.137085     1     1  \n",
       " 3     0.000000   0.000000    0.000000     0.000000     0     1  \n",
       " 4     0.000000   0.000000    0.000000     0.000000     0     1  \n",
       " ..         ...        ...         ...          ...   ...   ...  \n",
       " 640   0.000000   0.000000    0.000000     0.000000     0    17  \n",
       " 641   0.000000   0.000000    0.000000     0.000000     0    17  \n",
       " 642   0.000000   0.000000    0.000000     0.000000     0    17  \n",
       " 643   0.000000   0.000000    0.000000     0.000000     0    17  \n",
       " 644   0.000000   0.000000    0.000000     0.000000     0    17  \n",
       " \n",
       " [645 rows x 260 columns],\n",
       "      L1  L2  L3  L4  L5  L6  L7  L8  L9  L10  L11  L12  L13  L14  L15  L16  \\\n",
       " 0     0   0   0   0   0   0   0   0   0    0    0    1    1    0    0    0   \n",
       " 1     0   0   0   0   0   0   0   0   0    0    0    0    0    0    0    0   \n",
       " 2     0   0   0   0   0   0   0   0   0    0    1    0    0    0    0    0   \n",
       " 3     0   0   0   0   0   0   0   0   0    0    0    0    0    0    0    0   \n",
       " 4     0   0   0   0   0   0   0   0   0    0    0    0    0    0    0    0   \n",
       " ..   ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...  ...  ...   \n",
       " 640   0   0   0   0   0   0   0   0   0    0    0    0    0    0    0    0   \n",
       " 641   0   0   0   0   0   0   0   0   0    0    0    0    0    0    0    0   \n",
       " 642   0   0   0   0   0   0   0   0   0    0    0    0    0    0    0    0   \n",
       " 643   0   0   0   0   0   0   0   0   0    0    0    0    0    0    0    0   \n",
       " 644   0   0   0   0   0   0   0   0   0    0    0    0    0    0    0    0   \n",
       " \n",
       "      L17  L18  L19  \n",
       " 0      0    0    0  \n",
       " 1      0    0    0  \n",
       " 2      0    0    0  \n",
       " 3      0    0    0  \n",
       " 4      0    0    0  \n",
       " ..   ...  ...  ...  \n",
       " 640    0    0    0  \n",
       " 641    0    0    0  \n",
       " 642    0    0    0  \n",
       " 643    0    0    0  \n",
       " 644    0    0    0  \n",
       " \n",
       " [645 rows x 19 columns])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[df.columns[df.columns.str.startswith('A')]]  # Selecting columns with names starting with 'A'\n",
    "y = df[df.columns[df.columns.str.startswith('L')]]  # Selecting columns with names starting with 'L'\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "113e2a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_files:\n",
    "    X.to_csv(\"./data/7-BIRDS_X.csv\")\n",
    "    y.to_csv(\"./data/7-BIRDS_y.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13134354",
   "metadata": {},
   "source": [
    "## 8. Genbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87187d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  protein PS00010 PS00011 PS00012 PS00014 PS00017 PS00018 PS00019 PS00020  \\\n",
       " 0  O00060      NO      NO      NO      NO      NO      NO      NO      NO   \n",
       " 1  O00139      NO      NO      NO      NO     YES      NO      NO      NO   \n",
       " 2  O02741      NO      NO      NO      NO      NO      NO      NO      NO   \n",
       " 3  O08424      NO      NO      NO      NO      NO      NO      NO      NO   \n",
       " 4  O12984      NO      NO      NO      NO      NO      NO      NO      NO   \n",
       " \n",
       "   PS00021  ... PDOC00662 PDOC00018 PDOC50001 PDOC00014 PDOC00750 PDOC50196  \\\n",
       " 0      NO  ...         0         0         0         0         0         0   \n",
       " 1      NO  ...         0         0         0         0         0         0   \n",
       " 2      NO  ...         0         0         0         0         0         0   \n",
       " 3      NO  ...         0         0         0         0         0         0   \n",
       " 4      NO  ...         0         0         0         0         0         0   \n",
       " \n",
       "   PDOC50199 PDOC00660 PDOC00653 PDOC00030  \n",
       " 0         0         0         0         0  \n",
       " 1         0         0         0         0  \n",
       " 2         0         0         0         0  \n",
       " 3         0         0         0         0  \n",
       " 4         0         0         0         0  \n",
       " \n",
       " [5 rows x 1213 columns],\n",
       " Index(['protein', 'PS00010', 'PS00011', 'PS00012', 'PS00014', 'PS00017',\n",
       "        'PS00018', 'PS00019', 'PS00020', 'PS00021',\n",
       "        ...\n",
       "        'PDOC00662', 'PDOC00018', 'PDOC50001', 'PDOC00014', 'PDOC00750',\n",
       "        'PDOC50196', 'PDOC50199', 'PDOC00660', 'PDOC00653', 'PDOC00030'],\n",
       "       dtype='object', length=1213))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "genbase_raw_file_name = './genbase/genbase.arff'\n",
    "assert(os.path.isfile(genbase_raw_file_name))\n",
    "\n",
    "# Load ARFF file\n",
    "data, meta = arff.loadarff(genbase_raw_file_name,)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Optionally, decode byte strings to regular strings if necessary\n",
    "df = df.applymap(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
    "\n",
    "df.head(), df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aba60513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     protein  PS00010  PS00011  PS00012  PS00014  PS00017  PS00018  PS00019  \\\n",
       " 0          0        0        0        0        0        0        0        0   \n",
       " 1          1        0        0        0        0        1        0        0   \n",
       " 2          2        0        0        0        0        0        0        0   \n",
       " 3          3        0        0        0        0        0        0        0   \n",
       " 4          4        0        0        0        0        0        0        0   \n",
       " ..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       " 657      657        0        0        0        0        0        0        0   \n",
       " 658      658        0        0        0        0        1        0        0   \n",
       " 659      659        0        0        0        0        0        0        0   \n",
       " 660      660        0        0        0        0        0        0        0   \n",
       " 661      661        0        0        0        0        1        0        0   \n",
       " \n",
       "      PS00020  PS00021  ...  PS50821  PS50822  PS50823  PS50824  PS50825  \\\n",
       " 0          0        0  ...        0        0        0        0        0   \n",
       " 1          0        0  ...        0        0        0        0        0   \n",
       " 2          0        0  ...        0        0        0        0        0   \n",
       " 3          0        0  ...        0        0        0        0        0   \n",
       " 4          0        0  ...        0        0        0        0        0   \n",
       " ..       ...      ...  ...      ...      ...      ...      ...      ...   \n",
       " 657        0        0  ...        0        0        0        0        0   \n",
       " 658        0        0  ...        0        0        0        0        0   \n",
       " 659        0        0  ...        0        0        0        0        0   \n",
       " 660        0        0  ...        0        0        0        0        0   \n",
       " 661        0        0  ...        0        0        0        0        0   \n",
       " \n",
       "      PS50826  PS50827  PS50829  PS50830  PS60000  \n",
       " 0          0        0        0        0        0  \n",
       " 1          0        0        0        0        0  \n",
       " 2          0        0        0        0        0  \n",
       " 3          0        0        0        0        0  \n",
       " 4          0        0        0        0        0  \n",
       " ..       ...      ...      ...      ...      ...  \n",
       " 657        0        0        0        0        0  \n",
       " 658        0        0        0        0        0  \n",
       " 659        0        0        0        0        0  \n",
       " 660        0        0        0        0        0  \n",
       " 661        0        0        0        0        0  \n",
       " \n",
       " [662 rows x 1186 columns],\n",
       "     PDOC00154 PDOC00343 PDOC00271 PDOC00064 PDOC00791 PDOC00380 PDOC50007  \\\n",
       " 0           1         0         0         0         0         0         0   \n",
       " 1           0         1         0         0         0         0         0   \n",
       " 2           0         0         1         0         0         0         0   \n",
       " 3           0         0         0         1         0         0         0   \n",
       " 4           0         0         0         0         1         0         0   \n",
       " ..        ...       ...       ...       ...       ...       ...       ...   \n",
       " 657         0         0         0         0         1         0         0   \n",
       " 658         0         0         0         0         0         0         0   \n",
       " 659         0         0         0         0         0         0         0   \n",
       " 660         0         0         0         0         1         0         0   \n",
       " 661         0         0         0         0         0         0         0   \n",
       " \n",
       "     PDOC00224 PDOC00100 PDOC00670  ... PDOC00662 PDOC00018 PDOC50001  \\\n",
       " 0           0         0         0  ...         0         0         0   \n",
       " 1           0         0         0  ...         0         0         0   \n",
       " 2           0         0         0  ...         0         0         0   \n",
       " 3           0         0         0  ...         0         0         0   \n",
       " 4           0         0         0  ...         0         0         0   \n",
       " ..        ...       ...       ...  ...       ...       ...       ...   \n",
       " 657         0         0         0  ...         0         0         0   \n",
       " 658         0         0         1  ...         0         0         0   \n",
       " 659         0         0         1  ...         0         0         0   \n",
       " 660         0         0         0  ...         0         0         0   \n",
       " 661         0         0         1  ...         0         0         0   \n",
       " \n",
       "     PDOC00014 PDOC00750 PDOC50196 PDOC50199 PDOC00660 PDOC00653 PDOC00030  \n",
       " 0           0         0         0         0         0         0         0  \n",
       " 1           0         0         0         0         0         0         0  \n",
       " 2           0         0         0         0         0         0         0  \n",
       " 3           0         0         0         0         0         0         0  \n",
       " 4           0         0         0         0         0         0         0  \n",
       " ..        ...       ...       ...       ...       ...       ...       ...  \n",
       " 657         0         0         0         0         0         0         0  \n",
       " 658         0         0         0         0         0         0         0  \n",
       " 659         0         0         0         0         0         0         0  \n",
       " 660         0         0         0         0         0         0         0  \n",
       " 661         0         0         0         0         0         0         0  \n",
       " \n",
       " [662 rows x 27 columns])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = df.columns[df.columns.str.startswith('PDOC')]\n",
    "\n",
    "X = df.drop(columns=columns)\n",
    "y = df[columns]\n",
    "\n",
    "for x in X.columns:\n",
    "    if X[x].dtype == 'object':\n",
    "        X[x] = label_encoder.fit_transform(X[x])\n",
    "\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e1631308",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_files:\n",
    "    X.to_csv(\"./data/8-GENBASE_X.csv\")\n",
    "    y.to_csv(\"./data/8-GENBASE_y.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1da308",
   "metadata": {},
   "source": [
    "## 9. Medical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "374d311c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   Class-0-593_70  Class-1-079_99  Class-2-786_09  Class-3-759_89  \\\n",
       " 0               0               0               0               0   \n",
       " 1               0               0               0               0   \n",
       " 2               0               0               0               0   \n",
       " 3               0               0               0               0   \n",
       " 4               1               0               0               0   \n",
       " \n",
       "    Class-4-753_0  Class-5-786_2  Class-6-V72_5  Class-7-511_9  Class-8-596_8  \\\n",
       " 0              1              0              0              0              0   \n",
       " 1              1              0              0              0              0   \n",
       " 2              0              0              0              0              0   \n",
       " 3              1              0              0              0              0   \n",
       " 4              0              0              0              0              0   \n",
       " \n",
       "    Class-9-599_0  ...  x2  x5  xray  year  year-old  yearly  years  yesterday  \\\n",
       " 0              0  ...   0   0     0     0         0       0      0          0   \n",
       " 1              0  ...   0   0     0     0         0       0      0          0   \n",
       " 2              0  ...   0   0     0     0         0       0      0          0   \n",
       " 3              0  ...   0   0     0     0         0       0      0          0   \n",
       " 4              0  ...   0   0     0     0         0       0      0          0   \n",
       " \n",
       "    zithromax  zone  \n",
       " 0          0     0  \n",
       " 1          0     0  \n",
       " 2          0     0  \n",
       " 3          0     0  \n",
       " 4          0     0  \n",
       " \n",
       " [5 rows x 1494 columns],\n",
       " Index(['Class-0-593_70', 'Class-1-079_99', 'Class-2-786_09', 'Class-3-759_89',\n",
       "        'Class-4-753_0', 'Class-5-786_2', 'Class-6-V72_5', 'Class-7-511_9',\n",
       "        'Class-8-596_8', 'Class-9-599_0',\n",
       "        ...\n",
       "        'x2', 'x5', 'xray', 'year', 'year-old', 'yearly', 'years', 'yesterday',\n",
       "        'zithromax', 'zone'],\n",
       "       dtype='object', length=1494))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./datasets/9-MEDC.csv\")\n",
    "\n",
    "df.head(), df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b70336ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     -  /  0  00  04  0;  0cm  1  1-1/2  1-1/2-year  ...  x2  x5  xray  year  \\\n",
       " 0    0  0  0   0   0   0    0  0      0           0  ...   0   0     0     0   \n",
       " 1    1  0  0   0   0   0    0  1      0           0  ...   0   0     0     0   \n",
       " 2    1  0  0   0   0   0    0  1      0           0  ...   0   0     0     0   \n",
       " 3    1  0  0   0   0   0    0  0      0           0  ...   0   0     0     0   \n",
       " 4    0  0  0   0   0   0    0  1      0           0  ...   0   0     0     0   \n",
       " ..  .. .. ..  ..  ..  ..  ... ..    ...         ...  ...  ..  ..   ...   ...   \n",
       " 973  0  0  0   0   0   0    0  0      0           0  ...   0   0     0     0   \n",
       " 974  1  0  0   0   0   0    0  0      0           0  ...   0   0     0     0   \n",
       " 975  1  0  0   0   0   0    0  0      0           0  ...   0   0     0     0   \n",
       " 976  0  0  0   0   0   0    0  0      0           0  ...   0   0     0     0   \n",
       " 977  1  0  0   0   0   0    0  0      0           0  ...   0   0     0     0   \n",
       " \n",
       "      year-old  yearly  years  yesterday  zithromax  zone  \n",
       " 0           0       0      0          0          0     0  \n",
       " 1           0       0      0          0          0     0  \n",
       " 2           0       0      0          0          0     0  \n",
       " 3           0       0      0          0          0     0  \n",
       " 4           0       0      0          0          0     0  \n",
       " ..        ...     ...    ...        ...        ...   ...  \n",
       " 973         0       0      1          0          0     0  \n",
       " 974         1       0      0          0          0     0  \n",
       " 975         1       0      0          0          0     0  \n",
       " 976         0       0      0          0          0     0  \n",
       " 977         0       0      0          0          0     0  \n",
       " \n",
       " [978 rows x 1449 columns],\n",
       "      Class-0-593_70  Class-1-079_99  Class-2-786_09  Class-3-759_89  \\\n",
       " 0                 0               0               0               0   \n",
       " 1                 0               0               0               0   \n",
       " 2                 0               0               0               0   \n",
       " 3                 0               0               0               0   \n",
       " 4                 1               0               0               0   \n",
       " ..              ...             ...             ...             ...   \n",
       " 973               0               0               0               0   \n",
       " 974               0               0               0               0   \n",
       " 975               0               0               0               0   \n",
       " 976               0               0               0               0   \n",
       " 977               0               0               0               0   \n",
       " \n",
       "      Class-4-753_0  Class-5-786_2  Class-6-V72_5  Class-7-511_9  \\\n",
       " 0                1              0              0              0   \n",
       " 1                1              0              0              0   \n",
       " 2                0              0              0              0   \n",
       " 3                1              0              0              0   \n",
       " 4                0              0              0              0   \n",
       " ..             ...            ...            ...            ...   \n",
       " 973              0              0              0              0   \n",
       " 974              0              0              0              0   \n",
       " 975              1              0              0              0   \n",
       " 976              0              0              0              0   \n",
       " 977              0              0              0              0   \n",
       " \n",
       "      Class-8-596_8  Class-9-599_0  ...  Class-35-493_90  Class-36-788_30  \\\n",
       " 0                0              0  ...                0                0   \n",
       " 1                0              0  ...                0                0   \n",
       " 2                0              0  ...                0                1   \n",
       " 3                0              0  ...                0                0   \n",
       " 4                0              0  ...                0                0   \n",
       " ..             ...            ...  ...              ...              ...   \n",
       " 973              0              0  ...                1                0   \n",
       " 974              0              0  ...                0                0   \n",
       " 975              0              0  ...                0                0   \n",
       " 976              0              0  ...                0                0   \n",
       " 977              0              0  ...                0                0   \n",
       " \n",
       "      Class-37-753_3  Class-38-593_89  Class-39-758_6  Class-40-741_90  \\\n",
       " 0                 0                0               0                0   \n",
       " 1                 0                0               0                0   \n",
       " 2                 0                0               0                0   \n",
       " 3                 0                0               0                0   \n",
       " 4                 0                0               0                0   \n",
       " ..              ...              ...             ...              ...   \n",
       " 973               0                0               0                0   \n",
       " 974               0                0               0                0   \n",
       " 975               0                0               0                0   \n",
       " 976               0                0               0                0   \n",
       " 977               0                1               0                0   \n",
       " \n",
       "      Class-41-591  Class-42-599_7  Class-43-279_12  Class-44-786_07  \n",
       " 0               0               0                0                0  \n",
       " 1               0               0                0                0  \n",
       " 2               1               0                0                0  \n",
       " 3               0               0                0                0  \n",
       " 4               0               0                0                0  \n",
       " ..            ...             ...              ...              ...  \n",
       " 973             0               0                0                0  \n",
       " 974             0               0                0                1  \n",
       " 975             0               0                0                0  \n",
       " 976             0               0                0                1  \n",
       " 977             0               0                0                0  \n",
       " \n",
       " [978 rows x 45 columns])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=df.columns[df.columns.str.startswith('Class')])  # Selecting columns with names starting with 'L'\n",
    "y = df[df.columns[df.columns.str.startswith('Class')]]  # Selecting columns with names starting with 'A'\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "02e40fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_files:\n",
    "    X.to_csv(\"./data/9-MEDC_X.csv\")\n",
    "    y.to_csv(\"./data/9-MEDC_y.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6b4110",
   "metadata": {},
   "source": [
    "## 10. Enron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "634a79b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   A.A8  C.C9  B.B12  C.C11  C.C5  C.C7  B.B2  B.B3  D.D16  A.A7  ...  \\\n",
       " 0     0     0      0      0     0     0     0     0      0     0  ...   \n",
       " 1     0     0      0      0     0     0     0     0      0     0  ...   \n",
       " 2     0     0      0      0     0     0     0     0      0     0  ...   \n",
       " 3     0     0      0      0     0     0     0     0      0     0  ...   \n",
       " 4     0     0      0      0     0     0     0     0      0     0  ...   \n",
       " \n",
       "    workers  working  world  writer  writers  www  year  years  yesterday  york  \n",
       " 0        0        0      0       0        0    0     0      0          0     0  \n",
       " 1        0        0      0       0        0    0     0      0          0     0  \n",
       " 2        0        0      0       0        0    0     0      0          0     0  \n",
       " 3        0        0      0       0        0    0     0      0          0     0  \n",
       " 4        0        0      0       0        0    0     1      0          0     0  \n",
       " \n",
       " [5 rows x 1054 columns],\n",
       " Index(['A.A8', 'C.C9', 'B.B12', 'C.C11', 'C.C5', 'C.C7', 'B.B2', 'B.B3',\n",
       "        'D.D16', 'A.A7',\n",
       "        ...\n",
       "        'workers', 'working', 'world', 'writer', 'writers', 'www', 'year',\n",
       "        'years', 'yesterday', 'york'],\n",
       "       dtype='object', length=1054))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./datasets/10-ENRON.csv\")\n",
    "\n",
    "df.head(), df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0708392f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      0  00  000  01  02  03  04  05  06  07  ...  workers  working  world  \\\n",
       " 0     0   0    0   0   0   0   0   0   0   0  ...        0        0      0   \n",
       " 1     0   0    0   1   0   0   0   0   0   0  ...        0        0      0   \n",
       " 2     0   0    0   0   0   0   0   0   0   0  ...        0        0      0   \n",
       " 3     0   0    0   0   0   0   0   0   0   0  ...        0        0      0   \n",
       " 4     0   0    0   0   0   0   0   0   0   0  ...        0        0      0   \n",
       " ...  ..  ..  ...  ..  ..  ..  ..  ..  ..  ..  ...      ...      ...    ...   \n",
       " 1697  0   0    0   0   0   0   0   0   0   0  ...        0        0      0   \n",
       " 1698  0   0    0   0   1   0   1   0   0   0  ...        0        0      0   \n",
       " 1699  0   0    0   0   0   0   0   0   0   0  ...        0        0      0   \n",
       " 1700  0   0    0   0   1   0   1   0   0   1  ...        0        0      0   \n",
       " 1701  0   0    0   0   1   0   1   0   1   1  ...        0        0      0   \n",
       " \n",
       "       writer  writers  www  year  years  yesterday  york  \n",
       " 0          0        0    0     0      0          0     0  \n",
       " 1          0        0    0     0      0          0     0  \n",
       " 2          0        0    0     0      0          0     0  \n",
       " 3          0        0    0     0      0          0     0  \n",
       " 4          0        0    0     1      0          0     0  \n",
       " ...      ...      ...  ...   ...    ...        ...   ...  \n",
       " 1697       0        0    0     1      1          0     0  \n",
       " 1698       0        0    1     1      1          1     0  \n",
       " 1699       0        0    0     1      0          0     0  \n",
       " 1700       0        0    1     1      1          1     0  \n",
       " 1701       0        0    1     1      1          1     0  \n",
       " \n",
       " [1702 rows x 1001 columns],\n",
       "       A.A8  C.C9  B.B12  C.C11  C.C5  C.C7  B.B2  B.B3  D.D16  A.A7  ...  \\\n",
       " 0        0     0      0      0     0     0     0     0      0     0  ...   \n",
       " 1        0     0      0      0     0     0     0     0      0     0  ...   \n",
       " 2        0     0      0      0     0     0     0     0      0     0  ...   \n",
       " 3        0     0      0      0     0     0     0     0      0     0  ...   \n",
       " 4        0     0      0      0     0     0     0     0      0     0  ...   \n",
       " ...    ...   ...    ...    ...   ...   ...   ...   ...    ...   ...  ...   \n",
       " 1697     0     0      0      0     0     0     1     0      0     0  ...   \n",
       " 1698     0     0      0      0     0     0     1     0      0     0  ...   \n",
       " 1699     0     0      0      0     0     0     1     0      0     0  ...   \n",
       " 1700     0     1      0      0     0     0     1     0      0     0  ...   \n",
       " 1701     0     0      0      0     0     0     1     0      0     0  ...   \n",
       " \n",
       "       C.C3  D.D10  D.D18  B.B13  D.D17  B.B10  C.C1  D.D4  C.C13  D.D14  \n",
       " 0        0      0      0      1      0      0     1     0      0      0  \n",
       " 1        0      0      0      0      0      0     1     0      0      0  \n",
       " 2        0      0      0      0      0      0     0     0      0      0  \n",
       " 3        0      0      0      0      0      0     0     0      0      0  \n",
       " 4        0      0      0      0      0      0     0     0      0      0  \n",
       " ...    ...    ...    ...    ...    ...    ...   ...   ...    ...    ...  \n",
       " 1697     0      1      0      1      0      0     0     0      0      0  \n",
       " 1698     0      1      0      0      0      0     0     0      0      0  \n",
       " 1699     0      1      0      0      0      0     1     0      0      0  \n",
       " 1700     0      0      0      0      0      0     0     0      0      0  \n",
       " 1701     0      0      0      1      0      0     0     0      0      0  \n",
       " \n",
       " [1702 rows x 53 columns])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_columns = [col for col in df.columns if col[0].isupper()]\n",
    "\n",
    "# Create a new DataFrame with the filtered columns\n",
    "X = df.drop(columns=filtered_columns)\n",
    "y = df[filtered_columns]\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c3ffa326",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_files:\n",
    "    X.to_csv(\"./data/10-ENRON_X.csv\")\n",
    "    y.to_csv(\"./data/10-ENRON_y.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8012a13a",
   "metadata": {},
   "source": [
    "## 11. MediaMill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f9293698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(       Att1      Att2      Att3      Att4      Att5      Att6      Att7  \\\n",
       " 0  0.380877  0.494079  0.540009  0.422926  0.158318  0.326975  0.390861   \n",
       " 1  0.508613  0.505837  0.437155  0.490723  0.262201  0.459610  0.393838   \n",
       " 2  0.449571  0.460490  0.453469  0.410779  0.231759  0.402147  0.349590   \n",
       " 3  0.416800  0.548996  0.520850  0.465410  0.181603  0.357255  0.389347   \n",
       " 4  0.501986  0.480820  0.435543  0.432002  0.250599  0.408353  0.357816   \n",
       " \n",
       "        Att8      Att9     Att10  ...  Class92  Class93  Class94  Class95  \\\n",
       " 0  0.527121  0.254052  0.223731  ...        0        0        0        0   \n",
       " 1  0.524006  0.370391  0.329424  ...        0        0        0        0   \n",
       " 2  0.536456  0.318117  0.301615  ...        0        0        0        0   \n",
       " 3  0.530189  0.290942  0.244521  ...        0        0        0        0   \n",
       " 4  0.499186  0.353172  0.327622  ...        0        0        0        0   \n",
       " \n",
       "    Class96  Class97  Class98  Class99  Class100  Class101  \n",
       " 0        0        0        0        0         0         0  \n",
       " 1        0        0        0        0         0         0  \n",
       " 2        0        0        0        0         0         0  \n",
       " 3        0        0        0        0         0         0  \n",
       " 4        0        0        0        0         0         0  \n",
       " \n",
       " [5 rows x 221 columns],\n",
       " Index(['Att1', 'Att2', 'Att3', 'Att4', 'Att5', 'Att6', 'Att7', 'Att8', 'Att9',\n",
       "        'Att10',\n",
       "        ...\n",
       "        'Class92', 'Class93', 'Class94', 'Class95', 'Class96', 'Class97',\n",
       "        'Class98', 'Class99', 'Class100', 'Class101'],\n",
       "       dtype='object', length=221))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "mediamill_raw_file_name = './mediamill/mediamill.arff'\n",
    "assert(os.path.isfile(mediamill_raw_file_name))\n",
    "\n",
    "# Load ARFF file\n",
    "data, meta = arff.loadarff(mediamill_raw_file_name,)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Optionally, decode byte strings to regular strings if necessary\n",
    "df = df.applymap(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
    "\n",
    "df.head(), df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eb34be7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(           Att1      Att2      Att3      Att4      Att5      Att6      Att7  \\\n",
       " 0      0.380877  0.494079  0.540009  0.422926  0.158318  0.326975  0.390861   \n",
       " 1      0.508613  0.505837  0.437155  0.490723  0.262201  0.459610  0.393838   \n",
       " 2      0.449571  0.460490  0.453469  0.410779  0.231759  0.402147  0.349590   \n",
       " 3      0.416800  0.548996  0.520850  0.465410  0.181603  0.357255  0.389347   \n",
       " 4      0.501986  0.480820  0.435543  0.432002  0.250599  0.408353  0.357816   \n",
       " ...         ...       ...       ...       ...       ...       ...       ...   \n",
       " 43902  0.426864  0.528629  0.532957  0.401551  0.187178  0.328457  0.363949   \n",
       " 43903  0.344094  0.537319  0.516101  0.430633  0.147998  0.310974  0.373041   \n",
       " 43904  0.329709  0.453422  0.523771  0.314048  0.133553  0.249196  0.296952   \n",
       " 43905  0.470031  0.489588  0.488227  0.356816  0.228900  0.370288  0.327771   \n",
       " 43906  0.350638  0.548779  0.554297  0.404750  0.134141  0.284098  0.361868   \n",
       " \n",
       "            Att8      Att9     Att10  ...    Att111    Att112    Att113  \\\n",
       " 0      0.527121  0.254052  0.223731  ...  0.593651  0.551529  0.574392   \n",
       " 1      0.524006  0.370391  0.329424  ...  0.616601  0.556555  0.553718   \n",
       " 2      0.536456  0.318117  0.301615  ...  0.627463  0.539564  0.638607   \n",
       " 3      0.530189  0.290942  0.244521  ...  0.604669  0.557365  0.571348   \n",
       " 4      0.499186  0.353172  0.327622  ...  0.607607  0.543372  0.566417   \n",
       " ...         ...       ...       ...  ...       ...       ...       ...   \n",
       " 43902  0.487699  0.306376  0.266459  ...  0.610354  0.544168  0.553511   \n",
       " 43903  0.493417  0.249852  0.191468  ...  0.582064  0.527097  0.581796   \n",
       " 43904  0.440839  0.222037  0.196553  ...  0.574960  0.522756  0.594364   \n",
       " 43905  0.464365  0.347709  0.319948  ...  0.585344  0.494285  0.566579   \n",
       " 43906  0.465428  0.241016  0.199843  ...  0.561277  0.542575  0.601334   \n",
       " \n",
       "          Att114    Att115    Att116    Att117    Att118    Att119    Att120  \n",
       " 0      0.511032  0.463997  0.202034  0.492341  0.317983  0.547807  0.393778  \n",
       " 1      0.552479  0.511739  0.218366  0.547476  0.348174  0.584991  0.422205  \n",
       " 2      0.496368  0.480986  0.199592  0.535078  0.323834  0.571487  0.397564  \n",
       " 3      0.565105  0.497706  0.252656  0.546756  0.346506  0.589601  0.430145  \n",
       " 4      0.526322  0.484486  0.186909  0.564721  0.325957  0.578370  0.398771  \n",
       " ...         ...       ...       ...       ...       ...       ...       ...  \n",
       " 43902  0.580699  0.559847  0.348502  0.587482  0.488400  0.624835  0.527380  \n",
       " 43903  0.555630  0.515736  0.271329  0.520354  0.410659  0.564902  0.453231  \n",
       " 43904  0.567564  0.524449  0.232201  0.554800  0.408484  0.570778  0.453345  \n",
       " 43905  0.555662  0.544435  0.244654  0.575187  0.422255  0.585876  0.464987  \n",
       " 43906  0.563842  0.556132  0.289604  0.564673  0.448091  0.589267  0.497985  \n",
       " \n",
       " [43907 rows x 120 columns],\n",
       "       Class1 Class2 Class3 Class4 Class5 Class6 Class7 Class8 Class9 Class10  \\\n",
       " 0          0      0      0      0      0      0      0      0      0       0   \n",
       " 1          0      0      0      0      0      0      0      0      0       0   \n",
       " 2          0      0      0      0      0      0      0      0      0       0   \n",
       " 3          0      0      0      0      0      0      0      0      0       0   \n",
       " 4          0      0      0      0      0      0      0      0      0       0   \n",
       " ...      ...    ...    ...    ...    ...    ...    ...    ...    ...     ...   \n",
       " 43902      0      0      0      0      0      0      0      0      0       0   \n",
       " 43903      0      0      0      0      0      0      0      0      0       0   \n",
       " 43904      0      0      0      0      0      0      0      0      0       0   \n",
       " 43905      0      0      0      0      0      0      0      0      0       0   \n",
       " 43906      0      0      0      0      0      0      0      0      0       0   \n",
       " \n",
       "        ... Class92 Class93 Class94 Class95 Class96 Class97 Class98 Class99  \\\n",
       " 0      ...       0       0       0       0       0       0       0       0   \n",
       " 1      ...       0       0       0       0       0       0       0       0   \n",
       " 2      ...       0       0       0       0       0       0       0       0   \n",
       " 3      ...       0       0       0       0       0       0       0       0   \n",
       " 4      ...       0       0       0       0       0       0       0       0   \n",
       " ...    ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       " 43902  ...       0       0       0       0       1       0       0       0   \n",
       " 43903  ...       0       0       0       0       1       0       0       0   \n",
       " 43904  ...       0       0       0       0       1       0       0       0   \n",
       " 43905  ...       0       0       0       0       0       0       0       0   \n",
       " 43906  ...       0       0       0       0       1       0       0       0   \n",
       " \n",
       "       Class100 Class101  \n",
       " 0            0        0  \n",
       " 1            0        0  \n",
       " 2            0        0  \n",
       " 3            0        0  \n",
       " 4            0        0  \n",
       " ...        ...      ...  \n",
       " 43902        0        0  \n",
       " 43903        0        0  \n",
       " 43904        0        0  \n",
       " 43905        0        0  \n",
       " 43906        0        0  \n",
       " \n",
       " [43907 rows x 101 columns])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[df.columns[df.columns.str.startswith('Att')]]  # Selecting columns with names starting with 'A'\n",
    "y = df[df.columns[df.columns.str.startswith('Class')]]  # Selecting columns with names starting with 'L'\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4b683b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_files:\n",
    "    X.to_csv(\"./data/11-MEDIAMILL_X.csv\")\n",
    "    y.to_csv(\"./data/11-MEDIAMILL_y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2bec85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
