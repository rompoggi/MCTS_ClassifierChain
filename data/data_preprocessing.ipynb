{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "212749e6",
   "metadata": {},
   "source": [
    "# Cleaning up of datasets for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8600337f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_files = True\n",
    "\n",
    "if save_files:\n",
    "    import os\n",
    "    if (os.path.exists(\"./data/\") is False):\n",
    "        os.makedirs(\"./data/\")\n",
    "        \n",
    "    assert(os.path.exists(\"./data/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f15734c",
   "metadata": {},
   "source": [
    "## 1. Solar Flare: N = 1389, L = 3, d = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7b15061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ucimlrepo in ./.venv/lib/python3.11/site-packages (0.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb99457e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "{'uci_id': 89, 'name': 'Solar Flare', 'repository_url': 'https://archive.ics.uci.edu/dataset/89/solar+flare', 'data_url': 'https://archive.ics.uci.edu/static/public/89/data.csv', 'abstract': 'Each class attribute counts the number of solar flares of a certain class that occur in a 24 hour period', 'area': 'Physics and Chemistry', 'tasks': ['Regression'], 'characteristics': ['Multivariate'], 'num_instances': 1389, 'num_features': 10, 'feature_types': ['Categorical'], 'demographics': [], 'target_col': ['common flares', 'moderate flares', 'severe flares'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1989, 'last_updated': 'Wed Feb 14 2024', 'dataset_doi': '10.24432/C5530G', 'creators': [], 'intro_paper': None, 'additional_info': {'summary': 'Notes:\\r\\n\\r\\n   -- The database contains 3 potential classes, one for the number of times a certain type of solar flare occured in a 24 hour period.\\r\\n   -- Each instance represents captured features for 1 active region on the sun.\\r\\n   -- The data are divided into two sections. The second section (flare.data2) has had much more error correction applied to the it, and has consequently been treated as more reliable.', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': \"   1. Code for class (modified Zurich class)  (A,B,C,D,E,F,H)\\r\\n   2. Code for largest spot size              (X,R,S,A,H,K)\\r\\n   3. Code for spot distribution              (X,O,I,C)\\r\\n   4. Activity                                (1 = reduced, 2 = unchanged)\\r\\n   5. Evolution                               (1 = decay, 2 = no growth, 3 = growth)\\r\\n   6. Previous 24 hour flare activity code    (1 = nothing as big as an M1, 2 = one M1, 3 = more activity than one M1)\\r\\n   7. Historically-complex                    (1 = Yes, 2 = No)\\r\\n   8. Did region become historically complex  on this pass across the sun's disk (1 = yes, 2 = no) \\r\\n   9. Area                                    (1 = small, 2 = large)\\r\\n  10. Area of the largest spot                (1 = <=5, 2 = >5)\\r\\n\\r\\n From all these predictors three classes of flares are predicted, which are represented in the last three columns.\\r\\n\\r\\n  11. C-class flares production by this region in the following 24 hours (common flares); Number\\r\\n  12. M-class flares production by this region in the following 24 hours (moderate flares);   Number\\r\\n  13. X-class flares production by this region in the following 24 hours (severe flares); Number\\r\\n     \", 'citation': None}}\n",
      "                               name     role  ... units missing_values\n",
      "0             modified Zurich class  Feature  ...  None             no\n",
      "1                 largest spot size  Feature  ...  None             no\n",
      "2                 spot distribution  Feature  ...  None             no\n",
      "3                          activity  Feature  ...  None             no\n",
      "4                         evolution  Feature  ...  None             no\n",
      "5   previous 24 hour flare activity  Feature  ...  None             no\n",
      "6              historically-complex  Feature  ...  None             no\n",
      "7       became complex on this pass  Feature  ...  None             no\n",
      "8                              area  Feature  ...  None             no\n",
      "9              area of largest spot  Feature  ...  None             no\n",
      "10                    common flares   Target  ...  None             no\n",
      "11                  moderate flares   Target  ...  None             no\n",
      "12                    severe flares   Target  ...  None             no\n",
      "\n",
      "[13 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# fetch dataset \n",
    "solar_flare = fetch_ucirepo(name=\"Solar Flare\") \n",
    "\n",
    "print(solar_flare.data.version2)\n",
    "  \n",
    "# data (as pandas dataframes)\n",
    "X = solar_flare.data.features \n",
    "y = solar_flare.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(solar_flare.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(solar_flare.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "967601e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      modified Zurich class  largest spot size  ...  area  area of largest spot\n",
       " 0                         1                  4  ...     1                     2\n",
       " 1                         2                  4  ...     1                     2\n",
       " 2                         1                  4  ...     1                     1\n",
       " 3                         2                  4  ...     1                     2\n",
       " 4                         2                  0  ...     1                     2\n",
       " ...                     ...                ...  ...   ...                   ...\n",
       " 1384                      5                  4  ...     1                     1\n",
       " 1385                      5                  4  ...     1                     1\n",
       " 1386                      1                  4  ...     1                     1\n",
       " 1387                      5                  3  ...     1                     1\n",
       " 1388                      0                  5  ...     1                     1\n",
       " \n",
       " [1389 rows x 10 columns],\n",
       "       common flares  moderate flares  severe flares\n",
       " 0                 0                0              0\n",
       " 1                 0                0              0\n",
       " 2                 0                0              0\n",
       " 3                 0                0              0\n",
       " 4                 0                0              0\n",
       " ...             ...              ...            ...\n",
       " 1384              0                0              0\n",
       " 1385              0                0              0\n",
       " 1386              0                0              0\n",
       " 1387              0                0              0\n",
       " 1388              0                0              0\n",
       " \n",
       " [1389 rows x 3 columns])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "clean_X = X.copy()\n",
    "for x in X.columns:\n",
    "    if X[x].dtype == 'object':\n",
    "        clean_X[x] = label_encoder.fit_transform(X[x])      \n",
    "\n",
    "X = clean_X.copy()\n",
    "del clean_X\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f3b312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_files:\n",
    "    X.to_csv('./data/1-FLARE_X.csv', index=False)\n",
    "    y.to_csv('./data/1-FLARE_y.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76be05f0",
   "metadata": {},
   "source": [
    "## 0.2. Bridges, N = 105, L = 6 , d = 7, not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a88daeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rom/Documents/Education/Bachelor/Thesis/MCTS_ClassifierChain\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce424d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "bridges_raw_file_name = os.getcwd() + \"/data/\" + \"./datasets/bridges.arff\"\n",
    "assert(os.path.isfile(bridges_raw_file_name))\n",
    "\n",
    "# Load ARFF file\n",
    "data, meta = arff.loadarff(bridges_raw_file_name,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da9e3b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  IDENTIF RIVER LOCATION ERECTED   PURPOSE  ...   T-OR-D MATERIAL   SPAN REL-L  TYPE\n",
       " 0      E1     M        3  CRAFTS   HIGHWAY  ...  THROUGH     WOOD  SHORT     S  WOOD\n",
       " 1      E2     A       25  CRAFTS   HIGHWAY  ...  THROUGH     WOOD  SHORT     S  WOOD\n",
       " 2      E3     A       39  CRAFTS  AQUEDUCT  ...  THROUGH     WOOD      ?     S  WOOD\n",
       " 3      E5     A       29  CRAFTS   HIGHWAY  ...  THROUGH     WOOD  SHORT     S  WOOD\n",
       " 4      E6     M       23  CRAFTS   HIGHWAY  ...  THROUGH     WOOD      ?     S  WOOD\n",
       " \n",
       " [5 rows x 13 columns],\n",
       " Index(['IDENTIF', 'RIVER', 'LOCATION', 'ERECTED', 'PURPOSE', 'LENGTH', 'LANES',\n",
       "        'CLEAR-G', 'T-OR-D', 'MATERIAL', 'SPAN', 'REL-L', 'TYPE'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Optionally, decode byte strings to regular strings if necessary\n",
    "df = df.map(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
    "\n",
    "df.head(), df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d80ffa08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     IDENTIF  RIVER  LOCATION  ERECTED  ...  T-OR-D  MATERIAL  SPAN  REL-L\n",
       " 0          0      1        22        0  ...       2         2     3      2\n",
       " 1         17      0        17        0  ...       2         2     3      2\n",
       " 2         28      0        33        0  ...       2         2     0      2\n",
       " 3         50      0        21        0  ...       2         2     3      2\n",
       " 4         61      1        15        0  ...       2         2     0      2\n",
       " ..       ...    ...       ...      ...  ...     ...       ...   ...    ...\n",
       " 100       90      0        26        3  ...       1         1     2      3\n",
       " 101       89      1        53        3  ...       1         1     1      1\n",
       " 102       88      0        16        3  ...       2         1     2      1\n",
       " 103       96      2        41        3  ...       2         1     1      1\n",
       " 104       95      1        51        3  ...       2         1     1      1\n",
       " \n",
       " [105 rows x 12 columns],\n",
       "      TYPE_ARCH  TYPE_CANTILEV  ...  TYPE_SUSPEN  TYPE_WOOD\n",
       " 0        False          False  ...        False       True\n",
       " 1        False          False  ...        False       True\n",
       " 2        False          False  ...        False       True\n",
       " 3        False          False  ...        False       True\n",
       " 4        False          False  ...        False       True\n",
       " ..         ...            ...  ...          ...        ...\n",
       " 100      False          False  ...        False      False\n",
       " 101      False          False  ...        False      False\n",
       " 102       True          False  ...        False      False\n",
       " 103       True          False  ...        False      False\n",
       " 104       True          False  ...        False      False\n",
       " \n",
       " [105 rows x 6 columns])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=[\"TYPE\"])\n",
    "y = pd.DataFrame(df[\"TYPE\"])\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for x in X.columns:\n",
    "    if X[x].dtype == 'object':\n",
    "        X[x] = label_encoder.fit_transform(X[x])\n",
    "\n",
    "y = pd.DataFrame(df[\"TYPE\"])\n",
    "y = pd.get_dummies(y[\"TYPE\"], prefix=\"TYPE\")\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b16308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_files and False:  # and False since we are not using bridges\n",
    "    X.to_csv(\"./data/2-BRIDGES_X.csv\")\n",
    "    y.to_csv(\"./data/2-BRIDGES_y.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd6964c",
   "metadata": {},
   "source": [
    "## 0.3. Parkinson's: L = 1, Not usable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca3cf5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 174, 'name': 'Parkinsons', 'repository_url': 'https://archive.ics.uci.edu/dataset/174/parkinsons', 'data_url': 'https://archive.ics.uci.edu/static/public/174/data.csv', 'abstract': \"Oxford Parkinson's Disease Detection Dataset\", 'area': 'Health and Medicine', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 197, 'num_features': 22, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['status'], 'index_col': ['name'], 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2007, 'last_updated': 'Wed Feb 14 2024', 'dataset_doi': '10.24432/C59C74', 'creators': ['Max Little'], 'intro_paper': {'title': 'Exploiting Nonlinear Recurrence and Fractal Scaling Properties for Voice Disorder Detection', 'authors': 'Max A. Little, P. McSharry, S. Roberts, D. Costello, I. Moroz', 'published_in': 'BioMedical Engineering OnLine', 'year': 2007, 'url': 'https://www.semanticscholar.org/paper/27e1dcd0d64bfc9d936e597d4f29b80c21571936', 'doi': '10.1186/1475-925X-6-23'}, 'additional_info': {'summary': 'This dataset is composed of a range of biomedical voice measurements from 31 people, 23 with Parkinson\\'s disease (PD). Each column in the table is a particular voice measure, and each row corresponds one of 195 voice recording from these individuals (\"name\" column). The main aim of the data is to discriminate healthy people from those with PD, according to \"status\" column which is set to 0 for healthy and 1 for PD. \\r\\n\\r\\nThe data is in ASCII CSV format. The rows of the CSV file contain an instance corresponding to one voice recording. There are around six recordings per patient, the name of the patient is identified in the first column.For further information or to pass on comments, please contact Max Little (littlem \\'@\\' robots.ox.ac.uk).\\r\\n\\r\\nFurther details are contained in the following reference -- if you use this dataset, please cite:\\r\\nMax A. Little, Patrick E. McSharry, Eric J. Hunter, Lorraine O. Ramig (2008), \\'Suitability of dysphonia measurements for telemonitoring of Parkinson\\'s disease\\', IEEE Transactions on Biomedical Engineering (to appear).', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': \"Matrix column entries (attributes):\\r\\nname - ASCII subject name and recording number\\r\\nMDVP:Fo(Hz) - Average vocal fundamental frequency\\r\\nMDVP:Fhi(Hz) - Maximum vocal fundamental frequency\\r\\nMDVP:Flo(Hz) - Minimum vocal fundamental frequency\\r\\nMDVP:Jitter(%),MDVP:Jitter(Abs),MDVP:RAP,MDVP:PPQ,Jitter:DDP - Several measures of variation in fundamental frequency\\r\\nMDVP:Shimmer,MDVP:Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,MDVP:APQ,Shimmer:DDA - Several measures of variation in amplitude\\r\\nNHR,HNR - Two measures of ratio of noise to tonal components in the voice\\r\\nstatus - Health status of the subject (one) - Parkinson's, (zero) - healthy\\r\\nRPDE,D2 - Two nonlinear dynamical complexity measures\\r\\nDFA - Signal fractal scaling exponent\\r\\nspread1,spread2,PPE - Three nonlinear measures of fundamental frequency variation\\r\\n\", 'citation': None}}\n",
      "            name     role         type  ... description units missing_values\n",
      "0           name       ID  Categorical  ...        None  None             no\n",
      "1        MDVP:Fo  Feature   Continuous  ...        None    Hz             no\n",
      "2       MDVP:Fhi  Feature   Continuous  ...        None    Hz             no\n",
      "3       MDVP:Flo  Feature   Continuous  ...        None    Hz             no\n",
      "4    MDVP:Jitter  Feature   Continuous  ...        None     %             no\n",
      "5    MDVP:Jitter  Feature   Continuous  ...        None   Abs             no\n",
      "6       MDVP:RAP  Feature   Continuous  ...        None  None             no\n",
      "7       MDVP:PPQ  Feature   Continuous  ...        None  None             no\n",
      "8     Jitter:DDP  Feature   Continuous  ...        None  None             no\n",
      "9   MDVP:Shimmer  Feature   Continuous  ...        None  None             no\n",
      "10  MDVP:Shimmer  Feature   Continuous  ...        None    dB             no\n",
      "11  Shimmer:APQ3  Feature   Continuous  ...        None  None             no\n",
      "12  Shimmer:APQ5  Feature   Continuous  ...        None  None             no\n",
      "13      MDVP:APQ  Feature   Continuous  ...        None  None             no\n",
      "14   Shimmer:DDA  Feature   Continuous  ...        None  None             no\n",
      "15           NHR  Feature   Continuous  ...        None  None             no\n",
      "16           HNR  Feature   Continuous  ...        None  None             no\n",
      "17        status   Target      Integer  ...        None  None             no\n",
      "18          RPDE  Feature   Continuous  ...        None  None             no\n",
      "19           DFA  Feature   Continuous  ...        None  None             no\n",
      "20       spread1  Feature   Continuous  ...        None  None             no\n",
      "21       spread2  Feature   Continuous  ...        None  None             no\n",
      "22            D2  Feature   Continuous  ...        None  None             no\n",
      "23           PPE  Feature   Continuous  ...        None  None             no\n",
      "\n",
      "[24 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "parkinsons = fetch_ucirepo(id=174) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = parkinsons.data.features \n",
    "y = parkinsons.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(parkinsons.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(parkinsons.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75bc48c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     MDVP:Fo  MDVP:Fhi  MDVP:Flo  ...       PPE  MDVP:Jitter  MDVP:Shimmer\n",
       " 0    119.992   157.302    74.997  ...  0.284654      0.00784       0.04374\n",
       " 1    122.400   148.650   113.819  ...  0.368674      0.00968       0.06134\n",
       " 2    116.682   131.111   111.555  ...  0.332634      0.01050       0.05233\n",
       " 3    116.676   137.871   111.366  ...  0.368975      0.00997       0.05492\n",
       " 4    116.014   141.781   110.655  ...  0.410335      0.01284       0.06425\n",
       " ..       ...       ...       ...  ...       ...          ...           ...\n",
       " 190  174.188   230.978    94.261  ...  0.133050      0.00459       0.04087\n",
       " 191  209.516   253.017    89.488  ...  0.168895      0.00564       0.02751\n",
       " 192  174.688   240.005    74.287  ...  0.131728      0.01360       0.02308\n",
       " 193  198.764   396.961    74.904  ...  0.123306      0.00740       0.02296\n",
       " 194  214.289   260.277    77.973  ...  0.148569      0.00567       0.01884\n",
       " \n",
       " [195 rows x 20 columns],\n",
       "      status\n",
       " 0         1\n",
       " 1         1\n",
       " 2         1\n",
       " 3         1\n",
       " 4         1\n",
       " ..      ...\n",
       " 190       0\n",
       " 191       0\n",
       " 192       0\n",
       " 193       0\n",
       " 194       0\n",
       " \n",
       " [195 rows x 1 columns])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "clean_X = X.drop(columns=[\"MDVP:Jitter\", \"MDVP:Shimmer\"]).copy()\n",
    "clean_X[\"MDVP:Jitter\"] = X[\"MDVP:Jitter\"].values.T[0]\n",
    "clean_X[\"MDVP:Shimmer\"] = X[\"MDVP:Shimmer\"].values.T[0]\n",
    "\n",
    "\n",
    "for x in clean_X.columns:\n",
    "    if clean_X[x].dtype == 'object':\n",
    "        clean_X[x] = label_encoder.fit_transform(clean_X[x])\n",
    "\n",
    "clean_y = y.copy()\n",
    "for yc in clean_y.columns:\n",
    "    if clean_y[yc].dtype == 'object':\n",
    "        clean_y[yc] = label_encoder.fit_transform(clean_y[yc])\n",
    "        \n",
    "clean_X, clean_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3379aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_files and False:  # and False since we are not using parkinsons\n",
    "    clean_X.to_csv(\"./data/3-PARKINS_X.csv\")\n",
    "    clean_y.to_csv(\"./data/3-PARKINS_y.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037f6297",
   "metadata": {},
   "source": [
    "## 0.4. Thyroid: Missing labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3611f10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  age sex on thyroxine  ... TBG referral source binaryClass\n",
       " 0  41   F            f  ...   ?            SVHC           P\n",
       " 1  23   F            f  ...   ?           other           P\n",
       " 2  46   M            f  ...   ?           other           P\n",
       " 3  70   F            t  ...   ?           other           P\n",
       " 4  70   F            f  ...   ?             SVI           P\n",
       " \n",
       " [5 rows x 30 columns],\n",
       " Index(['age', 'sex', 'on thyroxine', 'query on thyroxine',\n",
       "        'on antithyroid medication', 'sick', 'pregnant', 'thyroid surgery',\n",
       "        'I131 treatment', 'query hypothyroid', 'query hyperthyroid', 'lithium',\n",
       "        'goitre', 'tumor', 'hypopituitary', 'psych', 'TSH measured', 'TSH',\n",
       "        'T3 measured', 'T3', 'TT4 measured', 'TT4', 'T4U measured', 'T4U',\n",
       "        'FTI measured', 'FTI', 'TBG measured', 'TBG', 'referral source',\n",
       "        'binaryClass'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "assert(os.path.isfile(bridges_raw_file_name))\n",
    "thyroid_csv_file = os.getcwd() + \"/data/\" + \"./datasets/hypothyroid.csv\"\n",
    "df = pd.read_csv(thyroid_csv_file)\n",
    "\n",
    "df.head(), df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e6c63f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"binaryClass\"])\n",
    "y = df[\"binaryClass\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec18aa43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'f'}, {'?'})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(X[\"TBG measured\"]), set(X[\"TBG\"])  # Can drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e671317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>on thyroxine</th>\n",
       "      <th>query on thyroxine</th>\n",
       "      <th>on antithyroid medication</th>\n",
       "      <th>sick</th>\n",
       "      <th>pregnant</th>\n",
       "      <th>thyroid surgery</th>\n",
       "      <th>I131 treatment</th>\n",
       "      <th>query hypothyroid</th>\n",
       "      <th>query hyperthyroid</th>\n",
       "      <th>lithium</th>\n",
       "      <th>goitre</th>\n",
       "      <th>tumor</th>\n",
       "      <th>hypopituitary</th>\n",
       "      <th>psych</th>\n",
       "      <th>TSH measured</th>\n",
       "      <th>TSH</th>\n",
       "      <th>T3 measured</th>\n",
       "      <th>T3</th>\n",
       "      <th>TT4 measured</th>\n",
       "      <th>TT4</th>\n",
       "      <th>T4U measured</th>\n",
       "      <th>T4U</th>\n",
       "      <th>FTI measured</th>\n",
       "      <th>FTI</th>\n",
       "      <th>referral source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>1.3</td>\n",
       "      <td>t</td>\n",
       "      <td>2.5</td>\n",
       "      <td>t</td>\n",
       "      <td>125</td>\n",
       "      <td>t</td>\n",
       "      <td>1.14</td>\n",
       "      <td>t</td>\n",
       "      <td>109</td>\n",
       "      <td>SVHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>4.1</td>\n",
       "      <td>t</td>\n",
       "      <td>2</td>\n",
       "      <td>t</td>\n",
       "      <td>102</td>\n",
       "      <td>f</td>\n",
       "      <td>?</td>\n",
       "      <td>f</td>\n",
       "      <td>?</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>M</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>0.98</td>\n",
       "      <td>f</td>\n",
       "      <td>?</td>\n",
       "      <td>t</td>\n",
       "      <td>109</td>\n",
       "      <td>t</td>\n",
       "      <td>0.91</td>\n",
       "      <td>t</td>\n",
       "      <td>120</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>F</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>0.16</td>\n",
       "      <td>t</td>\n",
       "      <td>1.9</td>\n",
       "      <td>t</td>\n",
       "      <td>175</td>\n",
       "      <td>f</td>\n",
       "      <td>?</td>\n",
       "      <td>f</td>\n",
       "      <td>?</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>0.72</td>\n",
       "      <td>t</td>\n",
       "      <td>1.2</td>\n",
       "      <td>t</td>\n",
       "      <td>61</td>\n",
       "      <td>t</td>\n",
       "      <td>0.87</td>\n",
       "      <td>t</td>\n",
       "      <td>70</td>\n",
       "      <td>SVI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3767</th>\n",
       "      <td>30</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>?</td>\n",
       "      <td>f</td>\n",
       "      <td>?</td>\n",
       "      <td>f</td>\n",
       "      <td>?</td>\n",
       "      <td>f</td>\n",
       "      <td>?</td>\n",
       "      <td>f</td>\n",
       "      <td>?</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3768</th>\n",
       "      <td>68</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>2.1</td>\n",
       "      <td>t</td>\n",
       "      <td>124</td>\n",
       "      <td>t</td>\n",
       "      <td>1.08</td>\n",
       "      <td>t</td>\n",
       "      <td>114</td>\n",
       "      <td>SVI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3769</th>\n",
       "      <td>74</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>5.1</td>\n",
       "      <td>t</td>\n",
       "      <td>1.8</td>\n",
       "      <td>t</td>\n",
       "      <td>112</td>\n",
       "      <td>t</td>\n",
       "      <td>1.07</td>\n",
       "      <td>t</td>\n",
       "      <td>105</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3770</th>\n",
       "      <td>72</td>\n",
       "      <td>M</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>0.7</td>\n",
       "      <td>t</td>\n",
       "      <td>2</td>\n",
       "      <td>t</td>\n",
       "      <td>82</td>\n",
       "      <td>t</td>\n",
       "      <td>0.94</td>\n",
       "      <td>t</td>\n",
       "      <td>87</td>\n",
       "      <td>SVI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3771</th>\n",
       "      <td>64</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>2.2</td>\n",
       "      <td>t</td>\n",
       "      <td>99</td>\n",
       "      <td>t</td>\n",
       "      <td>1.07</td>\n",
       "      <td>t</td>\n",
       "      <td>92</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3772 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age sex on thyroxine  ... FTI measured  FTI referral source\n",
       "0     41   F            f  ...            t  109            SVHC\n",
       "1     23   F            f  ...            f    ?           other\n",
       "2     46   M            f  ...            t  120           other\n",
       "3     70   F            t  ...            f    ?           other\n",
       "4     70   F            f  ...            t   70             SVI\n",
       "...   ..  ..          ...  ...          ...  ...             ...\n",
       "3767  30   F            f  ...            f    ?           other\n",
       "3768  68   F            f  ...            t  114             SVI\n",
       "3769  74   F            f  ...            t  105           other\n",
       "3770  72   M            f  ...            t   87             SVI\n",
       "3771  64   F            f  ...            t   92           other\n",
       "\n",
       "[3772 rows x 27 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_X = X.drop(columns=[\"TBG measured\", \"TBG\"])\n",
    "\n",
    "clean_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "340245bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_files and False:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e254f7",
   "metadata": {},
   "source": [
    "## 2. Music: 593, 6, 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "307bbae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   amazed-suprised  happy-pleased  relaxing-clam  ...    BHSUM1    BHSUM2    BHSUM3\n",
       " 0                0              1              1  ...  0.245457  0.105065  0.405399\n",
       " 1                1              0              0  ...  0.343547  0.276366  0.710924\n",
       " 2                0              1              0  ...  0.188693  0.045941  0.457372\n",
       " 3                0              0              1  ...  0.102839  0.241934  0.351009\n",
       " 4                0              0              0  ...  0.195196  0.310801  0.683817\n",
       " \n",
       " [5 rows x 78 columns],\n",
       " Index(['amazed-suprised', 'happy-pleased', 'relaxing-clam', 'quiet-still',\n",
       "        'sad-lonely', 'angry-aggresive', 'Mean_Acc1298_Mean_Mem40_Centroid',\n",
       "        'Mean_Acc1298_Mean_Mem40_Rolloff', 'Mean_Acc1298_Mean_Mem40_Flux',\n",
       "        'Mean_Acc1298_Mean_Mem40_MFCC_0', 'Mean_Acc1298_Mean_Mem40_MFCC_1',\n",
       "        'Mean_Acc1298_Mean_Mem40_MFCC_2', 'Mean_Acc1298_Mean_Mem40_MFCC_3',\n",
       "        'Mean_Acc1298_Mean_Mem40_MFCC_4', 'Mean_Acc1298_Mean_Mem40_MFCC_5',\n",
       "        'Mean_Acc1298_Mean_Mem40_MFCC_6', 'Mean_Acc1298_Mean_Mem40_MFCC_7',\n",
       "        'Mean_Acc1298_Mean_Mem40_MFCC_8', 'Mean_Acc1298_Mean_Mem40_MFCC_9',\n",
       "        'Mean_Acc1298_Mean_Mem40_MFCC_10', 'Mean_Acc1298_Mean_Mem40_MFCC_11',\n",
       "        'Mean_Acc1298_Mean_Mem40_MFCC_12', 'Mean_Acc1298_Std_Mem40_Centroid',\n",
       "        'Mean_Acc1298_Std_Mem40_Rolloff', 'Mean_Acc1298_Std_Mem40_Flux',\n",
       "        'Mean_Acc1298_Std_Mem40_MFCC_0', 'Mean_Acc1298_Std_Mem40_MFCC_1',\n",
       "        'Mean_Acc1298_Std_Mem40_MFCC_2', 'Mean_Acc1298_Std_Mem40_MFCC_3',\n",
       "        'Mean_Acc1298_Std_Mem40_MFCC_4', 'Mean_Acc1298_Std_Mem40_MFCC_5',\n",
       "        'Mean_Acc1298_Std_Mem40_MFCC_6', 'Mean_Acc1298_Std_Mem40_MFCC_7',\n",
       "        'Mean_Acc1298_Std_Mem40_MFCC_8', 'Mean_Acc1298_Std_Mem40_MFCC_9',\n",
       "        'Mean_Acc1298_Std_Mem40_MFCC_10', 'Mean_Acc1298_Std_Mem40_MFCC_11',\n",
       "        'Mean_Acc1298_Std_Mem40_MFCC_12', 'Std_Acc1298_Mean_Mem40_Centroid',\n",
       "        'Std_Acc1298_Mean_Mem40_Rolloff', 'Std_Acc1298_Mean_Mem40_Flux',\n",
       "        'Std_Acc1298_Mean_Mem40_MFCC_0', 'Std_Acc1298_Mean_Mem40_MFCC_1',\n",
       "        'Std_Acc1298_Mean_Mem40_MFCC_2', 'Std_Acc1298_Mean_Mem40_MFCC_3',\n",
       "        'Std_Acc1298_Mean_Mem40_MFCC_4', 'Std_Acc1298_Mean_Mem40_MFCC_5',\n",
       "        'Std_Acc1298_Mean_Mem40_MFCC_6', 'Std_Acc1298_Mean_Mem40_MFCC_7',\n",
       "        'Std_Acc1298_Mean_Mem40_MFCC_8', 'Std_Acc1298_Mean_Mem40_MFCC_9',\n",
       "        'Std_Acc1298_Mean_Mem40_MFCC_10', 'Std_Acc1298_Mean_Mem40_MFCC_11',\n",
       "        'Std_Acc1298_Mean_Mem40_MFCC_12', 'Std_Acc1298_Std_Mem40_Centroid',\n",
       "        'Std_Acc1298_Std_Mem40_Rolloff', 'Std_Acc1298_Std_Mem40_Flux',\n",
       "        'Std_Acc1298_Std_Mem40_MFCC_0', 'Std_Acc1298_Std_Mem40_MFCC_1',\n",
       "        'Std_Acc1298_Std_Mem40_MFCC_2', 'Std_Acc1298_Std_Mem40_MFCC_3',\n",
       "        'Std_Acc1298_Std_Mem40_MFCC_4', 'Std_Acc1298_Std_Mem40_MFCC_5',\n",
       "        'Std_Acc1298_Std_Mem40_MFCC_6', 'Std_Acc1298_Std_Mem40_MFCC_7',\n",
       "        'Std_Acc1298_Std_Mem40_MFCC_8', 'Std_Acc1298_Std_Mem40_MFCC_9',\n",
       "        'Std_Acc1298_Std_Mem40_MFCC_10', 'Std_Acc1298_Std_Mem40_MFCC_11',\n",
       "        'Std_Acc1298_Std_Mem40_MFCC_12', 'BH_LowPeakAmp', 'BH_LowPeakBPM',\n",
       "        'BH_HighPeakAmp', 'BH_HighPeakBPM', 'BH_HighLowRatio', 'BHSUM1',\n",
       "        'BHSUM2', 'BHSUM3'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "emot_csv_file = os.getcwd() + \"/data/\" + \"./datasets/2-EMOT.csv\"\n",
    "df = pd.read_csv(emot_csv_file)\n",
    "\n",
    "df.head(), df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "969fa488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['amazed-suprised', 'happy-pleased', 'relaxing-clam', 'quiet-still',\n",
       "       'sad-lonely', 'angry-aggresive'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = df.columns[:6]\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b0f8ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     Mean_Acc1298_Mean_Mem40_Centroid  ...    BHSUM3\n",
       " 0                            0.034741  ...  0.405399\n",
       " 1                            0.081374  ...  0.710924\n",
       " 2                            0.110545  ...  0.457372\n",
       " 3                            0.042481  ...  0.351009\n",
       " 4                            0.074550  ...  0.683817\n",
       " ..                                ...  ...       ...\n",
       " 588                          0.027142  ...  1.149211\n",
       " 589                          0.094829  ...  0.335371\n",
       " 590                          0.035169  ...  0.476993\n",
       " 591                          0.054276  ...  1.255820\n",
       " 592                          0.073194  ...  0.451701\n",
       " \n",
       " [593 rows x 72 columns],\n",
       "      amazed-suprised  happy-pleased  ...  sad-lonely  angry-aggresive\n",
       " 0                  0              1  ...           0                0\n",
       " 1                  1              0  ...           0                1\n",
       " 2                  0              1  ...           0                1\n",
       " 3                  0              0  ...           0                0\n",
       " 4                  0              0  ...           0                0\n",
       " ..               ...            ...  ...         ...              ...\n",
       " 588                0              0  ...           1                0\n",
       " 589                1              0  ...           1                1\n",
       " 590                0              0  ...           1                0\n",
       " 591                0              1  ...           0                0\n",
       " 592                0              1  ...           0                0\n",
       " \n",
       " [593 rows x 6 columns])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=targets)\n",
    "y = df[targets]\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54e5e4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_files:\n",
    "    X.to_csv(\"./data/2-EMOT_X.csv\", index=False)\n",
    "    y.to_csv(\"./data/2-EMOT_y.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1dcefe",
   "metadata": {},
   "source": [
    "## 3. Scence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fcaace8b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   beach  sunset  foliage  field  ...    Att291    Att292    Att293    Att294\n",
       " 0      1       0        0      0  ...  0.157332  0.247298  0.014025  0.029709\n",
       " 1      1       0        0      0  ...  0.251454  0.137833  0.082672  0.036320\n",
       " 2      1       0        0      0  ...  0.017166  0.051125  0.112506  0.083924\n",
       " 3      1       0        0      0  ...  0.019267  0.031290  0.049780  0.090959\n",
       " 4      1       0        0      0  ...  0.198151  0.238796  0.164270  0.184290\n",
       " \n",
       " [5 rows x 300 columns],\n",
       " Index(['beach', 'sunset', 'foliage', 'field', 'mountain', 'urban', 'Att1',\n",
       "        'Att2', 'Att3', 'Att4',\n",
       "        ...\n",
       "        'Att285', 'Att286', 'Att287', 'Att288', 'Att289', 'Att290', 'Att291',\n",
       "        'Att292', 'Att293', 'Att294'],\n",
       "       dtype='object', length=300))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "scene_csv_file = os.getcwd() + \"/data/\" + \"./datasets/3-SCENE.csv\"\n",
    "df = pd.read_csv(scene_csv_file)\n",
    "\n",
    "df.head(), df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d28f3e2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(          Att1      Att2      Att3  ...    Att292    Att293    Att294\n",
       " 0     0.646467  0.666435  0.685047  ...  0.247298  0.014025  0.029709\n",
       " 1     0.770156  0.767255  0.761053  ...  0.137833  0.082672  0.036320\n",
       " 2     0.793984  0.772096  0.761820  ...  0.051125  0.112506  0.083924\n",
       " 3     0.938563  0.949260  0.955621  ...  0.031290  0.049780  0.090959\n",
       " 4     0.512130  0.524684  0.520020  ...  0.238796  0.164270  0.184290\n",
       " ...        ...       ...       ...  ...       ...       ...       ...\n",
       " 2402  0.875782  0.901653  0.926227  ...  0.279607  0.254413  0.134350\n",
       " 2403  0.657706  0.669877  0.692338  ...  0.199491  0.048747  0.041638\n",
       " 2404  0.952281  0.944987  0.905556  ...  0.031900  0.017547  0.019734\n",
       " 2405  0.883990  0.899004  0.901019  ...  0.256158  0.226332  0.223070\n",
       " 2406  0.974915  0.866425  0.818144  ...  0.005131  0.025059  0.004033\n",
       " \n",
       " [2407 rows x 294 columns],\n",
       "       beach  sunset  foliage  field  mountain  urban\n",
       " 0         1       0        0      0         1      0\n",
       " 1         1       0        0      0         0      1\n",
       " 2         1       0        0      0         0      0\n",
       " 3         1       0        0      0         0      0\n",
       " 4         1       0        0      0         0      0\n",
       " ...     ...     ...      ...    ...       ...    ...\n",
       " 2402      0       0        0      0         0      1\n",
       " 2403      0       0        0      0         0      1\n",
       " 2404      0       0        0      0         0      1\n",
       " 2405      0       0        0      0         0      1\n",
       " 2406      0       0        0      0         0      1\n",
       " \n",
       " [2407 rows x 6 columns])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = df.columns[df.columns.str.startswith('Att')]\n",
    "\n",
    "X = df[columns]\n",
    "y = df.drop(columns=columns)\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8636920d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_files:\n",
    "    X.to_csv(\"./data/3-SCENE_X.csv\", index=False)\n",
    "    y.to_csv(\"./data/3-SCENE_y.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69343255",
   "metadata": {},
   "source": [
    "## 4. Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63bc31e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  landmass zone    area  population language  ... blue  yellow  white  black  orange\n",
       " 0        5    1   648.0        16.0       10  ...    0       1      1      1       0\n",
       " 1        3    1    29.0         3.0        6  ...    0       1      0      1       0\n",
       " 2        4    1  2388.0        20.0        8  ...    0       0      1      0       0\n",
       " 3        6    3     0.0         0.0        1  ...    1       1      1      0       1\n",
       " 4        3    1     0.0         0.0        6  ...    1       1      0      0       0\n",
       " \n",
       " [5 rows x 26 columns],\n",
       " Index(['landmass', 'zone', 'area', 'population', 'language', 'religion',\n",
       "        'bars', 'stripes', 'colours', 'circles', 'crosses', 'saltires',\n",
       "        'quarters', 'sunstars', 'crescent', 'triangle', 'icon', 'animate',\n",
       "        'text', 'red', 'green', 'blue', 'yellow', 'white', 'black', 'orange'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "flags_raw_file_name = os.getcwd() + \"/data/\" + \"./datasets/flags.arff\"\n",
    "assert(os.path.isfile(flags_raw_file_name))\n",
    "\n",
    "# Load ARFF file\n",
    "data, meta = arff.loadarff(flags_raw_file_name,)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Optionally, decode byte strings to regular strings if necessary\n",
    "df = df.map(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
    "\n",
    "df.head(), df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5471109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(    landmass zone    area  population  ... triangle icon  animate  text\n",
       " 0          5    1   648.0        16.0  ...        0    1        0     0\n",
       " 1          3    1    29.0         3.0  ...        0    0        1     0\n",
       " 2          4    1  2388.0        20.0  ...        0    0        0     0\n",
       " 3          6    3     0.0         0.0  ...        1    1        1     0\n",
       " 4          3    1     0.0         0.0  ...        0    0        0     0\n",
       " ..       ...  ...     ...         ...  ...      ...  ...      ...   ...\n",
       " 189        6    3     3.0         0.0  ...        0    0        0     0\n",
       " 190        3    1   256.0        22.0  ...        0    0        0     0\n",
       " 191        4    2   905.0        28.0  ...        0    1        1     0\n",
       " 192        4    2   753.0         6.0  ...        0    0        1     0\n",
       " 193        4    2   391.0         8.0  ...        1    1        1     0\n",
       " \n",
       " [194 rows x 19 columns],\n",
       "     red green blue yellow white black orange\n",
       " 0     1     1    0      1     1     1      0\n",
       " 1     1     0    0      1     0     1      0\n",
       " 2     1     1    0      0     1     0      0\n",
       " 3     1     0    1      1     1     0      1\n",
       " 4     1     0    1      1     0     0      0\n",
       " ..   ..   ...  ...    ...   ...   ...    ...\n",
       " 189   1     0    1      0     1     0      0\n",
       " 190   1     0    1      1     1     0      0\n",
       " 191   1     1    0      1     0     0      1\n",
       " 192   1     1    0      0     0     1      1\n",
       " 193   1     1    0      1     1     1      0\n",
       " \n",
       " [194 rows x 7 columns])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = [\"red\", \"green\", \"blue\", \"yellow\", 'white', 'black', \"orange\"]\n",
    "\n",
    "X = df.drop(columns=columns)\n",
    "y = df[columns]\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4bd7457",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_files:\n",
    "    X.to_csv(\"./data/4-FLAGS_X.csv\", index=False)\n",
    "    y.to_csv(\"./data/4-FLAGS_y.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0fe38c",
   "metadata": {},
   "source": [
    "# 5. Foodtruck: N = 407, L = 12, d = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9034a2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   frequency       time  expenses  ... healthy_food  fitness_food  sweets_desserts\n",
       " 0        2.0     dinner      30.0  ...            0             0                1\n",
       " 1        0.0     dinner      20.0  ...            0             0                1\n",
       " 2        1.0  afternoon      15.0  ...            0             0                0\n",
       " 3        0.0      lunch      40.0  ...            0             0                0\n",
       " 4        0.0     dinner      15.0  ...            0             0                0\n",
       " \n",
       " [5 rows x 33 columns],\n",
       " Index(['frequency', 'time', 'expenses', 'motivation', 'taste', 'hygiene',\n",
       "        'menu', 'presentation', 'attendance', 'ingredients', 'place.to.sit',\n",
       "        'takeaway', 'variation', 'stop.strucks', 'schedule', 'gender',\n",
       "        'age.group', 'scholarity', 'average.income', 'has.work',\n",
       "        'marital.status', 'street_food', 'gourmet', 'italian_food',\n",
       "        'brazilian_food', 'mexican_food', 'chinese_food', 'japanese_food',\n",
       "        'arabic_food', 'snacks', 'healthy_food', 'fitness_food',\n",
       "        'sweets_desserts'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "mediamill_raw_file_name = os.getcwd() + \"/data/\" + \"./datasets/foodtruck.arff\"\n",
    "assert(os.path.isfile(mediamill_raw_file_name))\n",
    "\n",
    "# Load ARFF file\n",
    "data, meta = arff.loadarff(mediamill_raw_file_name,)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Optionally, decode byte strings to regular strings if necessary\n",
    "df = df.map(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
    "\n",
    "df.head(), df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "662420fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     frequency       time  expenses  ... average.income  has.work  marital.status\n",
       " 0          2.0     dinner      30.0  ...            4.0       0.0          single\n",
       " 1          0.0     dinner      20.0  ...            5.0       1.0         married\n",
       " 2          1.0  afternoon      15.0  ...            4.0       1.0          single\n",
       " 3          0.0      lunch      40.0  ...            6.0       1.0          single\n",
       " 4          0.0     dinner      15.0  ...            4.0       1.0          single\n",
       " ..         ...        ...       ...  ...            ...       ...             ...\n",
       " 402        0.0     dinner      30.0  ...            3.0       1.0          single\n",
       " 403        0.0     dinner      30.0  ...            4.0       0.0          single\n",
       " 404        0.0     dinner      30.0  ...            1.0       1.0          single\n",
       " 405        1.0     dinner      30.0  ...            2.0       1.0         married\n",
       " 406        0.0     dinner      15.0  ...            1.0       0.0          single\n",
       " \n",
       " [407 rows x 21 columns],\n",
       "     gourmet snacks street_food  ... healthy_food fitness_food sweets_desserts\n",
       " 0         0      0           1  ...            0            0               1\n",
       " 1         0      0           1  ...            0            0               1\n",
       " 2         0      0           1  ...            0            0               0\n",
       " 3         1      0           0  ...            0            0               0\n",
       " 4         0      0           1  ...            0            0               0\n",
       " ..      ...    ...         ...  ...          ...          ...             ...\n",
       " 402       0      0           1  ...            0            0               0\n",
       " 403       1      0           1  ...            0            0               1\n",
       " 404       0      0           1  ...            0            0               1\n",
       " 405       1      1           1  ...            0            0               1\n",
       " 406       0      1           0  ...            0            0               0\n",
       " \n",
       " [407 rows x 12 columns])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['gourmet', 'snacks', 'street_food', 'italian_food',\n",
    "           'brazilian_food', 'mexican_food', 'chinese_food','japanese_food',\n",
    "           'arabic_food', 'healthy_food', 'fitness_food', 'sweets_desserts']\n",
    "\n",
    "X = df.drop(columns=columns)\n",
    "y = df[columns]\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "acda8e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_files:\n",
    "    X.to_csv(\"./data/5-FOODTRUCK_X.csv\", index=False)\n",
    "    y.to_csv(\"./data/5-FOODTRUCK_y.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfff6e10",
   "metadata": {},
   "source": [
    "## 6. Yeast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6dfb0485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Att1</th>\n",
       "      <th>Att2</th>\n",
       "      <th>Att3</th>\n",
       "      <th>Att4</th>\n",
       "      <th>Att5</th>\n",
       "      <th>Att6</th>\n",
       "      <th>Att7</th>\n",
       "      <th>Att8</th>\n",
       "      <th>Att9</th>\n",
       "      <th>Att10</th>\n",
       "      <th>Att11</th>\n",
       "      <th>Att12</th>\n",
       "      <th>Att13</th>\n",
       "      <th>Att14</th>\n",
       "      <th>Att15</th>\n",
       "      <th>Att16</th>\n",
       "      <th>Att17</th>\n",
       "      <th>Att18</th>\n",
       "      <th>Att19</th>\n",
       "      <th>Att20</th>\n",
       "      <th>Att21</th>\n",
       "      <th>Att22</th>\n",
       "      <th>Att23</th>\n",
       "      <th>Att24</th>\n",
       "      <th>Att25</th>\n",
       "      <th>Att26</th>\n",
       "      <th>Att27</th>\n",
       "      <th>Att28</th>\n",
       "      <th>Att29</th>\n",
       "      <th>Att30</th>\n",
       "      <th>Att31</th>\n",
       "      <th>Att32</th>\n",
       "      <th>Att33</th>\n",
       "      <th>Att34</th>\n",
       "      <th>Att35</th>\n",
       "      <th>Att36</th>\n",
       "      <th>Att37</th>\n",
       "      <th>Att38</th>\n",
       "      <th>Att39</th>\n",
       "      <th>Att40</th>\n",
       "      <th>...</th>\n",
       "      <th>Att78</th>\n",
       "      <th>Att79</th>\n",
       "      <th>Att80</th>\n",
       "      <th>Att81</th>\n",
       "      <th>Att82</th>\n",
       "      <th>Att83</th>\n",
       "      <th>Att84</th>\n",
       "      <th>Att85</th>\n",
       "      <th>Att86</th>\n",
       "      <th>Att87</th>\n",
       "      <th>Att88</th>\n",
       "      <th>Att89</th>\n",
       "      <th>Att90</th>\n",
       "      <th>Att91</th>\n",
       "      <th>Att92</th>\n",
       "      <th>Att93</th>\n",
       "      <th>Att94</th>\n",
       "      <th>Att95</th>\n",
       "      <th>Att96</th>\n",
       "      <th>Att97</th>\n",
       "      <th>Att98</th>\n",
       "      <th>Att99</th>\n",
       "      <th>Att100</th>\n",
       "      <th>Att101</th>\n",
       "      <th>Att102</th>\n",
       "      <th>Att103</th>\n",
       "      <th>Class1</th>\n",
       "      <th>Class2</th>\n",
       "      <th>Class3</th>\n",
       "      <th>Class4</th>\n",
       "      <th>Class5</th>\n",
       "      <th>Class6</th>\n",
       "      <th>Class7</th>\n",
       "      <th>Class8</th>\n",
       "      <th>Class9</th>\n",
       "      <th>Class10</th>\n",
       "      <th>Class11</th>\n",
       "      <th>Class12</th>\n",
       "      <th>Class13</th>\n",
       "      <th>Class14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004168</td>\n",
       "      <td>-0.170975</td>\n",
       "      <td>-0.156748</td>\n",
       "      <td>-0.142151</td>\n",
       "      <td>0.058781</td>\n",
       "      <td>0.026851</td>\n",
       "      <td>0.197719</td>\n",
       "      <td>0.041850</td>\n",
       "      <td>0.066938</td>\n",
       "      <td>-0.056617</td>\n",
       "      <td>-0.027230</td>\n",
       "      <td>-0.137411</td>\n",
       "      <td>0.067776</td>\n",
       "      <td>0.047175</td>\n",
       "      <td>0.155671</td>\n",
       "      <td>0.050766</td>\n",
       "      <td>0.102557</td>\n",
       "      <td>-0.020259</td>\n",
       "      <td>-0.200512</td>\n",
       "      <td>-0.095371</td>\n",
       "      <td>-0.081940</td>\n",
       "      <td>-0.103735</td>\n",
       "      <td>0.093299</td>\n",
       "      <td>0.105475</td>\n",
       "      <td>0.148560</td>\n",
       "      <td>0.085925</td>\n",
       "      <td>0.107879</td>\n",
       "      <td>0.108075</td>\n",
       "      <td>0.085388</td>\n",
       "      <td>0.124026</td>\n",
       "      <td>-0.003650</td>\n",
       "      <td>-0.127376</td>\n",
       "      <td>0.039394</td>\n",
       "      <td>-0.018364</td>\n",
       "      <td>0.050378</td>\n",
       "      <td>0.157190</td>\n",
       "      <td>0.203563</td>\n",
       "      <td>0.111552</td>\n",
       "      <td>0.017907</td>\n",
       "      <td>-0.001126</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.175325</td>\n",
       "      <td>-0.133636</td>\n",
       "      <td>0.005524</td>\n",
       "      <td>-0.014981</td>\n",
       "      <td>-0.031946</td>\n",
       "      <td>-0.015114</td>\n",
       "      <td>-0.047175</td>\n",
       "      <td>0.003829</td>\n",
       "      <td>0.010967</td>\n",
       "      <td>-0.006062</td>\n",
       "      <td>-0.027560</td>\n",
       "      <td>-0.019866</td>\n",
       "      <td>-0.024046</td>\n",
       "      <td>-0.025153</td>\n",
       "      <td>-0.009261</td>\n",
       "      <td>-0.025539</td>\n",
       "      <td>0.006166</td>\n",
       "      <td>-0.012976</td>\n",
       "      <td>-0.014259</td>\n",
       "      <td>-0.015024</td>\n",
       "      <td>-0.010747</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>-0.032056</td>\n",
       "      <td>-0.018312</td>\n",
       "      <td>0.030126</td>\n",
       "      <td>0.124722</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.103956</td>\n",
       "      <td>0.011879</td>\n",
       "      <td>-0.098986</td>\n",
       "      <td>-0.054501</td>\n",
       "      <td>-0.007970</td>\n",
       "      <td>0.049113</td>\n",
       "      <td>-0.030580</td>\n",
       "      <td>-0.077933</td>\n",
       "      <td>-0.080529</td>\n",
       "      <td>-0.016267</td>\n",
       "      <td>-0.215304</td>\n",
       "      <td>-0.009885</td>\n",
       "      <td>-0.155843</td>\n",
       "      <td>-0.059522</td>\n",
       "      <td>-0.098836</td>\n",
       "      <td>-0.071141</td>\n",
       "      <td>-0.023494</td>\n",
       "      <td>-0.071200</td>\n",
       "      <td>0.027767</td>\n",
       "      <td>0.003091</td>\n",
       "      <td>-0.003761</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>0.053080</td>\n",
       "      <td>-0.008138</td>\n",
       "      <td>0.001794</td>\n",
       "      <td>-0.111704</td>\n",
       "      <td>-0.140291</td>\n",
       "      <td>-0.063347</td>\n",
       "      <td>0.066767</td>\n",
       "      <td>-0.167073</td>\n",
       "      <td>-0.095567</td>\n",
       "      <td>-0.047209</td>\n",
       "      <td>0.082206</td>\n",
       "      <td>0.144445</td>\n",
       "      <td>0.086581</td>\n",
       "      <td>-0.111850</td>\n",
       "      <td>-0.086560</td>\n",
       "      <td>0.024942</td>\n",
       "      <td>-0.131539</td>\n",
       "      <td>0.080062</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001249</td>\n",
       "      <td>-0.020209</td>\n",
       "      <td>-0.077359</td>\n",
       "      <td>-0.045139</td>\n",
       "      <td>-0.074738</td>\n",
       "      <td>0.051846</td>\n",
       "      <td>0.009323</td>\n",
       "      <td>0.184332</td>\n",
       "      <td>0.420424</td>\n",
       "      <td>-0.090224</td>\n",
       "      <td>-0.090718</td>\n",
       "      <td>-0.035266</td>\n",
       "      <td>-0.046729</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>-0.066023</td>\n",
       "      <td>-0.051916</td>\n",
       "      <td>0.007680</td>\n",
       "      <td>0.027719</td>\n",
       "      <td>-0.085811</td>\n",
       "      <td>0.111123</td>\n",
       "      <td>0.050541</td>\n",
       "      <td>0.027565</td>\n",
       "      <td>-0.063569</td>\n",
       "      <td>-0.041471</td>\n",
       "      <td>-0.079758</td>\n",
       "      <td>0.017161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.509949</td>\n",
       "      <td>0.401709</td>\n",
       "      <td>0.293799</td>\n",
       "      <td>0.087714</td>\n",
       "      <td>0.011686</td>\n",
       "      <td>-0.006411</td>\n",
       "      <td>-0.006255</td>\n",
       "      <td>0.013646</td>\n",
       "      <td>-0.040666</td>\n",
       "      <td>-0.024447</td>\n",
       "      <td>-0.040576</td>\n",
       "      <td>0.014326</td>\n",
       "      <td>-0.074968</td>\n",
       "      <td>0.141365</td>\n",
       "      <td>-0.015182</td>\n",
       "      <td>0.013691</td>\n",
       "      <td>0.006893</td>\n",
       "      <td>0.003736</td>\n",
       "      <td>-0.020726</td>\n",
       "      <td>-0.044104</td>\n",
       "      <td>-0.052959</td>\n",
       "      <td>-0.085572</td>\n",
       "      <td>-0.061547</td>\n",
       "      <td>-0.029578</td>\n",
       "      <td>0.027700</td>\n",
       "      <td>-0.094310</td>\n",
       "      <td>-0.047721</td>\n",
       "      <td>-0.081589</td>\n",
       "      <td>-0.022846</td>\n",
       "      <td>-0.106684</td>\n",
       "      <td>-0.068873</td>\n",
       "      <td>-0.105225</td>\n",
       "      <td>-0.065414</td>\n",
       "      <td>-0.047722</td>\n",
       "      <td>-0.070723</td>\n",
       "      <td>-0.057425</td>\n",
       "      <td>-0.042024</td>\n",
       "      <td>-0.034122</td>\n",
       "      <td>-0.049606</td>\n",
       "      <td>0.015137</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002432</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>-0.083572</td>\n",
       "      <td>-0.096943</td>\n",
       "      <td>0.148457</td>\n",
       "      <td>-0.007413</td>\n",
       "      <td>0.130691</td>\n",
       "      <td>-0.032325</td>\n",
       "      <td>0.028612</td>\n",
       "      <td>-0.023051</td>\n",
       "      <td>-0.092214</td>\n",
       "      <td>-0.103336</td>\n",
       "      <td>0.138232</td>\n",
       "      <td>-0.100351</td>\n",
       "      <td>0.140423</td>\n",
       "      <td>0.110074</td>\n",
       "      <td>0.096277</td>\n",
       "      <td>-0.044932</td>\n",
       "      <td>-0.089470</td>\n",
       "      <td>-0.009162</td>\n",
       "      <td>-0.012010</td>\n",
       "      <td>0.308378</td>\n",
       "      <td>-0.028053</td>\n",
       "      <td>0.026710</td>\n",
       "      <td>-0.066565</td>\n",
       "      <td>-0.122352</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.119092</td>\n",
       "      <td>0.004412</td>\n",
       "      <td>-0.002262</td>\n",
       "      <td>0.072254</td>\n",
       "      <td>0.044512</td>\n",
       "      <td>-0.051467</td>\n",
       "      <td>0.074686</td>\n",
       "      <td>-0.007670</td>\n",
       "      <td>0.079438</td>\n",
       "      <td>0.062184</td>\n",
       "      <td>-0.013027</td>\n",
       "      <td>0.045538</td>\n",
       "      <td>0.080412</td>\n",
       "      <td>-0.010042</td>\n",
       "      <td>0.013029</td>\n",
       "      <td>-0.071975</td>\n",
       "      <td>0.089818</td>\n",
       "      <td>-0.016129</td>\n",
       "      <td>0.033105</td>\n",
       "      <td>0.024275</td>\n",
       "      <td>0.040428</td>\n",
       "      <td>0.064248</td>\n",
       "      <td>0.225613</td>\n",
       "      <td>0.176576</td>\n",
       "      <td>0.015501</td>\n",
       "      <td>0.009491</td>\n",
       "      <td>-0.013684</td>\n",
       "      <td>-0.017633</td>\n",
       "      <td>0.085007</td>\n",
       "      <td>-0.056274</td>\n",
       "      <td>-0.088925</td>\n",
       "      <td>-0.062951</td>\n",
       "      <td>0.227151</td>\n",
       "      <td>0.165897</td>\n",
       "      <td>0.150224</td>\n",
       "      <td>0.065105</td>\n",
       "      <td>0.110891</td>\n",
       "      <td>0.048451</td>\n",
       "      <td>0.114726</td>\n",
       "      <td>0.020393</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.111806</td>\n",
       "      <td>-0.154732</td>\n",
       "      <td>0.302807</td>\n",
       "      <td>0.340027</td>\n",
       "      <td>-0.093332</td>\n",
       "      <td>-0.057848</td>\n",
       "      <td>-0.010558</td>\n",
       "      <td>-0.039194</td>\n",
       "      <td>-0.041628</td>\n",
       "      <td>-0.077455</td>\n",
       "      <td>-0.008553</td>\n",
       "      <td>-0.022404</td>\n",
       "      <td>-0.106131</td>\n",
       "      <td>-0.103067</td>\n",
       "      <td>-0.083059</td>\n",
       "      <td>-0.089064</td>\n",
       "      <td>-0.083809</td>\n",
       "      <td>0.200354</td>\n",
       "      <td>-0.075716</td>\n",
       "      <td>0.196605</td>\n",
       "      <td>0.152758</td>\n",
       "      <td>-0.028484</td>\n",
       "      <td>-0.074207</td>\n",
       "      <td>-0.089227</td>\n",
       "      <td>-0.049913</td>\n",
       "      <td>-0.043893</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.042037</td>\n",
       "      <td>0.007054</td>\n",
       "      <td>-0.069483</td>\n",
       "      <td>0.081015</td>\n",
       "      <td>-0.048207</td>\n",
       "      <td>0.089446</td>\n",
       "      <td>-0.004947</td>\n",
       "      <td>0.064456</td>\n",
       "      <td>-0.133387</td>\n",
       "      <td>0.068878</td>\n",
       "      <td>-0.139371</td>\n",
       "      <td>0.041487</td>\n",
       "      <td>-0.058531</td>\n",
       "      <td>0.021264</td>\n",
       "      <td>-0.101382</td>\n",
       "      <td>0.021015</td>\n",
       "      <td>0.096572</td>\n",
       "      <td>-0.005136</td>\n",
       "      <td>0.111104</td>\n",
       "      <td>-0.008323</td>\n",
       "      <td>0.020210</td>\n",
       "      <td>-0.003967</td>\n",
       "      <td>0.039762</td>\n",
       "      <td>0.006744</td>\n",
       "      <td>-0.041730</td>\n",
       "      <td>-0.174533</td>\n",
       "      <td>-0.101343</td>\n",
       "      <td>-0.115674</td>\n",
       "      <td>0.328511</td>\n",
       "      <td>-0.108945</td>\n",
       "      <td>-0.160748</td>\n",
       "      <td>-0.120290</td>\n",
       "      <td>-0.148308</td>\n",
       "      <td>-0.082882</td>\n",
       "      <td>-0.127218</td>\n",
       "      <td>-0.167186</td>\n",
       "      <td>-0.143210</td>\n",
       "      <td>-0.118028</td>\n",
       "      <td>-0.297516</td>\n",
       "      <td>-0.160082</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108388</td>\n",
       "      <td>0.095516</td>\n",
       "      <td>0.015942</td>\n",
       "      <td>0.087354</td>\n",
       "      <td>0.176911</td>\n",
       "      <td>-0.062311</td>\n",
       "      <td>0.117205</td>\n",
       "      <td>-0.048277</td>\n",
       "      <td>-0.053679</td>\n",
       "      <td>0.014850</td>\n",
       "      <td>-0.066453</td>\n",
       "      <td>-0.067962</td>\n",
       "      <td>-0.083653</td>\n",
       "      <td>-0.081130</td>\n",
       "      <td>-0.061469</td>\n",
       "      <td>0.023662</td>\n",
       "      <td>-0.060467</td>\n",
       "      <td>0.044351</td>\n",
       "      <td>-0.057209</td>\n",
       "      <td>0.028047</td>\n",
       "      <td>0.029661</td>\n",
       "      <td>-0.050026</td>\n",
       "      <td>0.023248</td>\n",
       "      <td>-0.061539</td>\n",
       "      <td>-0.035160</td>\n",
       "      <td>0.067834</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2412</th>\n",
       "      <td>-0.119784</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>-0.123645</td>\n",
       "      <td>-0.015513</td>\n",
       "      <td>-0.059683</td>\n",
       "      <td>0.091032</td>\n",
       "      <td>-0.043302</td>\n",
       "      <td>0.229219</td>\n",
       "      <td>-0.071498</td>\n",
       "      <td>0.182709</td>\n",
       "      <td>-0.169902</td>\n",
       "      <td>0.254843</td>\n",
       "      <td>-0.179968</td>\n",
       "      <td>0.173563</td>\n",
       "      <td>-0.060754</td>\n",
       "      <td>0.111926</td>\n",
       "      <td>0.055960</td>\n",
       "      <td>0.293560</td>\n",
       "      <td>0.017478</td>\n",
       "      <td>-0.081646</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>-0.079165</td>\n",
       "      <td>-0.030758</td>\n",
       "      <td>0.057605</td>\n",
       "      <td>-0.069617</td>\n",
       "      <td>-0.152909</td>\n",
       "      <td>-0.013818</td>\n",
       "      <td>-0.134586</td>\n",
       "      <td>0.035602</td>\n",
       "      <td>-0.111456</td>\n",
       "      <td>-0.013309</td>\n",
       "      <td>-0.169705</td>\n",
       "      <td>-0.116210</td>\n",
       "      <td>-0.088351</td>\n",
       "      <td>-0.059824</td>\n",
       "      <td>0.055180</td>\n",
       "      <td>-0.015347</td>\n",
       "      <td>-0.054320</td>\n",
       "      <td>-0.158766</td>\n",
       "      <td>-0.038536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057122</td>\n",
       "      <td>0.103497</td>\n",
       "      <td>-0.064997</td>\n",
       "      <td>-0.019628</td>\n",
       "      <td>0.012507</td>\n",
       "      <td>0.209633</td>\n",
       "      <td>-0.081401</td>\n",
       "      <td>-0.057052</td>\n",
       "      <td>-0.077347</td>\n",
       "      <td>-0.076410</td>\n",
       "      <td>-0.077983</td>\n",
       "      <td>-0.021983</td>\n",
       "      <td>0.053034</td>\n",
       "      <td>0.191556</td>\n",
       "      <td>0.183931</td>\n",
       "      <td>0.065281</td>\n",
       "      <td>0.024084</td>\n",
       "      <td>-0.055915</td>\n",
       "      <td>-0.055593</td>\n",
       "      <td>-0.049642</td>\n",
       "      <td>0.018571</td>\n",
       "      <td>0.068742</td>\n",
       "      <td>-0.061001</td>\n",
       "      <td>-0.081132</td>\n",
       "      <td>-0.065844</td>\n",
       "      <td>0.001267</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2413</th>\n",
       "      <td>0.085327</td>\n",
       "      <td>0.058590</td>\n",
       "      <td>0.085268</td>\n",
       "      <td>-0.020897</td>\n",
       "      <td>0.068972</td>\n",
       "      <td>0.030125</td>\n",
       "      <td>0.078056</td>\n",
       "      <td>0.011346</td>\n",
       "      <td>0.052618</td>\n",
       "      <td>0.066093</td>\n",
       "      <td>0.028501</td>\n",
       "      <td>0.037778</td>\n",
       "      <td>0.056401</td>\n",
       "      <td>0.073084</td>\n",
       "      <td>0.054199</td>\n",
       "      <td>0.010155</td>\n",
       "      <td>0.033694</td>\n",
       "      <td>0.022873</td>\n",
       "      <td>0.075112</td>\n",
       "      <td>0.092810</td>\n",
       "      <td>0.098595</td>\n",
       "      <td>0.059712</td>\n",
       "      <td>0.089367</td>\n",
       "      <td>0.056306</td>\n",
       "      <td>-0.010929</td>\n",
       "      <td>0.029214</td>\n",
       "      <td>0.028160</td>\n",
       "      <td>0.017634</td>\n",
       "      <td>0.005513</td>\n",
       "      <td>0.047156</td>\n",
       "      <td>0.100123</td>\n",
       "      <td>0.102521</td>\n",
       "      <td>-0.038055</td>\n",
       "      <td>-0.092468</td>\n",
       "      <td>-0.096875</td>\n",
       "      <td>-0.026086</td>\n",
       "      <td>0.048201</td>\n",
       "      <td>0.062117</td>\n",
       "      <td>0.052804</td>\n",
       "      <td>0.005024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030045</td>\n",
       "      <td>-0.049208</td>\n",
       "      <td>-0.061023</td>\n",
       "      <td>-0.073127</td>\n",
       "      <td>-0.054131</td>\n",
       "      <td>0.230720</td>\n",
       "      <td>-0.054853</td>\n",
       "      <td>0.137628</td>\n",
       "      <td>0.150380</td>\n",
       "      <td>-0.029207</td>\n",
       "      <td>0.198999</td>\n",
       "      <td>0.240646</td>\n",
       "      <td>-0.102721</td>\n",
       "      <td>-0.099789</td>\n",
       "      <td>-0.078345</td>\n",
       "      <td>-0.084716</td>\n",
       "      <td>-0.079992</td>\n",
       "      <td>-0.075444</td>\n",
       "      <td>0.294987</td>\n",
       "      <td>-0.076379</td>\n",
       "      <td>-0.076293</td>\n",
       "      <td>-0.072451</td>\n",
       "      <td>-0.052258</td>\n",
       "      <td>-0.040026</td>\n",
       "      <td>0.342176</td>\n",
       "      <td>-0.169668</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2414</th>\n",
       "      <td>0.082526</td>\n",
       "      <td>-0.095571</td>\n",
       "      <td>-0.022019</td>\n",
       "      <td>-0.046793</td>\n",
       "      <td>-0.038360</td>\n",
       "      <td>0.041084</td>\n",
       "      <td>0.056509</td>\n",
       "      <td>0.011749</td>\n",
       "      <td>-0.029657</td>\n",
       "      <td>-0.012198</td>\n",
       "      <td>-0.008540</td>\n",
       "      <td>-0.013902</td>\n",
       "      <td>-0.068013</td>\n",
       "      <td>0.042327</td>\n",
       "      <td>0.052293</td>\n",
       "      <td>0.050993</td>\n",
       "      <td>0.082892</td>\n",
       "      <td>-0.009390</td>\n",
       "      <td>0.029446</td>\n",
       "      <td>0.053463</td>\n",
       "      <td>0.074409</td>\n",
       "      <td>0.091427</td>\n",
       "      <td>0.059711</td>\n",
       "      <td>-0.020000</td>\n",
       "      <td>-0.020922</td>\n",
       "      <td>-0.073768</td>\n",
       "      <td>-0.061061</td>\n",
       "      <td>-0.091906</td>\n",
       "      <td>-0.046665</td>\n",
       "      <td>-0.041211</td>\n",
       "      <td>-0.047039</td>\n",
       "      <td>0.040556</td>\n",
       "      <td>-0.071408</td>\n",
       "      <td>-0.162032</td>\n",
       "      <td>-0.163358</td>\n",
       "      <td>0.012145</td>\n",
       "      <td>0.076758</td>\n",
       "      <td>-0.005729</td>\n",
       "      <td>-0.026470</td>\n",
       "      <td>-0.108322</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083398</td>\n",
       "      <td>-0.059522</td>\n",
       "      <td>-0.004905</td>\n",
       "      <td>-0.069757</td>\n",
       "      <td>0.293519</td>\n",
       "      <td>0.164906</td>\n",
       "      <td>0.172683</td>\n",
       "      <td>-0.024597</td>\n",
       "      <td>-0.056481</td>\n",
       "      <td>0.086025</td>\n",
       "      <td>-0.070759</td>\n",
       "      <td>-0.076122</td>\n",
       "      <td>-0.076408</td>\n",
       "      <td>-0.064713</td>\n",
       "      <td>-0.040290</td>\n",
       "      <td>-0.077142</td>\n",
       "      <td>-0.006624</td>\n",
       "      <td>-0.036850</td>\n",
       "      <td>-0.064831</td>\n",
       "      <td>-0.068696</td>\n",
       "      <td>-0.068521</td>\n",
       "      <td>-0.039841</td>\n",
       "      <td>0.274575</td>\n",
       "      <td>-0.066957</td>\n",
       "      <td>0.260121</td>\n",
       "      <td>-0.125303</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2415</th>\n",
       "      <td>-0.130830</td>\n",
       "      <td>0.008868</td>\n",
       "      <td>-0.009457</td>\n",
       "      <td>-0.058930</td>\n",
       "      <td>-0.041224</td>\n",
       "      <td>0.042269</td>\n",
       "      <td>0.117717</td>\n",
       "      <td>0.037388</td>\n",
       "      <td>-0.085563</td>\n",
       "      <td>0.136649</td>\n",
       "      <td>-0.255284</td>\n",
       "      <td>-0.334406</td>\n",
       "      <td>-0.194436</td>\n",
       "      <td>-0.046137</td>\n",
       "      <td>0.049138</td>\n",
       "      <td>0.014249</td>\n",
       "      <td>0.063691</td>\n",
       "      <td>-0.065423</td>\n",
       "      <td>-0.084182</td>\n",
       "      <td>0.013208</td>\n",
       "      <td>-0.043259</td>\n",
       "      <td>-0.122727</td>\n",
       "      <td>-0.119400</td>\n",
       "      <td>-0.082374</td>\n",
       "      <td>-0.033362</td>\n",
       "      <td>-0.012996</td>\n",
       "      <td>0.014870</td>\n",
       "      <td>-0.023433</td>\n",
       "      <td>-0.023071</td>\n",
       "      <td>0.020958</td>\n",
       "      <td>0.035999</td>\n",
       "      <td>-0.025947</td>\n",
       "      <td>-0.079952</td>\n",
       "      <td>-0.137046</td>\n",
       "      <td>0.058524</td>\n",
       "      <td>0.093744</td>\n",
       "      <td>0.109146</td>\n",
       "      <td>0.013801</td>\n",
       "      <td>-0.008219</td>\n",
       "      <td>0.063381</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023212</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>-0.113469</td>\n",
       "      <td>-0.130450</td>\n",
       "      <td>-0.109596</td>\n",
       "      <td>0.032658</td>\n",
       "      <td>0.147271</td>\n",
       "      <td>0.108450</td>\n",
       "      <td>0.023597</td>\n",
       "      <td>0.195494</td>\n",
       "      <td>-0.093824</td>\n",
       "      <td>-0.072476</td>\n",
       "      <td>-0.034463</td>\n",
       "      <td>-0.000725</td>\n",
       "      <td>-0.114834</td>\n",
       "      <td>0.085087</td>\n",
       "      <td>0.033166</td>\n",
       "      <td>-0.012710</td>\n",
       "      <td>0.135359</td>\n",
       "      <td>0.213512</td>\n",
       "      <td>-0.107561</td>\n",
       "      <td>-0.081925</td>\n",
       "      <td>-0.122332</td>\n",
       "      <td>-0.022453</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2416</th>\n",
       "      <td>-0.171578</td>\n",
       "      <td>-0.066536</td>\n",
       "      <td>0.168206</td>\n",
       "      <td>0.246831</td>\n",
       "      <td>0.079555</td>\n",
       "      <td>0.016528</td>\n",
       "      <td>-0.088908</td>\n",
       "      <td>-0.212926</td>\n",
       "      <td>-0.280230</td>\n",
       "      <td>-0.187064</td>\n",
       "      <td>0.021891</td>\n",
       "      <td>0.257780</td>\n",
       "      <td>0.181716</td>\n",
       "      <td>0.122069</td>\n",
       "      <td>0.008877</td>\n",
       "      <td>-0.067158</td>\n",
       "      <td>-0.067343</td>\n",
       "      <td>-0.168937</td>\n",
       "      <td>-0.124432</td>\n",
       "      <td>-0.172594</td>\n",
       "      <td>0.053653</td>\n",
       "      <td>0.009450</td>\n",
       "      <td>0.053303</td>\n",
       "      <td>0.090438</td>\n",
       "      <td>0.085904</td>\n",
       "      <td>0.069243</td>\n",
       "      <td>0.030781</td>\n",
       "      <td>0.074417</td>\n",
       "      <td>0.066347</td>\n",
       "      <td>-0.050537</td>\n",
       "      <td>-0.046217</td>\n",
       "      <td>0.106744</td>\n",
       "      <td>-0.081458</td>\n",
       "      <td>0.173149</td>\n",
       "      <td>0.196126</td>\n",
       "      <td>0.057334</td>\n",
       "      <td>-0.046731</td>\n",
       "      <td>-0.171364</td>\n",
       "      <td>0.086061</td>\n",
       "      <td>0.148047</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037724</td>\n",
       "      <td>-0.097965</td>\n",
       "      <td>-0.062793</td>\n",
       "      <td>0.020469</td>\n",
       "      <td>-0.091561</td>\n",
       "      <td>-0.056605</td>\n",
       "      <td>0.087247</td>\n",
       "      <td>-0.012466</td>\n",
       "      <td>-0.037839</td>\n",
       "      <td>-0.074064</td>\n",
       "      <td>-0.076054</td>\n",
       "      <td>0.081239</td>\n",
       "      <td>-0.007374</td>\n",
       "      <td>0.056464</td>\n",
       "      <td>0.054823</td>\n",
       "      <td>0.034766</td>\n",
       "      <td>0.360199</td>\n",
       "      <td>-0.058178</td>\n",
       "      <td>-0.003104</td>\n",
       "      <td>-0.016028</td>\n",
       "      <td>0.054244</td>\n",
       "      <td>-0.017797</td>\n",
       "      <td>-0.081870</td>\n",
       "      <td>-0.083342</td>\n",
       "      <td>-0.063135</td>\n",
       "      <td>0.018810</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2417 rows × 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Att1      Att2      Att3  ...  Class12  Class13  Class14\n",
       "0     0.004168 -0.170975 -0.156748  ...        1        1        0\n",
       "1    -0.103956  0.011879 -0.098986  ...        0        0        0\n",
       "2     0.509949  0.401709  0.293799  ...        1        1        0\n",
       "3     0.119092  0.004412 -0.002262  ...        0        0        0\n",
       "4     0.042037  0.007054 -0.069483  ...        0        0        0\n",
       "...        ...       ...       ...  ...      ...      ...      ...\n",
       "2412 -0.119784  0.001259 -0.123645  ...        0        0        0\n",
       "2413  0.085327  0.058590  0.085268  ...        1        1        0\n",
       "2414  0.082526 -0.095571 -0.022019  ...        1        1        0\n",
       "2415 -0.130830  0.008868 -0.009457  ...        1        1        0\n",
       "2416 -0.171578 -0.066536  0.168206  ...        1        1        0\n",
       "\n",
       "[2417 rows x 117 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "yeast_raw_file_name = os.getcwd() + \"/data/\" + \"./datasets/yeast.arff\"\n",
    "assert(os.path.isfile(yeast_raw_file_name))\n",
    "\n",
    "# Load ARFF file\n",
    "data, meta = arff.loadarff(yeast_raw_file_name)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Optionally, decode byte strings to regular strings if necessary\n",
    "df = df.map(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38d593b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(          Att1      Att2      Att3  ...    Att101    Att102    Att103\n",
       " 0     0.004168 -0.170975 -0.156748  ... -0.018312  0.030126  0.124722\n",
       " 1    -0.103956  0.011879 -0.098986  ... -0.041471 -0.079758  0.017161\n",
       " 2     0.509949  0.401709  0.293799  ...  0.026710 -0.066565 -0.122352\n",
       " 3     0.119092  0.004412 -0.002262  ... -0.089227 -0.049913 -0.043893\n",
       " 4     0.042037  0.007054 -0.069483  ... -0.061539 -0.035160  0.067834\n",
       " ...        ...       ...       ...  ...       ...       ...       ...\n",
       " 2412 -0.119784  0.001259 -0.123645  ... -0.081132 -0.065844  0.001267\n",
       " 2413  0.085327  0.058590  0.085268  ... -0.040026  0.342176 -0.169668\n",
       " 2414  0.082526 -0.095571 -0.022019  ... -0.066957  0.260121 -0.125303\n",
       " 2415 -0.130830  0.008868 -0.009457  ... -0.122332 -0.022453  0.001953\n",
       " 2416 -0.171578 -0.066536  0.168206  ... -0.083342 -0.063135  0.018810\n",
       " \n",
       " [2417 rows x 103 columns],\n",
       "      Class1 Class2 Class3 Class4 Class5  ... Class10 Class11 Class12 Class13 Class14\n",
       " 0         0      0      0      0      0  ...       0       0       1       1       0\n",
       " 1         0      0      1      1      0  ...       0       0       0       0       0\n",
       " 2         0      1      1      0      0  ...       0       0       1       1       0\n",
       " 3         0      0      1      1      0  ...       0       0       0       0       0\n",
       " 4         0      0      1      1      1  ...       0       0       0       0       0\n",
       " ...     ...    ...    ...    ...    ...  ...     ...     ...     ...     ...     ...\n",
       " 2412      0      1      1      0      0  ...       0       0       0       0       0\n",
       " 2413      1      1      0      0      0  ...       0       0       1       1       0\n",
       " 2414      0      0      0      0      0  ...       0       0       1       1       0\n",
       " 2415      0      0      0      0      0  ...       0       0       1       1       0\n",
       " 2416      0      1      1      0      0  ...       0       0       1       1       0\n",
       " \n",
       " [2417 rows x 14 columns])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = df.columns[df.columns.str.startswith('Att')]\n",
    "\n",
    "X = df[columns]\n",
    "y = df.drop(columns=columns)\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68d11122",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_files:\n",
    "    X.to_csv(\"./data/6-YEAST_X.csv\", index=False)\n",
    "    y.to_csv(\"./data/6-YEAST_y.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c5750c",
   "metadata": {},
   "source": [
    "## 7. Birds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "04853e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['L1', 'L2', 'L3', 'L4', 'L5', 'L6', 'L7', 'L8', 'L9', 'L10',\n",
       "       ...\n",
       "       'A251', 'A252', 'A253', 'A254', 'A255', 'A256', 'A257', 'A258', 'A259',\n",
       "       'A260'],\n",
       "      dtype='object', length=279)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "birds_csv_file = os.getcwd() + \"/data/\" + \"./datasets/7-BIRDS.csv\"\n",
    "df = pd.read_csv(birds_csv_file)\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3cb84142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(           A1        A2        A3  ...         A258  A259  A260\n",
       " 0    0.016521  0.039926  0.089632  ...  1761.802180     1     1\n",
       " 1    0.006600  0.035984  0.089956  ...     0.000000     0     1\n",
       " 2    0.006894  0.017722  0.048062  ...   113.137085     1     1\n",
       " 3    0.031046  0.127675  0.221428  ...     0.000000     0     1\n",
       " 4    0.064721  0.226644  0.304482  ...     0.000000     0     1\n",
       " ..        ...       ...       ...  ...          ...   ...   ...\n",
       " 640  0.065968  0.005699  0.009809  ...     0.000000     0    17\n",
       " 641  0.037432  0.010440  0.021009  ...     0.000000     0    17\n",
       " 642  0.200058  0.054787  0.137048  ...     0.000000     0    17\n",
       " 643  0.064331  0.012261  0.022449  ...     0.000000     0    17\n",
       " 644  0.008697  0.012031  0.021212  ...     0.000000     0    17\n",
       " \n",
       " [645 rows x 260 columns],\n",
       "      L1  L2  L3  L4  L5  L6  L7  L8  ...  L12  L13  L14  L15  L16  L17  L18  L19\n",
       " 0     0   0   0   0   0   0   0   0  ...    1    1    0    0    0    0    0    0\n",
       " 1     0   0   0   0   0   0   0   0  ...    0    0    0    0    0    0    0    0\n",
       " 2     0   0   0   0   0   0   0   0  ...    0    0    0    0    0    0    0    0\n",
       " 3     0   0   0   0   0   0   0   0  ...    0    0    0    0    0    0    0    0\n",
       " 4     0   0   0   0   0   0   0   0  ...    0    0    0    0    0    0    0    0\n",
       " ..   ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
       " 640   0   0   0   0   0   0   0   0  ...    0    0    0    0    0    0    0    0\n",
       " 641   0   0   0   0   0   0   0   0  ...    0    0    0    0    0    0    0    0\n",
       " 642   0   0   0   0   0   0   0   0  ...    0    0    0    0    0    0    0    0\n",
       " 643   0   0   0   0   0   0   0   0  ...    0    0    0    0    0    0    0    0\n",
       " 644   0   0   0   0   0   0   0   0  ...    0    0    0    0    0    0    0    0\n",
       " \n",
       " [645 rows x 19 columns])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[df.columns[df.columns.str.startswith('A')]]  # Selecting columns with names starting with 'A'\n",
    "y = df[df.columns[df.columns.str.startswith('L')]]  # Selecting columns with names starting with 'L'\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "113e2a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_files:\n",
    "    X.to_csv(\"./data/7-BIRDS_X.csv\", index=False)\n",
    "    y.to_csv(\"./data/7-BIRDS_y.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13134354",
   "metadata": {},
   "source": [
    "## 8. Genbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87187d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  protein PS00010 PS00011 PS00012  ... PDOC50199 PDOC00660 PDOC00653 PDOC00030\n",
       " 0  O00060      NO      NO      NO  ...         0         0         0         0\n",
       " 1  O00139      NO      NO      NO  ...         0         0         0         0\n",
       " 2  O02741      NO      NO      NO  ...         0         0         0         0\n",
       " 3  O08424      NO      NO      NO  ...         0         0         0         0\n",
       " 4  O12984      NO      NO      NO  ...         0         0         0         0\n",
       " \n",
       " [5 rows x 1213 columns],\n",
       " Index(['protein', 'PS00010', 'PS00011', 'PS00012', 'PS00014', 'PS00017',\n",
       "        'PS00018', 'PS00019', 'PS00020', 'PS00021',\n",
       "        ...\n",
       "        'PDOC00662', 'PDOC00018', 'PDOC50001', 'PDOC00014', 'PDOC00750',\n",
       "        'PDOC50196', 'PDOC50199', 'PDOC00660', 'PDOC00653', 'PDOC00030'],\n",
       "       dtype='object', length=1213))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "genbase_raw_file_name = os.getcwd() + \"/data/\" + \"./datasets/genbase.arff\"\n",
    "assert(os.path.isfile(genbase_raw_file_name))\n",
    "\n",
    "# Load ARFF file\n",
    "data, meta = arff.loadarff(genbase_raw_file_name,)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Optionally, decode byte strings to regular strings if necessary\n",
    "df = df.map(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
    "\n",
    "df.head(), df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aba60513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     protein  PS00010  PS00011  PS00012  ...  PS50827  PS50829  PS50830  PS60000\n",
       " 0          0        0        0        0  ...        0        0        0        0\n",
       " 1          1        0        0        0  ...        0        0        0        0\n",
       " 2          2        0        0        0  ...        0        0        0        0\n",
       " 3          3        0        0        0  ...        0        0        0        0\n",
       " 4          4        0        0        0  ...        0        0        0        0\n",
       " ..       ...      ...      ...      ...  ...      ...      ...      ...      ...\n",
       " 657      657        0        0        0  ...        0        0        0        0\n",
       " 658      658        0        0        0  ...        0        0        0        0\n",
       " 659      659        0        0        0  ...        0        0        0        0\n",
       " 660      660        0        0        0  ...        0        0        0        0\n",
       " 661      661        0        0        0  ...        0        0        0        0\n",
       " \n",
       " [662 rows x 1186 columns],\n",
       "     PDOC00154 PDOC00343 PDOC00271  ... PDOC00660 PDOC00653 PDOC00030\n",
       " 0           1         0         0  ...         0         0         0\n",
       " 1           0         1         0  ...         0         0         0\n",
       " 2           0         0         1  ...         0         0         0\n",
       " 3           0         0         0  ...         0         0         0\n",
       " 4           0         0         0  ...         0         0         0\n",
       " ..        ...       ...       ...  ...       ...       ...       ...\n",
       " 657         0         0         0  ...         0         0         0\n",
       " 658         0         0         0  ...         0         0         0\n",
       " 659         0         0         0  ...         0         0         0\n",
       " 660         0         0         0  ...         0         0         0\n",
       " 661         0         0         0  ...         0         0         0\n",
       " \n",
       " [662 rows x 27 columns])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = df.columns[df.columns.str.startswith('PDOC')]\n",
    "\n",
    "X = df.drop(columns=columns)\n",
    "y = df[columns]\n",
    "\n",
    "for x in X.columns:\n",
    "    if X[x].dtype == 'object':\n",
    "        X[x] = label_encoder.fit_transform(X[x])\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e1631308",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_files:\n",
    "    X.to_csv(\"./data/8-GENBASE_X.csv\", index=False)\n",
    "    y.to_csv(\"./data/8-GENBASE_y.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1da308",
   "metadata": {},
   "source": [
    "## 9. Medical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "374d311c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   Class-0-593_70  Class-1-079_99  Class-2-786_09  ...  yesterday  zithromax  zone\n",
       " 0               0               0               0  ...          0          0     0\n",
       " 1               0               0               0  ...          0          0     0\n",
       " 2               0               0               0  ...          0          0     0\n",
       " 3               0               0               0  ...          0          0     0\n",
       " 4               1               0               0  ...          0          0     0\n",
       " \n",
       " [5 rows x 1494 columns],\n",
       " Index(['Class-0-593_70', 'Class-1-079_99', 'Class-2-786_09', 'Class-3-759_89',\n",
       "        'Class-4-753_0', 'Class-5-786_2', 'Class-6-V72_5', 'Class-7-511_9',\n",
       "        'Class-8-596_8', 'Class-9-599_0',\n",
       "        ...\n",
       "        'x2', 'x5', 'xray', 'year', 'year-old', 'yearly', 'years', 'yesterday',\n",
       "        'zithromax', 'zone'],\n",
       "       dtype='object', length=1494))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "medc_csv_file = os.getcwd() + \"/data/\" + \"./datasets/9-MEDC.csv\"\n",
    "df = pd.read_csv(medc_csv_file)\n",
    "\n",
    "df.head(), df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b70336ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     -  /  0  00  04  0;  ...  year-old  yearly  years  yesterday  zithromax  zone\n",
       " 0    0  0  0   0   0   0  ...         0       0      0          0          0     0\n",
       " 1    1  0  0   0   0   0  ...         0       0      0          0          0     0\n",
       " 2    1  0  0   0   0   0  ...         0       0      0          0          0     0\n",
       " 3    1  0  0   0   0   0  ...         0       0      0          0          0     0\n",
       " 4    0  0  0   0   0   0  ...         0       0      0          0          0     0\n",
       " ..  .. .. ..  ..  ..  ..  ...       ...     ...    ...        ...        ...   ...\n",
       " 973  0  0  0   0   0   0  ...         0       0      1          0          0     0\n",
       " 974  1  0  0   0   0   0  ...         1       0      0          0          0     0\n",
       " 975  1  0  0   0   0   0  ...         1       0      0          0          0     0\n",
       " 976  0  0  0   0   0   0  ...         0       0      0          0          0     0\n",
       " 977  1  0  0   0   0   0  ...         0       0      0          0          0     0\n",
       " \n",
       " [978 rows x 1449 columns],\n",
       "      Class-0-593_70  Class-1-079_99  ...  Class-43-279_12  Class-44-786_07\n",
       " 0                 0               0  ...                0                0\n",
       " 1                 0               0  ...                0                0\n",
       " 2                 0               0  ...                0                0\n",
       " 3                 0               0  ...                0                0\n",
       " 4                 1               0  ...                0                0\n",
       " ..              ...             ...  ...              ...              ...\n",
       " 973               0               0  ...                0                0\n",
       " 974               0               0  ...                0                1\n",
       " 975               0               0  ...                0                0\n",
       " 976               0               0  ...                0                1\n",
       " 977               0               0  ...                0                0\n",
       " \n",
       " [978 rows x 45 columns])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=df.columns[df.columns.str.startswith('Class')])  # Selecting columns with names starting with 'L'\n",
    "y = df[df.columns[df.columns.str.startswith('Class')]]  # Selecting columns with names starting with 'A'\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "02e40fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_files:\n",
    "    X.to_csv(\"./data/9-MEDC_X.csv\", index=False)\n",
    "    y.to_csv(\"./data/9-MEDC_y.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6b4110",
   "metadata": {},
   "source": [
    "## 10. Enron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "634a79b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   A.A8  C.C9  B.B12  C.C11  C.C5  ...  www  year  years  yesterday  york\n",
       " 0     0     0      0      0     0  ...    0     0      0          0     0\n",
       " 1     0     0      0      0     0  ...    0     0      0          0     0\n",
       " 2     0     0      0      0     0  ...    0     0      0          0     0\n",
       " 3     0     0      0      0     0  ...    0     0      0          0     0\n",
       " 4     0     0      0      0     0  ...    0     1      0          0     0\n",
       " \n",
       " [5 rows x 1054 columns],\n",
       " Index(['A.A8', 'C.C9', 'B.B12', 'C.C11', 'C.C5', 'C.C7', 'B.B2', 'B.B3',\n",
       "        'D.D16', 'A.A7',\n",
       "        ...\n",
       "        'workers', 'working', 'world', 'writer', 'writers', 'www', 'year',\n",
       "        'years', 'yesterday', 'york'],\n",
       "       dtype='object', length=1054))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "enron_csv_file = os.getcwd() + \"/data/\" + \"./datasets/10-ENRON.csv\"\n",
    "df = pd.read_csv(enron_csv_file)\n",
    "\n",
    "df.head(), df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0708392f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      0  00  000  01  02  03  ...  writers  www  year  years  yesterday  york\n",
       " 0     0   0    0   0   0   0  ...        0    0     0      0          0     0\n",
       " 1     0   0    0   1   0   0  ...        0    0     0      0          0     0\n",
       " 2     0   0    0   0   0   0  ...        0    0     0      0          0     0\n",
       " 3     0   0    0   0   0   0  ...        0    0     0      0          0     0\n",
       " 4     0   0    0   0   0   0  ...        0    0     1      0          0     0\n",
       " ...  ..  ..  ...  ..  ..  ..  ...      ...  ...   ...    ...        ...   ...\n",
       " 1697  0   0    0   0   0   0  ...        0    0     1      1          0     0\n",
       " 1698  0   0    0   0   1   0  ...        0    1     1      1          1     0\n",
       " 1699  0   0    0   0   0   0  ...        0    0     1      0          0     0\n",
       " 1700  0   0    0   0   1   0  ...        0    1     1      1          1     0\n",
       " 1701  0   0    0   0   1   0  ...        0    1     1      1          1     0\n",
       " \n",
       " [1702 rows x 1001 columns],\n",
       "       A.A8  C.C9  B.B12  C.C11  C.C5  ...  B.B10  C.C1  D.D4  C.C13  D.D14\n",
       " 0        0     0      0      0     0  ...      0     1     0      0      0\n",
       " 1        0     0      0      0     0  ...      0     1     0      0      0\n",
       " 2        0     0      0      0     0  ...      0     0     0      0      0\n",
       " 3        0     0      0      0     0  ...      0     0     0      0      0\n",
       " 4        0     0      0      0     0  ...      0     0     0      0      0\n",
       " ...    ...   ...    ...    ...   ...  ...    ...   ...   ...    ...    ...\n",
       " 1697     0     0      0      0     0  ...      0     0     0      0      0\n",
       " 1698     0     0      0      0     0  ...      0     0     0      0      0\n",
       " 1699     0     0      0      0     0  ...      0     1     0      0      0\n",
       " 1700     0     1      0      0     0  ...      0     0     0      0      0\n",
       " 1701     0     0      0      0     0  ...      0     0     0      0      0\n",
       " \n",
       " [1702 rows x 53 columns])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_columns = [col for col in df.columns if col[0].isupper()]\n",
    "\n",
    "# Create a new DataFrame with the filtered columns\n",
    "X = df.drop(columns=filtered_columns)\n",
    "y = df[filtered_columns]\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c3ffa326",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_files:\n",
    "    X.to_csv(\"./data/10-ENRON_X.csv\", index=False)\n",
    "    y.to_csv(\"./data/10-ENRON_y.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8012a13a",
   "metadata": {},
   "source": [
    "## 11. MediaMill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f9293698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(       Att1      Att2      Att3      Att4  ...  Class98  Class99  Class100  Class101\n",
       " 0  0.380877  0.494079  0.540009  0.422926  ...        0        0         0         0\n",
       " 1  0.508613  0.505837  0.437155  0.490723  ...        0        0         0         0\n",
       " 2  0.449571  0.460490  0.453469  0.410779  ...        0        0         0         0\n",
       " 3  0.416800  0.548996  0.520850  0.465410  ...        0        0         0         0\n",
       " 4  0.501986  0.480820  0.435543  0.432002  ...        0        0         0         0\n",
       " \n",
       " [5 rows x 221 columns],\n",
       " Index(['Att1', 'Att2', 'Att3', 'Att4', 'Att5', 'Att6', 'Att7', 'Att8', 'Att9',\n",
       "        'Att10',\n",
       "        ...\n",
       "        'Class92', 'Class93', 'Class94', 'Class95', 'Class96', 'Class97',\n",
       "        'Class98', 'Class99', 'Class100', 'Class101'],\n",
       "       dtype='object', length=221))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "mediamill_raw_file_name = os.getcwd() + \"/data/\" + \"./datasets/mediamill.arff\"\n",
    "assert(os.path.isfile(mediamill_raw_file_name))\n",
    "\n",
    "# Load ARFF file\n",
    "data, meta = arff.loadarff(mediamill_raw_file_name,)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Optionally, decode byte strings to regular strings if necessary\n",
    "df = df.map(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
    "\n",
    "df.head(), df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eb34be7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(           Att1      Att2      Att3  ...    Att118    Att119    Att120\n",
       " 0      0.380877  0.494079  0.540009  ...  0.317983  0.547807  0.393778\n",
       " 1      0.508613  0.505837  0.437155  ...  0.348174  0.584991  0.422205\n",
       " 2      0.449571  0.460490  0.453469  ...  0.323834  0.571487  0.397564\n",
       " 3      0.416800  0.548996  0.520850  ...  0.346506  0.589601  0.430145\n",
       " 4      0.501986  0.480820  0.435543  ...  0.325957  0.578370  0.398771\n",
       " ...         ...       ...       ...  ...       ...       ...       ...\n",
       " 43902  0.426864  0.528629  0.532957  ...  0.488400  0.624835  0.527380\n",
       " 43903  0.344094  0.537319  0.516101  ...  0.410659  0.564902  0.453231\n",
       " 43904  0.329709  0.453422  0.523771  ...  0.408484  0.570778  0.453345\n",
       " 43905  0.470031  0.489588  0.488227  ...  0.422255  0.585876  0.464987\n",
       " 43906  0.350638  0.548779  0.554297  ...  0.448091  0.589267  0.497985\n",
       " \n",
       " [43907 rows x 120 columns],\n",
       "       Class1 Class2 Class3 Class4  ... Class98 Class99 Class100 Class101\n",
       " 0          0      0      0      0  ...       0       0        0        0\n",
       " 1          0      0      0      0  ...       0       0        0        0\n",
       " 2          0      0      0      0  ...       0       0        0        0\n",
       " 3          0      0      0      0  ...       0       0        0        0\n",
       " 4          0      0      0      0  ...       0       0        0        0\n",
       " ...      ...    ...    ...    ...  ...     ...     ...      ...      ...\n",
       " 43902      0      0      0      0  ...       0       0        0        0\n",
       " 43903      0      0      0      0  ...       0       0        0        0\n",
       " 43904      0      0      0      0  ...       0       0        0        0\n",
       " 43905      0      0      0      0  ...       0       0        0        0\n",
       " 43906      0      0      0      0  ...       0       0        0        0\n",
       " \n",
       " [43907 rows x 101 columns])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[df.columns[df.columns.str.startswith('Att')]]  # Selecting columns with names starting with 'A'\n",
    "y = df[df.columns[df.columns.str.startswith('Class')]]  # Selecting columns with names starting with 'L'\n",
    "\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4b683b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_files:\n",
    "    X.to_csv(\"./data/11-MEDIAMILL_X.csv\", index=False)\n",
    "    y.to_csv(\"./data/11-MEDIAMILL_y.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2bec85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
