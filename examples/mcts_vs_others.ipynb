{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare MCTS to other methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "n_samples = 1000\n",
    "n_features = 20\n",
    "n_classes = 8\n",
    "n_labels = 2\n",
    "random_state = 0\n",
    "\n",
    "X, Y = make_multilabel_classification(\n",
    "    n_samples = n_samples,\n",
    "    n_features = n_features,\n",
    "    n_classes = n_classes,\n",
    "    n_labels = n_labels,\n",
    "    random_state = random_state)\n",
    "\n",
    "test_size = 0.2\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "solver = \"liblinear\"\n",
    "base = LogisticRegression(solver=solver)\n",
    "chain = ClassifierChain(base)\n",
    "\n",
    "chain = chain.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic loss comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import hamming_loss, zero_one_loss\n",
    "\n",
    "from mcts_inference.constraints import Constraint\n",
    "from mcts_inference.mcts_config import MCTSConfig\n",
    "from mcts_inference.mcts import MCTS\n",
    "\n",
    "secs_lis = [0.1, 0.5, 1.]\n",
    "M = min(100,len(Y_test))\n",
    "\n",
    "hl_mt = []\n",
    "hl_ct = []\n",
    "hl_mc = []\n",
    "\n",
    "zo_mt = []\n",
    "zo_ct = []\n",
    "zo_mc = []\n",
    "\n",
    "y_chain = chain.predict(X_test[:M])\n",
    "for secs in secs_lis:\n",
    "#     continue  # Comment if you do not want to run this loop.\n",
    "    y_mcts = []\n",
    "\n",
    "    config = MCTSConfig(n_classes=n_classes, constraint=Constraint(time=True,d_time=secs), parallel=True, verbose=True)\n",
    "    y_mcts = MCTS(X_test[:M], chain, config=config)\n",
    "    \n",
    "    hl_mt.append(hamming_loss(y_mcts,Y_test[:M]))\n",
    "    hl_ct.append(hamming_loss(y_chain,Y_test[:M]))\n",
    "    hl_mc.append(hamming_loss(y_chain,y_mcts))\n",
    "\n",
    "    zo_mt.append(zero_one_loss(y_mcts,Y_test[:M]))\n",
    "    zo_ct.append(zero_one_loss(y_chain,Y_test[:M]))\n",
    "    zo_mc.append(zero_one_loss(y_chain,y_mcts))\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(secs_lis,hl_mt,label=\"MCTS vs True\")\n",
    "plt.plot(secs_lis,hl_ct,label=\"Chains vs True\")\n",
    "plt.plot(secs_lis,hl_mc,label=\"MCTS vs Chains\")\n",
    "\n",
    "plt.title(\"Hamming Loss Comparison for different times\")\n",
    "plt.xlabel(\"Seconds\")\n",
    "plt.ylim(0,1)\n",
    "plt.ylabel(\"Hamming Loss\")\n",
    "plt.legend()\n",
    "plt.show();\n",
    "\n",
    "plt.plot(secs_lis,zo_mt,label=\"MCTS vs True\")\n",
    "plt.plot(secs_lis,zo_ct,label=\"Chains vs True\")\n",
    "plt.plot(secs_lis,zo_mc,label=\"MCTS vs Chains\")\n",
    "\n",
    "plt.title(\"Zero One Loss Comparison for time different times\")\n",
    "plt.xlabel(\"Seconds\")\n",
    "plt.ylim(0,1)\n",
    "plt.ylabel(\"Zero One Loss\")\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some averaged runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mcts_inference.mcts import MCTS\n",
    "from mcts_inference.mcts_config import MCTSConfig\n",
    "from mcts_inference.pcc import PCC\n",
    "\n",
    "def avg_losses(Ns, config, chain, algo= MCTS, loss_function = hamming_loss, M: int = 100, avg: int = 10):\n",
    "    losses = []\n",
    "\n",
    "    print(\"> n:\",end=\"\")\n",
    "    for n in Ns:\n",
    "        print(n, end=\", \")\n",
    "        constraint = Constraint(max_iter=True, n_iter=n)\n",
    "        config.replace_constraint(constraint)\n",
    "\n",
    "        avg_loss = 0\n",
    "        for _ in range(avg):\n",
    "            out = algo(X_test[:M], chain, config)\n",
    "            avg_loss += loss_function(out, Y_test[:M])\n",
    "\n",
    "        losses.append(avg_loss/avg)\n",
    "\n",
    "    return losses\n",
    "\n",
    "def plot_losses(Ns, config, algo, chain, bf: bool = True, M: int = 100, label: str = \"\", title: str = \"\", loss_function=hamming_loss):\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    losses = avg_losses(Ns=Ns, config=config, algo=algo, chain=chain, M=M, loss_function=loss_function)\n",
    "    chain_losses = loss_function(chain.predict(X_test[:M]), Y_test[:M])\n",
    "\n",
    "    plt.plot(Ns, losses, label=label, marker=\"o\", markersize=3)\n",
    "    plt.plot(Ns, [chain_losses]*len(Ns), label=\"Chain\", marker=\"o\", markersize=1)\n",
    "\n",
    "    if bf:\n",
    "        title += \" vs PCC\"\n",
    "        con = MCTSConfig(n_classes, constraint=Constraint(time=True, d_time=2), parallel=True)\n",
    "        PCC_losses = loss_function(PCC(X_test[:M], chain, config=con), Y_test[:M])\n",
    "        plt.plot(Ns, [PCC_losses]*len(Ns), label=\"PCC\", marker=\"o\", markersize=1)\n",
    "\n",
    "    plt.xlabel(\"Number of Iterations\")\n",
    "    plt.ylabel(loss_function.__qualname__ + \" Loss\")\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcts_inference.mcc import MCC\n",
    "from mcts_inference.constraints import Constraint\n",
    "from mcts_inference.mcts_config import MonteCarloConfig\n",
    "\n",
    "Ns = [n for n in range(5, 206, 20)]\n",
    "config = MonteCarloConfig(n_classes, constraint=Constraint(max_iter=True, n_iter=2))\n",
    "plot_losses(Ns, config, algo=MCC, chain=chain, bf = False, label=\"MCC\", title=\"MCC vs Chain\", M=100, loss_function=hamming_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
